[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This repository houses the code submitted by me (Ryan Zomorrodi) for the Spring 2024 PA470 Course."
  },
  {
    "objectID": "posts/coding_warmup_3/index.html",
    "href": "posts/coding_warmup_3/index.html",
    "title": "Coding Warmup 3",
    "section": "",
    "text": "Exercise 7.2.3 from Data Science for Public Policy. Data can be found here.\n\nGraph and regress sale price against gross square feet interpret the results\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(scales)\n\nsales &lt;- read_csv(\"https://raw.githubusercontent.com/DataScienceForPublicPolicy/diys/main/data/home_sales_nyc.csv\")\n\nsales %&gt;%\n    ggplot(aes(x = gross.square.feet, y = sale.price)) +\n        geom_point(alpha = 0.1, size = 1, color = \"springgreen4\") +\n        geom_smooth(method = \"lm\", linewidth = 1, colour = \"black\") + \n        scale_x_continuous(labels = label_comma()) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Sale Price and Gross Square Feet of House Sales in New York City \", \n            x = \"Gross Square Feet\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\nCode\nlinear_reg() %&gt;% \n    set_engine(\"lm\") %&gt;%\n    set_mode(\"regression\") %&gt;%\n    fit(sale.price ~ gross.square.feet, data = sales) %&gt;%\n    extract_fit_engine() %&gt;%\n    summary()\n\n\n\nCall:\nstats::lm(formula = sale.price ~ gross.square.feet, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1700116  -212264   -44958   138638  8661923 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -42584.389  11534.260  -3.692 0.000223 ***\ngross.square.feet    466.176      7.097  65.684  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 463900 on 12666 degrees of freedom\nMultiple R-squared:  0.2541,    Adjusted R-squared:  0.254 \nF-statistic:  4314 on 1 and 12666 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/coding_warmup_3/index.html#part-1",
    "href": "posts/coding_warmup_3/index.html#part-1",
    "title": "Coding Warmup 3",
    "section": "",
    "text": "Exercise 7.2.3 from Data Science for Public Policy. Data can be found here.\n\nGraph and regress sale price against gross square feet interpret the results\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(scales)\n\nsales &lt;- read_csv(\"https://raw.githubusercontent.com/DataScienceForPublicPolicy/diys/main/data/home_sales_nyc.csv\")\n\nsales %&gt;%\n    ggplot(aes(x = gross.square.feet, y = sale.price)) +\n        geom_point(alpha = 0.1, size = 1, color = \"springgreen4\") +\n        geom_smooth(method = \"lm\", linewidth = 1, colour = \"black\") + \n        scale_x_continuous(labels = label_comma()) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Sale Price and Gross Square Feet of House Sales in New York City \", \n            x = \"Gross Square Feet\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\nCode\nlinear_reg() %&gt;% \n    set_engine(\"lm\") %&gt;%\n    set_mode(\"regression\") %&gt;%\n    fit(sale.price ~ gross.square.feet, data = sales) %&gt;%\n    extract_fit_engine() %&gt;%\n    summary()\n\n\n\nCall:\nstats::lm(formula = sale.price ~ gross.square.feet, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1700116  -212264   -44958   138638  8661923 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -42584.389  11534.260  -3.692 0.000223 ***\ngross.square.feet    466.176      7.097  65.684  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 463900 on 12666 degrees of freedom\nMultiple R-squared:  0.2541,    Adjusted R-squared:  0.254 \nF-statistic:  4314 on 1 and 12666 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/coding_warmup_3/index.html#part-2",
    "href": "posts/coding_warmup_3/index.html#part-2",
    "title": "Coding Warmup 3",
    "section": "Part 2",
    "text": "Part 2\nReproduce this figure from tidymodels 3.3\n\n\n\n\n  \n\n\n\n  \n    \n  \n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-1.0\n-0.5\n0.0\n0.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwt\ncyl\ndisp\nhp\ncarb\nqsec\ngear\nam\nvs\ndrat\nCorrelation with mpg\n\n\nCorr Plot 1\n\n\nwith the data from Part 1 replacing mpg with sale price for numeric variables.\n\n\nCode\nlibrary(broom)\n\nsales %&gt;%\n    select(where(is.numeric), -c(sale.price, borough, zip.code)) %&gt;%\n    map(function(col) cor.test(col, sales$sale.price)) %&gt;%\n    map_dfr(tidy, .id = \"predictor\") %&gt;% \n    ggplot(aes(y = fct_reorder(predictor, estimate))) + \n        geom_point(aes(x = estimate)) + \n        geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = .1) +\n        labs(title = \"Correlation of Predictors with Sale Price\", \n            x = \"Correlation\", \n            y = \"Predictor\")"
  },
  {
    "objectID": "posts/coding_warmup_3/index.html#part-3",
    "href": "posts/coding_warmup_3/index.html#part-3",
    "title": "Coding Warmup 3",
    "section": "Part 3",
    "text": "Part 3\nExercise 7.4.5\nEstimate a set of regressions, evaluate the pros and cons of each, and select the “best” specification.\nCreate and analyze the following four models from the textbook and one of your own:\n\nModel 1 (mod1) regresses sales prices and building area\nModel 2 (mod2) adds borough as a categorical variable\nModel 3 (mod3) incorporates an interaction to estimate borough-specific slopes for building area\nModel 4 (mod4) adds land area\n\nThis is obviously a very rudementary analysis, but it looks like model 4 has the lowest AIC and BIC of our 5 models. At a later point, we should conduct a more robust analysis of these models.\nAs with all models, the inclusion of certain predictors into our model requires some contemplation of the bias-variance tradeoff. If we were to simply analyse the RMSE of our models, we will always find that the model with all predictors will have the lowest RMSE. AIC on the other hand penalizes models with more variables and should give us a decent idea if the variance we may be adding is worth the bias we may be reducing.\n\n\nCode\nglm_spec &lt;- linear_reg() %&gt;% \n    set_engine(\"glm\") %&gt;%\n    set_mode(\"regression\")\n\nmod1_rec &lt;- recipe(sale.price ~ gross.square.feet, data = sales)\n\nmod2_rec &lt;- recipe(sale.price ~ gross.square.feet + borough, data = sales) %&gt;%\n    step_mutate(borough = factor(borough))\n\nmod3_rec &lt;- recipe(sale.price ~ gross.square.feet + borough, data = sales) %&gt;%\n    step_mutate(borough = factor(borough)) %&gt;%\n    step_interact(terms = ~ borough:gross.square.feet)\n\nmod4_rec &lt;- recipe(sale.price ~ gross.square.feet + borough + land.square.feet, data = sales) %&gt;%\n    step_mutate(borough = factor(borough)) %&gt;%\n    step_interact(terms = ~ borough:gross.square.feet)\n\nmod5_rec &lt;- recipe(sale.price ~ gross.square.feet + borough + age, data = sales) %&gt;%\n    step_mutate(borough = factor(borough))\n\nlist(mod1_rec, mod2_rec, mod3_rec, mod4_rec, mod5_rec) %&gt;% \n    map(\n        function (rec) {\n            workflow() %&gt;%\n                add_recipe(rec) %&gt;%\n                add_model(glm_spec) %&gt;%\n                fit(data = sales) %&gt;% \n                glance()\n        }) %&gt;%\n    bind_rows(.id = \"id\") %&gt;%\n    mutate(id = str_c(\"mod\", id)) %&gt;%\n    arrange(AIC)\n\n\n# A tibble: 5 × 9\n  id    null.deviance df.null   logLik     AIC    BIC deviance df.residual  nobs\n  &lt;chr&gt;         &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1 mod4        3.65e15   12667 -180884. 361791. 3.62e5  1.87e15       12657 12668\n2 mod3        3.65e15   12667 -181071. 362164. 3.62e5  1.93e15       12658 12668\n3 mod5        3.65e15   12667 -181709. 363433. 3.63e5  2.13e15       12661 12668\n4 mod2        3.65e15   12667 -181710. 363434. 3.63e5  2.13e15       12662 12668\n5 mod1        3.65e15   12667 -183258. 366522. 3.67e5  2.73e15       12666 12668\n\n\n\n\nCode\nworkflow() %&gt;%\n    add_recipe(mod4_rec) %&gt;%\n    add_model(glm_spec) %&gt;%\n    fit(data = sales) %&gt;%\n    tidy()\n\n\n# A tibble: 11 × 5\n   term                           estimate std.error statistic  p.value\n   &lt;chr&gt;                             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                    720684.  191646.        3.76 1.70e- 4\n 2 gross.square.feet                1034.      56.5      18.3  9.89e-74\n 3 borough2                      -627822.  195168.       -3.22 1.30e- 3\n 4 borough3                     -1072863.  192860.       -5.56 2.71e- 8\n 5 borough4                      -589096.  192262.       -3.06 2.19e- 3\n 6 borough5                      -557855.  192464.       -2.90 3.76e- 3\n 7 land.square.feet                   35.7      1.83     19.5  1.63e-83\n 8 borough2_x_gross.square.feet     -864.      60.5     -14.3  7.56e-46\n 9 borough3_x_gross.square.feet     -292.      57.8      -5.04 4.70e- 7\n10 borough4_x_gross.square.feet     -756.      57.5     -13.2  2.91e-39\n11 borough5_x_gross.square.feet     -882.      57.7     -15.3  2.71e-52"
  },
  {
    "objectID": "posts/coding_warmup_3/index.html#part-4",
    "href": "posts/coding_warmup_3/index.html#part-4",
    "title": "Coding Warmup 3",
    "section": "Part 4",
    "text": "Part 4\nIn the class divvy example (see the lectures page for code/files), we had a lot of missing values in our data. We also didn’t have a very rigorous treatment of time/seasonality. Explore how impactful these issues are by creating a few different models and comparing the predictions using the workflows we saw from class in rsample (splitting data), parsnip (linear_reg, set_engine, set_mode, fit), yardstick (mape, rmse), and broom (augment).\nDue to time constraints, I chose not to do this problem rather that give a sub par response."
  },
  {
    "objectID": "posts/cook_part_1/index.html",
    "href": "posts/cook_part_1/index.html",
    "title": "Cook County Property Assessment - Part 1",
    "section": "",
    "text": "You have been tasked with undertaking a multi-part analysis of homes in Cook County, Illinois. You are provided with a database to facilitate this analysis. This database was constructed from the Cook County Open Data portal. More information is included in the database section below. Note that the database must be downloaded.\nFour tables are provided:\nassessments - 2021 to 2023 (not finalized)\nSee: https://datacatalog.cookcountyil.gov/Property-Taxation/Assessor-Assessed-Values/uzyt-m557/about_data\n\n\nView Table Columns\n\n\n\n\n\n\nColumn Name\nDescription\nType\n\n\n\n\npin\nParcel Identification Number (PIN)\nPlain Text\n\n\ntax_year\nTax year\nNumber\n\n\nclass\nProperty class\nPlain Text\n\n\ntownship_code\nTownship code\nPlain Text\n\n\ntownship_name\nTownship name\nPlain Text\n\n\nmailed_bldg\nAssessor mailed building value\nNumber\n\n\nmailed_land\nAssessor mailed land value\nNumber\n\n\nmailed_tot\nAssessor mailed total value\nNumber\n\n\ncertified_bldg\nAssessor certified building value\nNumber\n\n\ncertified_land\nAssessor certified land value\nNumber\n\n\ncertified_tot\nAssessor certified total value\nNumber\n\n\nboard_bldg\nBoard of Review certified building value\nNumber\n\n\nboard_land\nBoard of Review certified land value\nNumber\n\n\nboard_tot\nBoard of Review certified total value\nNumber\n\n\n\n\n\n\ncharacteristics - Tax year 2023 characteristics. See: https://datacatalog.cookcountyil.gov/Property-Taxation/Assessor-Single-and-Multi-Family-Improvement-Chara/x54s-btds/about_data\n\n\nView Table Columns\n\n\n\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\n\n\n\n\npin\nParcel Identification Number (PIN)\nPlain Text\n\n\ntax_year\nTax year\nNumber\n\n\ncard_num\nCard number. Each card is an improvement/building on the parcel\nNumber\n\n\nclass\nProperty class\nPlain Text\n\n\ntownship_code\nTownship code\nPlain Text\n\n\nproration_key_pin\nTieback key PIN. Prorated properties (whose value is split across multiple PINs) have a “main” or key PIN\nPlain Text\n\n\npin_proration_rate\nTieback proration rate. Prorated properties (whose value is split across multiple PINs) pay taxes on the proportion of value on their PIN. In other words, assessed value is multiplied by proration rate to determine taxable assessed value\nNumber\n\n\ncard_proration_rate\nCard proration rate. Prorated parcels (whose value is split across multiple cards) pay taxes on the proportion of value on their card. In other words, assessed value is multiplied by proration rate to determine taxable assessed value. Cards are divisions within parcels, such as one of multiple buildings on a single parcel.\nNumber\n\n\ncdu\nCondition, Desirability, and Utility code. Not well maintained.\nPlain Text\n\n\npin_is_multicard\nMulticard PIN. Indicates whether the parcel contains more than one building (ADU, coach house, etc.)\nCheckbox\n\n\npin_num_cards\nNumber of cards on this parcel. Each card is an improvement/building\nNumber\n\n\npin_is_multiland\nMultiland PIN. Indicates whether parcel has more than one landline\nCheckbox\n\n\npin_num_landlines\nNumber of landlines on a parcel. The sum of all landline square footage should be equal to the total square footage of the parcel. Each landline can correspond to a different land price/rate\nNumber\n\n\nyear_built\nYear built\nNumber\n\n\nbuilding_sqft\nBuilding square feet. Square footage of the building, as measured from the exterior\nNumber\n\n\nland_sqft\nLand square feet. Square footage of the land (not just the building) of the property. Note that a single PIN can have multiple landlines, meaning it can be associated with more than one land price/rate\nNumber\n\n\nnum_bedrooms\nNumber of bedrooms\nNumber\n\n\nnum_rooms\nRooms. Number of total rooms in the building (excluding baths). Not to be confused with bedrooms\nNumber\n\n\nnum_full_baths\nFull baths. Defined as having a bath or shower. If this value is missing, the default value is set to 1\nNumber\n\n\nnum_half_baths\nHalf baths. Defined as bathrooms without a shower or bathtub\nNumber\n\n\nnum_fireplaces\nFireplaces. Counted as the number of flues one can see from the outside of the building\nNumber\n\n\ntype_of_residence\nType of residence\nPlain Text\n\n\nconstruction_quality\nConstruction quality\nPlain Text\n\n\nnum_apartments\nApartments. Number of apartments for class 211 and 212 properties\nPlain Text\n\n\nattic_finish\nAttic finish\nPlain Text\n\n\ngarage_attached\nGarage 1 attached\nPlain Text\n\n\ngarage_area_included\nIs Garage 1 physically included within the building area? If yes, the garage area is subtracted from the building square feet calculation by the field agent\nPlain Text\n\n\ngarage_size\nGarage 1 size\nPlain Text\n\n\ngarage_ext_wall_material\nGarage 1 exterior wall material\nPlain Text\n\n\nattic_type\nAttic type\nPlain Text\n\n\nbasement_type\nBasement type\nPlain Text\n\n\next_wall_material\nExterior wall material\nPlain Text\n\n\ncentral_heating\nCentral heating\nPlain Text\n\n\nrepair_condition\nRepair condition\nPlain Text\n\n\nbasement_finish\nBasement finish\nPlain Text\n\n\nroof_material\nRoof material\nPlain Text\n\n\nsingle_v_multi_family\nSingle vs. multi-family use\nPlain Text\n\n\nsite_desirability\nSite desirability\nPlain Text\n\n\nnum_commercial_units\nNumber of commercial units on the parcel (the vast majority are for properties with class 212)\nPlain Text\n\n\nrenovation\nRenovation\nPlain Text\n\n\nrecent_renovation\nRenovation in last 3 years\nCheckbox\n\n\nporch\nPorch\nPlain Text\n\n\ncentral_air\nCentral air conditioning\nPlain Text\n\n\ndesign_plan\nDesign plan\nPlain Text\n\n\n\n\n\n\ngeospatial_universe - Information on latitude/longitude and neighborhood code from tax year 2022 (released on a delay). Only a subset of columns is selected. See: https://datacatalog.cookcountyil.gov/Property-Taxation/Assessor-Parcel-Universe/nj4t-kc8j/about_data\n\n\nView Table Columns\n\n\n\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\n\n\n\n\npin\nParcel Identification Number (PIN)\nPlain Text\n\n\npin10\nParcel Identification Number (10-digit)\nPlain Text\n\n\ntax_year\nTax year\nNumber\n\n\nclass\nProperty class\nPlain Text\n\n\ntriad_name\nTriad name. Reassessment of property in Cook County is done within a triennial cycle, meaning it occurs every three years. The Cook County Assessor’s Office alternates reassessments between triads: the north and west suburbs, the south and west suburbs and the City of Chicago.\nPlain Text\n\n\ntriad_code\nTriad code. Reassessment of property in Cook County is done within a triennial cycle, meaning it occurs every three years. The Cook County Assessor’s Office alternates reassessments between triads: the north and west suburbs, the south and west suburbs and the City of Chicago.\nPlain Text\n\n\ntownship_name\nTownship name\nPlain Text\n\n\ntownship_code\nTownship code\nPlain Text\n\n\nneighborhood_code\nAssessor neighborhood code, first two digits are township, last three are neighborhood\nPlain Text\n\n\ntax_district_code\nTax district code, as seen on individual property tax bills (Not currently up-to-date)\nPlain Text\n\n\nzip_code\nProperty zip code\nPlain Text\n\n\nlongitude\nParcel centroid longitude\nNumber\n\n\nlatitude\nParcel centroid latitude\nNumber\n\n\ncentroid_x_crs_3435\nParcel centroid X coordinate (CRS 3435)\nNumber\n\n\ncentroid_y_crs_3435\nParcel centroid Y coordinate (CRS 3435)\nNumber\n\n\ncensus_block_group_geoid\nCensus block group GEOID\nPlain Text\n\n\ncensus_block_geoid\nCensus block GEOID\nPlain Text\n\n\ncensus_congressional_district_geoid\nCensus congressional district GEOID\nPlain Text\n\n\ncensus_county_subdivision_geoid\nCensus county subdivision GEOID\nPlain Text\n\n\ncensus_place_geoid\nCensus place GEOID\nPlain Text\n\n\ncensus_puma_geoid\nCensus PUMA GEOID\nPlain Text\n\n\ncensus_school_district_elementary_geoid\nCensus school district (elementary) GEOID\nPlain Text\n\n\ncensus_school_district_secondary_geoid\nCensus school district (secondary) GEOID\nPlain Text\n\n\ncensus_school_district_unified_geoid\nCensus school district (unified) GEOID\nPlain Text\n\n\ncensus_state_representative_geoid\nCensus state representative GEOID\nPlain Text\n\n\ncensus_state_senate_geoid\nCensus state senate GEOID\nPlain Text\n\n\ncensus_tract_geoid\nCensus tract GEOID\nPlain Text\n\n\ncensus_zcta_geoid\nCensus ZCTA GEOID\nPlain Text\n\n\ncensus_data_year\nCensus data year\nNumber\n\n\ncensus_acs5_congressional_district_geoid\nCensus ACS5 congressional district GEOID\nPlain Text\n\n\ncensus_acs5_county_subdivision_geoid\nCensus ACS5 county subdivision GEOID\nPlain Text\n\n\ncensus_acs5_place_geoid\nCensus ACS5 place GEOID\nPlain Text\n\n\ncensus_acs5_puma_geoid\nCensus ACS5 PUMA GEOID\nPlain Text\n\n\ncensus_acs5_school_district_elementary_geoid\nCensus ACS5 school district (elementary) GEOID\nPlain Text\n\n\ncensus_acs5_school_district_secondary_geoid\nCensus ACS5 school district (secondary) GEOID\nPlain Text\n\n\ncensus_acs5_school_district_unified_geoid\nCensus ACS5 school district (unified) GEOID\nPlain Text\n\n\ncensus_acs5_state_representative_geoid\nCensus ACS5 state representative GEOID\nPlain Text\n\n\ncensus_acs5_state_senate_geoid\nCensus ACS5 state senate GEOID\nPlain Text\n\n\ncensus_acs5_tract_geoid\nCensus ACS5 tract GEOID\nPlain Text\n\n\ncensus_acs5_data_year\nCensus ACS5 data year\nNumber\n\n\nboard_of_review_district_num\nBoard of Review district number\nPlain Text\n\n\nboard_of_review_district_data_year\nBoard of Review district data year\nNumber\n\n\ncommissioner_district_num\nCommissioner district number\nPlain Text\n\n\ncommissioner_district_data_year\nCommissioner district data year\nNumber\n\n\njudicial_district_num\nJudicial district number\nPlain Text\n\n\njudicial_district_data_year\nJudicial district data year\nNumber\n\n\nward_num\nWard number\nPlain Text\n\n\nward_chicago_data_year\nChicago ward data year\nNumber\n\n\nward_evanston_data_year\nEvanston ward data year\nNumber\n\n\nchicago_community_area_num\nChicago community area number\nPlain Text\n\n\nchicago_community_area_name\nChicago community area name\nPlain Text\n\n\nchicago_community_area_data_year\nChicago community area data year\nNumber\n\n\nchicago_industrial_corridor_num\nChicago industrial corridor number\nPlain Text\n\n\nchicago_industrial_corridor_name\nChicago industrial corridor name\nPlain Text\n\n\nchicago_industrial_corridor_data_year\nChicago industrial corridor data year\nNumber\n\n\nchicago_police_district_num\nChicago police district number\nPlain Text\n\n\nchicago_police_district_data_year\nChicago police district data year\nNumber\n\n\ncoordinated_care_area_num\nCoordinated Care Area number\nPlain Text\n\n\ncoordinated_care_area_data_year\nCoordinated Care Area data year\nNumber\n\n\nenterprise_zone_num\nEnterprise Zone number\nPlain Text\n\n\nenterprise_zone_data_year\nEnterprise Zone data year\nNumber\n\n\nindustrial_growth_zone_num\nIndustrial Growth Zone number\nPlain Text\n\n\nindustrial_growth_zone_data_year\nIndustrial Growth Zone data year\nNumber\n\n\nqualified_opportunity_zone_num\nQualified Opportunity Zone number\nPlain Text\n\n\nqualified_opportunity_zone_data_year\nQualified Opportunity Zone data year\nNumber\n\n\nflood_fema_sfha\nFEMA Special Flood Hazard Area (SFHA) indicator\nCheckbox\n\n\nflood_fema_data_year\nFEMA Special Flood Hazard Area (SFHA) data year\nNumber\n\n\nflood_fs_factor\nFirst Street Flood Factor\nNumber\n\n\nflood_fs_risk_direction\nFirst Street flood risk direction\nNumber\n\n\nflood_fs_data_year\nFirst Street data year\nNumber\n\n\nohare_noise_contour_no_buffer_bool\nO’Hare noise contour indicator (no buffer). Indicates whether or not a parcel’s centroid is within O’Hare’s 65 DNL noise contour\nCheckbox\n\n\nohare_noise_contour_half_mile_buffer_bool\nO’Hare noise contour indicator (1/2 mile buffer). Indicates whether or not a parcel’s centroid is within O’Hare’s 65 DNL noise contour, buffered by 1/2 mile\nCheckbox\n\n\nohare_noise_contour_data_year\nO’Hare noise contour data year. The “omp” value corresponds to the projected noise contour upon completion of the O’Hare Modernization Project\nNumber\n\n\nairport_noise_dnl\nAirport continuous noise surface estimated DNL\nNumber\n\n\nairport_noise_data_year\nAirport continuous noise surface estimated data year\nPlain Text\n\n\nschool_elementary_district_geoid\nSchool district (elementary) GEOID, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_elementary_district_name\nSchool district (elementary) name, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_secondary_district_geoid\nSchool district (secondary) GEOID, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_secondary_district_name\nSchool district (secondary) name, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_unified_district_geoid\nSchool district (unified) GEOID, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_unified_district_name\nSchool district (unified) name, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_year\nSchool year\nPlain Text\n\n\nschool_data_year\nSchool data year\nNumber\n\n\ntax_municipality_num\nMunicipality number\nPlain Text\n\n\ntax_municipality_name\nMunicipality name\nPlain Text\n\n\ntax_school_elementary_district_num\nSchool district (elementary) number, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_elementary_district_name\nSchool district (elementary) name, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_secondary_district_num\nSchool district (secondary) number, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_secondary_district_name\nSchool district (secondary) name, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_unified_district_num\nSchool district (unified) number, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_unified_district_name\nSchool district (unified) name, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_community_college_district_num\nCommunity college district number\nPlain Text\n\n\ntax_community_college_district_name\nCommunity college district name\nPlain Text\n\n\ntax_fire_protection_district_num\nFire protection district number\nPlain Text\n\n\ntax_fire_protection_district_name\nFire protection district name\nPlain Text\n\n\ntax_library_district_num\nLibrary district number\nPlain Text\n\n\ntax_library_district_name\nLibrary district name\nPlain Text\n\n\ntax_park_district_num\nPark district number\nPlain Text\n\n\ntax_park_district_name\nPark district name\nPlain Text\n\n\ntax_sanitation_district_num\nSanitation district number\nPlain Text\n\n\ntax_sanitation_district_name\nSanitation district name\nPlain Text\n\n\ntax_special_service_area_num\nSpecial Service Area number\nPlain Text\n\n\ntax_special_service_area_name\nSpecial Service Area name\nPlain Text\n\n\ntax_tif_district_num\nTIF district number\nPlain Text\n\n\ntax_tif_district_name\nTIF district name\nPlain Text\n\n\ntax_districts_data_year\nData year for municipality, school, community college, fire, library, park, sanitary, special service area, and tax increment financing tax districts.\nNumber\n\n\ncmap_walkability_grid_id\nCMAP walkability grid ID. From CMAP’s ON TO 2050 spatial data files\nPlain Text\n\n\ncmap_walkability_no_transit_score\nCMAP walkability score (no transit). From CMAP’s ON TO 2050 spatial data files\nNumber\n\n\ncmap_walkability_total_score\nCMAP walkability total score. From CMAP’s ON TO 2050 spatial data files\nNumber\n\n\ncmap_walkability_data_year\nCMAP walkability data year\nNumber\n\n\nsubdivision_id\nSubdivision ID\nPlain Text\n\n\nsubdivision_data_year\nSubdivision data year\nNumber\n\n\n\n\n\n\nsales - Information on sales from 2021 to present (current mid-September 2023) See: https://datacatalog.cookcountyil.gov/Property-Taxation/Assessor-Parcel-Sales/wvhk-k5uv/about_data\n\n\nView Table Columns\n\n\n\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\n\n\n\n\npin\nParcel Identification Number (PIN)\nPlain Text\n\n\nyear\nYear\nNumber\n\n\ntownship_code\nTownship code\nPlain Text\n\n\nneighborhood_code\nAssessor neighborhood code, first two digits are township, last three are neighborhood\nPlain Text\n\n\nclass\nProperty class\nPlain Text\n\n\nsale_date\nSale date (recorded, not executed)\nDate & Time\n\n\nis_mydec_date\nIndicates whether the sale date has been overwritten with a more precise value from IDOR (Illinois Department of Revenue). In the past the Assessor’s ingest process truncated sale dates to the first of the month. Not all sales can be updated with dates from IDOR.\nCheckbox\n\n\nsale_price\nSale price\nNumber\n\n\nsale_document_num\nSale document number. Corresponds to Clerk’s document number\nPlain Text\n\n\nsale_deed_type\nSale deed type\nPlain Text\n\n\nmydec_deed_type\nDeed type from MyDec, more granular than CCAO deed type.\nPlain Text\n\n\nsale_seller_name\nSale seller name\nPlain Text\n\n\nis_multisale\nIndicates whether a parcel was sold individually or as part of a larger group of PINs\nCheckbox\n\n\nnum_parcels_sale\nThe number of parcels that were part of the sale\nNumber\n\n\nsale_buyer_name\nSale buyer name\nPlain Text\n\n\nsale_type\nSale type\nPlain Text\n\n\nsale_filter_same_sale_within_365\nRemove sale with the same value (for the same PIN) within 365 days\nCheckbox\n\n\nsale_filter_less_than_10k\nIndicator for whether sale is less than $10K FMW\nCheckbox\n\n\nsale_filter_deed_type\nIndicator for quit claim, executor, beneficiary and missing deed types\nCheckbox\n\n\n\n\n\n\n\n\nFirst let’s load our data and make some joins to sales data\n\n\nCode\nlibrary(tidyverse)\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"../data/cook.sqlite\")\n\nsfh_sales &lt;- tbl(con, 'sales') %&gt;%\n    collect() %&gt;%\n    filter(class %in% c(202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278)) %&gt;%\n    mutate(sale_date = as_datetime(sale_date)) %&gt;% \n    mutate(township_code = as.character(township_code)) %&gt;%\n    distinct(doc_no, .keep_all = TRUE)\n\ntownship_codes &lt;- read_csv(\"../data/township_codes.csv\") %&gt;% \n    mutate(across(where(is.numeric), as.character))\n\nsfh_characteristics &lt;- tbl(con, 'characteristics') %&gt;%\n    collect() %&gt;%\n    distinct(pin, .keep_all = T) %&gt;%\n    select(-c(class, township_code)) %&gt;%\n    right_join(sfh_sales, by = join_by(pin, year == year)) %&gt;%\n    right_join(township_codes)\n\nsfh_assessments &lt;- tbl(con, 'assessments') %&gt;%\n    collect() %&gt;%\n    mutate(township_code = as.character(township_code)) %&gt;%\n    distinct(pin, .keep_all = T) %&gt;%\n    select(-c(class, township_code)) %&gt;%\n    right_join(sfh_sales, by = join_by(pin, tax_year == year))\n\n\n\n\nThe distributions of average sale price for single family homes by township lines up with most people’s preconceptions of Cook County. We can see that average sale prices are highest in townships in northern Cook County in Chicago and the more wealthy northern suburbs. Within these very same townships, we can see that single family homes both tend to be larger and tend to cost more per square foot. Lastly, we can see that the oldest households tend be within the city of Chicago, while the mean age of houses within Cook County seems to lower, the farther you get from the city of Chicago.\n\nSale PriceBuilding SqFtPrice Per SqFtYears old\n\n\n\n\nCode\nlibrary(sf)\nlibrary(leaflet)\nlibrary(scales)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n    mutate(ORIGOID = as.character(ORIGOID)) %&gt;%\n    right_join(township_codes, by = join_by(ORIGOID == origoid))\n\nsfh_mean_by_township &lt;- sfh_characteristics %&gt;%\n    group_by(township_code) %&gt;%\n    reframe(sale_price_mean = mean(sale_price, na.rm = T),\n        bldg_sf_mean = mean(char_bldg_sf, na.rm = T),\n        sale_price_per_sf = mean(sale_price/char_bldg_sf, na.rm = T),\n        years_old_mean = mean(2023 - char_yrblt, na.rm = T)) %&gt;%\n    right_join(townships) %&gt;%\n    st_as_sf()\n    \nqpal &lt;- colorQuantile(\"Greens\", sfh_mean_by_township$sale_price_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(sale_price_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Average Sale: %s&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_currency()(sfh_mean_by_township$sale_price_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\"))   %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$sale_price_mean,\n            opacity = 0.7,\n            title = \"Mean Sale Price of &lt;/br&gt;Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Oranges\", sfh_mean_by_township$bldg_sf_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(bldg_sf_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Mean Building sqft: %s&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_comma(1)(sfh_mean_by_township$bldg_sf_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\"))   %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$bldg_sf_mean,\n            opacity = 0.7,\n            title = \"Mean Building Square Feet&lt;/br&gt; of Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_comma(1)(cuts[-n]), \" - \", label_comma(1)(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Blues\", sfh_mean_by_township$sale_price_per_sf, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(sale_price_per_sf),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;%s per sqft&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_currency()(sfh_mean_by_township$sale_price_per_sf)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")) %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$sale_price_per_sf,\n            opacity = 0.7,\n            title = \"Dollars per Square Foot of &lt;/br&gt;Single Family Homes in &lt;/br&gt;Cook County by Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Reds\", sfh_mean_by_township$years_old_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(years_old_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;%s years old&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_number(1)(sfh_mean_by_township$years_old_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")) %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$years_old_mean,\n            opacity = 0.7,\n            title = \"Mean Years Old of &lt;/br&gt;Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_number(1)(cuts[-n]), \" - \", label_number(1)(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\n\n\nIt seems that single family homes built in the last 30 - 40 years tend to be more expensive, but beyond that sale prices do not seem to be associated with sale prices. As expected, higher square footage single family homes tend to sell for more, but there is still a large amount variability in sale prices. Larger land square footage single family homes seem to sell for more up until about 15,000 square feet where additional land does not seem to be associated with much greater sale prices. More beds, rooms, and bathrooms seem to all be associated with greater sale prices. However, there seems to be some odd outliers with 0 bedrooms or 2 rooms that are selling for more than would be expected. This may be something we would want to investigate later. These could be simply a result of faulty assessor data.\n\nYear builtBuilding SqFtLand SqFtBedsRoomsBathrooms\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    ggplot(aes(x = char_yrblt, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Sale Price and Year Built in Cook County, IL\", \n            x = \"Year Built\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    ggplot(aes(x = char_bldg_sf, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Building Square Footage and Sale Price \\nin Cook County, IL\", \n            x = \"Building Square Footage\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    filter(char_land_sf &lt;= 10^5) %&gt;%\n    ggplot(aes(x = char_land_sf, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Building Square Footage and Sale Price \\nin Cook County, IL\", \n            x = \"Land Square Footage\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_beds, y = sale_price, fill = factor(char_beds))) +\n        scale_x_continuous(n.breaks = 9) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Number of Bedrooms and Sale Price \\nin Cook County, IL\", \n            x = \"Number of Bedrooms\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_rooms, y = sale_price, fill = factor(char_rooms))) +\n        scale_x_continuous(n.breaks = 20) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Number of Rooms and Sale Price \\nin Cook County, IL\", \n            x = \"Number of Rooms\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_fbath + char_hbath * 0.5, y = sale_price, fill = factor(char_fbath + char_hbath * 0.5))) +\n        scale_x_continuous(n.breaks = 20) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Total Number of Baths and Sale Price \\nin Cook County, IL\", \n            x = \"Total Number of Baths\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s get our data into a format that the cmfproperty package can use.\n\n\nCode\nlibrary(cmfproperty)\n\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"../data/cook.sqlite\")\n\nsfh_sales_cmf &lt;- sfh_sales %&gt;% \n    select(pin, year, sale_price, doc_no) %&gt;%\n    distinct(doc_no, .keep_all = TRUE) %&gt;%\n    select(-doc_no) %&gt;%\n    filter(as.numeric(sale_price) &gt; 2500)\n\nassessments_cmf &lt;- tbl(con, \"assessments\") %&gt;%\n    collect() %&gt;%\n    select(pin, tax_year, certified_tot)\n\nsale_assess_cmf &lt;- sfh_sales_cmf %&gt;% \n    left_join(assessments_cmf, by = join_by(pin, year == tax_year)) %&gt;% \n    rename(PIN = pin, SALE_YEAR = year, SALE_PRICE = sale_price, ASSESSED_VALUE = certified_tot) %&gt;%\n    mutate(ASSESSED_VALUE = 10 * ASSESSED_VALUE)\n\nratios &lt;- reformat_data(sale_assess_cmf,\n    sale_col = \"SALE_PRICE\",\n    assessment_col = \"ASSESSED_VALUE\",\n    sale_year_col = \"SALE_YEAR\")\n\nstats &lt;- calc_iaao_stats(ratios)\n\n\nOverall, we can see that at every sale price decile, single family homes are underassessed compared to their true sale price. However, the degree to which single family homes are underassessed is not equal. Regardless of efforts of the county, it is clear that in 2023 (for the months of Jan-Sep), houses within the lowest deciles tend to be assessed at higher ratios to their true sales price. The overall picture from 2021 to Sep 2023 is more enocouraging, but nevertheless the lowest decile tends to be assessed at higher rates than all other deciles and the 2nd to 5th lowest deciles seem to be asssed at lower rates than the higher deciles.\n\nBinned ScatterPercent AssessedCoefficient of DispersionPrice-Related DifferentialCoefficient of Price-Related Bias\n\n\n\n\nCode\nbinned &lt;- binned_scatter(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nknitr::asis_output(htmltools::htmlPreserve(binned[[1]]))\n\nbinned[[2]]\n\n\n\n\n\n\n\n\n\nIn 2023, the most expensive homes (the top decile) were assessed at 76.2% of their value and the least expensive homes (the bottom decile) were assessed at 93.1%. In other words, the least expensive homes were assessed at 1.22 times the rate applied to the most expensive homes. Across our sample from 2021 to 2023, the most expensive homes were assessed at 77.4% of their value and the least expensive homes were assessed at 84.6%, which is 1.09 times the rate applied to the most expensive homes.\n\n\n\n\n\n\nCode\npct_over &lt;- pct_over_under(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nknitr::asis_output(htmltools::htmlPreserve(pct_over[[1]]))\n\npct_over[[2]]\n\n\n\n\n\n\n\n\n\nIn Cook County, IL, 58% of the lowest value homes are overassessed and 52% of the highest value homes are overassessed.\n\n\n\n\n\n\nCode\niaao_rslt &lt;- iaao_graphs(stats,\n    ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, Illinois\")\n\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[1]]))\n\niaao_rslt[[2]]\n\n\n\n\n\n\n\n\n\nFor 2023, the COD in Cook County, Illinois was 19.6 which did not meet the IAAO standard for uniformity.\n\n\n\n\n\n\nCode\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[3]]))\n\niaao_rslt[[4]]\n\n\n\n\n\n\n\n\n\nIn 2023, the PRD in  Cook County, Illinois, was 1.074 which does not meet  the IAAO standard for vertical equity.\n\n\n\n\n\n\nCode\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[5]]))\n\niaao_rslt[[6]]\n\n\n\n\n\n\n\n\n\nIn 2023, the PRB in Cook County, Illinois was 0.004 which indicates that sales ratios increase by 0.4% when home values double. This meets the IAAO standard.\n\n\n\n\n\n\n\n\nLet’s evaluate a couple different linear models (linear models were chosen simply because of the lower computing power necessary to train them). First, we’ll split our data.\n\n\nCode\nlibrary(tidymodels) \ntidymodels_prefer()\n\nset.seed(1)\nsplit &lt;- initial_split(sfh_characteristics)\ntrain_set &lt;- training(split)\ntest_set &lt;- testing(split)\n\nset.seed(2)\ntrain_resamples &lt;- bootstraps(train_set)\n\n\nWe’ll preprocess our data.\n\n\nCode\nbasic_rec &lt;- recipe(sale_price ~ char_yrblt + char_bldg_sf + char_land_sf + char_beds + char_rooms + char_fbath + char_hbath + township_code, data = sfh_characteristics) %&gt;% \n    step_mutate(years_old = 2023 - char_yrblt, role = \"predictor\") %&gt;%\n    remove_role(char_yrblt, old_role = \"predictor\") %&gt;%\n    step_string2factor(township_code) %&gt;% \n    step_naomit(all_predictors()) %&gt;% \n    step_novel(all_nominal_predictors()) %&gt;%\n    step_dummy(all_nominal_predictors()) %&gt;%\n    step_zv(all_predictors())\n\nnormalized_rec &lt;- basic_rec %&gt;% \n   step_normalize(all_predictors())\n\n\nSave the specifications of our models.\n\n\nCode\nols_spec &lt;- linear_reg() %&gt;% \n    set_engine(\"lm\") %&gt;%\n    set_mode(\"regression\")\n\nridge_spec &lt;- linear_reg(penalty = tune(), mixture = 0) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\nlasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\nenet_spec &lt;- linear_reg(penalty = tune(), mixture = tune()) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\n\nCreate our workflows.\n\n\nCode\nall_workflows &lt;- workflow_set(\n    preproc = list(normalize = normalized_rec),\n    models = list( \n        ols = ols_spec,\n        ridge = ridge_spec,\n        lasso = lasso_spec,\n        enet = enet_spec))\n\n\nRun our models.\n\n\nCode\nctrl_grid &lt;- control_grid(\n    save_pred = TRUE,\n    save_workflow = TRUE)\n\nres_grid &lt;- all_workflows %&gt;% \n    workflow_map(\n        resamples = train_resamples, \n        grid = 20, \n        control = ctrl_grid,\n        metrics = metric_set(rmse, rsq, ccc),\n        verbose = TRUE)\n\n\nFit our best model (Elastic Net).\n\n\nCode\nres_ranks &lt;- res_grid %&gt;% \n    rank_results('rmse') %&gt;% \n    filter(.metric == 'rmse') %&gt;%\n    select(wflow_id, model, .config, rmse = mean, rank) %&gt;% \n    group_by(wflow_id) %&gt;% \n    slice_min(rank, with_ties = FALSE) %&gt;% \n    ungroup() %&gt;% \n    arrange(rank)\n\nwflow_id_best &lt;- res_ranks %&gt;% \n    slice_min(rank, with_ties = FALSE) %&gt;% \n    pull(wflow_id)\n\nwf_best &lt;- res_grid %&gt;% \n    extract_workflow_set_result(wflow_id_best) %&gt;% \n    select_best(metric = 'rmse')\n\nfit_best &lt;- res_grid %&gt;% \n    extract_workflow(wflow_id_best) %&gt;% \n    finalize_workflow(wf_best) %&gt;% \n    last_fit(split = split)\n\n\nLet’s look at how well our model performs\n\n\nCode\ntrain_fit &lt;- res_grid %&gt;% \n    extract_workflow(wflow_id_best) %&gt;%\n    finalize_workflow(wf_best) %&gt;% \n    fit(data = train_set)\n\ntest_augment &lt;- augment(train_fit, test_set)\n\n\n\n\nCode\nmape(test_augment, truth = sale_price, estimate = .pred) %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nmape\nstandard\n434.6188\n\n\n\n\n\nCode\nrmse(test_augment, truth = sale_price, estimate = .pred) %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n264690.7\n\n\n\n\n\nIt looks like our model underestimates higher sale price homes. This would make our model regressive, which is concerning.\n\n\nCode\nggplot(test_augment, aes(x = sale_price, y = sale_price - .pred)) +\n    geom_point() +\n    labs(title = \"Elastic Net Residuals and Sale Price in Cook County, IL\", \n        x = \"Sale Price\", \n        y = \"Residuals\")\n\n\n\n\n\n\n\n\n\nLet’s see what variables have the largest impact on sale_price.\nNotice that building square feet seems to have the largest impact on the sale price. This makes implicit sense because larger single family homes tend to sell for more. We can also see that certain townships (ex: New Trier, Lake View, North Chicago) can have large impacts on the sale price of single family homes.\nAlthough our exploratory data analysis indicated that the number of years old a single family home was and how much land it has was associated with changes in sale prices within certain ranges it seems that the model was still able to pick up on some association.\nInterestingly, the number of beds that a single family home has was only the fifth strongest non-township predictor within this model. My guess is that this is because there is some multicolinearity between it and building square feet and number of full baths (two of our strongest non-township predictors). Elastic net takes some characteristics from ridge regression which means that it may shrink coefficients for parameters that exibit multicollinearity. In the future, we should take some caution to address concerns that may stem out of the fact that some of our parameters may exhibit multicollinearity.\n\n\nCode\nfit_best %&gt;%\n    extract_fit_parsnip() %&gt;%\n    tidy() %&gt;% \n    arrange(desc(abs(estimate))) %&gt;%\n    select(-penalty) %&gt;%\n    knitr::kable()\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n411430.1509\n\n\nchar_bldg_sf\n173102.1930\n\n\ntownship_code_X23\n122590.9790\n\n\ntownship_code_X73\n100464.1254\n\n\ntownship_code_X74\n98948.7028\n\n\nchar_fbath\n57515.9458\n\n\ntownship_code_X71\n44273.8193\n\n\ntownship_code_X77\n40171.8266\n\n\ntownship_code_X25\n37585.7469\n\n\ntownship_code_X17\n37127.8833\n\n\nyears_old\n-36310.3012\n\n\ntownship_code_X32\n-29412.3966\n\n\ntownship_code_X37\n-26423.4514\n\n\nchar_land_sf\n25928.7813\n\n\ntownship_code_X12\n-24590.2254\n\n\nchar_beds\n-23844.3942\n\n\ntownship_code_X27\n23571.0122\n\n\ntownship_code_X21\n22396.3105\n\n\ntownship_code_X22\n18702.2171\n\n\ntownship_code_X24\n18433.0435\n\n\ntownship_code_X33\n17375.9446\n\n\ntownship_code_X13\n-15277.9551\n\n\nchar_hbath\n13864.3441\n\n\ntownship_code_X28\n-13663.1957\n\n\ntownship_code_X70\n-11151.1800\n\n\ntownship_code_X18\n-10018.7998\n\n\ntownship_code_X16\n9804.5747\n\n\ntownship_code_X75\n9622.6161\n\n\ntownship_code_X26\n9527.2867\n\n\ntownship_code_X38\n8921.9784\n\n\ntownship_code_X39\n-7649.2568\n\n\ntownship_code_X76\n7577.2306\n\n\ntownship_code_X30\n-7055.2081\n\n\ntownship_code_X34\n6767.3835\n\n\ntownship_code_X72\n-6149.2097\n\n\ntownship_code_X19\n-5829.4375\n\n\ntownship_code_X14\n-5619.0157\n\n\ntownship_code_X31\n5335.3295\n\n\ntownship_code_X20\n5057.9514\n\n\nchar_rooms\n-3085.1155\n\n\ntownship_code_X29\n-2818.9065\n\n\ntownship_code_X11\n2720.7418\n\n\ntownship_code_X35\n-464.7437\n\n\ntownship_code_X36\n-291.2669\n\n\ntownship_code_X15\n0.0000"
  },
  {
    "objectID": "posts/cook_part_1/index.html#conduct-an-exploratory-data-analysis",
    "href": "posts/cook_part_1/index.html#conduct-an-exploratory-data-analysis",
    "title": "Cook County Property Assessment - Part 1",
    "section": "",
    "text": "First let’s load our data and make some joins to sales data\n\n\nCode\nlibrary(tidyverse)\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"../data/cook.sqlite\")\n\nsfh_sales &lt;- tbl(con, 'sales') %&gt;%\n    collect() %&gt;%\n    filter(class %in% c(202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278)) %&gt;%\n    mutate(sale_date = as_datetime(sale_date)) %&gt;% \n    mutate(township_code = as.character(township_code)) %&gt;%\n    distinct(doc_no, .keep_all = TRUE)\n\ntownship_codes &lt;- read_csv(\"../data/township_codes.csv\") %&gt;% \n    mutate(across(where(is.numeric), as.character))\n\nsfh_characteristics &lt;- tbl(con, 'characteristics') %&gt;%\n    collect() %&gt;%\n    distinct(pin, .keep_all = T) %&gt;%\n    select(-c(class, township_code)) %&gt;%\n    right_join(sfh_sales, by = join_by(pin, year == year)) %&gt;%\n    right_join(township_codes)\n\nsfh_assessments &lt;- tbl(con, 'assessments') %&gt;%\n    collect() %&gt;%\n    mutate(township_code = as.character(township_code)) %&gt;%\n    distinct(pin, .keep_all = T) %&gt;%\n    select(-c(class, township_code)) %&gt;%\n    right_join(sfh_sales, by = join_by(pin, tax_year == year))\n\n\n\n\nThe distributions of average sale price for single family homes by township lines up with most people’s preconceptions of Cook County. We can see that average sale prices are highest in townships in northern Cook County in Chicago and the more wealthy northern suburbs. Within these very same townships, we can see that single family homes both tend to be larger and tend to cost more per square foot. Lastly, we can see that the oldest households tend be within the city of Chicago, while the mean age of houses within Cook County seems to lower, the farther you get from the city of Chicago.\n\nSale PriceBuilding SqFtPrice Per SqFtYears old\n\n\n\n\nCode\nlibrary(sf)\nlibrary(leaflet)\nlibrary(scales)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n    mutate(ORIGOID = as.character(ORIGOID)) %&gt;%\n    right_join(township_codes, by = join_by(ORIGOID == origoid))\n\nsfh_mean_by_township &lt;- sfh_characteristics %&gt;%\n    group_by(township_code) %&gt;%\n    reframe(sale_price_mean = mean(sale_price, na.rm = T),\n        bldg_sf_mean = mean(char_bldg_sf, na.rm = T),\n        sale_price_per_sf = mean(sale_price/char_bldg_sf, na.rm = T),\n        years_old_mean = mean(2023 - char_yrblt, na.rm = T)) %&gt;%\n    right_join(townships) %&gt;%\n    st_as_sf()\n    \nqpal &lt;- colorQuantile(\"Greens\", sfh_mean_by_township$sale_price_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(sale_price_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Average Sale: %s&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_currency()(sfh_mean_by_township$sale_price_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\"))   %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$sale_price_mean,\n            opacity = 0.7,\n            title = \"Mean Sale Price of &lt;/br&gt;Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Oranges\", sfh_mean_by_township$bldg_sf_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(bldg_sf_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Mean Building sqft: %s&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_comma(1)(sfh_mean_by_township$bldg_sf_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\"))   %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$bldg_sf_mean,\n            opacity = 0.7,\n            title = \"Mean Building Square Feet&lt;/br&gt; of Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_comma(1)(cuts[-n]), \" - \", label_comma(1)(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Blues\", sfh_mean_by_township$sale_price_per_sf, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(sale_price_per_sf),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;%s per sqft&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_currency()(sfh_mean_by_township$sale_price_per_sf)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")) %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$sale_price_per_sf,\n            opacity = 0.7,\n            title = \"Dollars per Square Foot of &lt;/br&gt;Single Family Homes in &lt;/br&gt;Cook County by Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Reds\", sfh_mean_by_township$years_old_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(years_old_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;%s years old&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_number(1)(sfh_mean_by_township$years_old_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")) %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$years_old_mean,\n            opacity = 0.7,\n            title = \"Mean Years Old of &lt;/br&gt;Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_number(1)(cuts[-n]), \" - \", label_number(1)(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\n\n\nIt seems that single family homes built in the last 30 - 40 years tend to be more expensive, but beyond that sale prices do not seem to be associated with sale prices. As expected, higher square footage single family homes tend to sell for more, but there is still a large amount variability in sale prices. Larger land square footage single family homes seem to sell for more up until about 15,000 square feet where additional land does not seem to be associated with much greater sale prices. More beds, rooms, and bathrooms seem to all be associated with greater sale prices. However, there seems to be some odd outliers with 0 bedrooms or 2 rooms that are selling for more than would be expected. This may be something we would want to investigate later. These could be simply a result of faulty assessor data.\n\nYear builtBuilding SqFtLand SqFtBedsRoomsBathrooms\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    ggplot(aes(x = char_yrblt, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Sale Price and Year Built in Cook County, IL\", \n            x = \"Year Built\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    ggplot(aes(x = char_bldg_sf, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Building Square Footage and Sale Price \\nin Cook County, IL\", \n            x = \"Building Square Footage\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    filter(char_land_sf &lt;= 10^5) %&gt;%\n    ggplot(aes(x = char_land_sf, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Building Square Footage and Sale Price \\nin Cook County, IL\", \n            x = \"Land Square Footage\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_beds, y = sale_price, fill = factor(char_beds))) +\n        scale_x_continuous(n.breaks = 9) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Number of Bedrooms and Sale Price \\nin Cook County, IL\", \n            x = \"Number of Bedrooms\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_rooms, y = sale_price, fill = factor(char_rooms))) +\n        scale_x_continuous(n.breaks = 20) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Number of Rooms and Sale Price \\nin Cook County, IL\", \n            x = \"Number of Rooms\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_fbath + char_hbath * 0.5, y = sale_price, fill = factor(char_fbath + char_hbath * 0.5))) +\n        scale_x_continuous(n.breaks = 20) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Total Number of Baths and Sale Price \\nin Cook County, IL\", \n            x = \"Total Number of Baths\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")"
  },
  {
    "objectID": "posts/cook_part_1/index.html#use-cmfproperty-to-conduct-a-sales-ratio-study-across-the-relevant-time-period",
    "href": "posts/cook_part_1/index.html#use-cmfproperty-to-conduct-a-sales-ratio-study-across-the-relevant-time-period",
    "title": "Cook County Property Assessment - Part 1",
    "section": "",
    "text": "Let’s get our data into a format that the cmfproperty package can use.\n\n\nCode\nlibrary(cmfproperty)\n\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"../data/cook.sqlite\")\n\nsfh_sales_cmf &lt;- sfh_sales %&gt;% \n    select(pin, year, sale_price, doc_no) %&gt;%\n    distinct(doc_no, .keep_all = TRUE) %&gt;%\n    select(-doc_no) %&gt;%\n    filter(as.numeric(sale_price) &gt; 2500)\n\nassessments_cmf &lt;- tbl(con, \"assessments\") %&gt;%\n    collect() %&gt;%\n    select(pin, tax_year, certified_tot)\n\nsale_assess_cmf &lt;- sfh_sales_cmf %&gt;% \n    left_join(assessments_cmf, by = join_by(pin, year == tax_year)) %&gt;% \n    rename(PIN = pin, SALE_YEAR = year, SALE_PRICE = sale_price, ASSESSED_VALUE = certified_tot) %&gt;%\n    mutate(ASSESSED_VALUE = 10 * ASSESSED_VALUE)\n\nratios &lt;- reformat_data(sale_assess_cmf,\n    sale_col = \"SALE_PRICE\",\n    assessment_col = \"ASSESSED_VALUE\",\n    sale_year_col = \"SALE_YEAR\")\n\nstats &lt;- calc_iaao_stats(ratios)\n\n\nOverall, we can see that at every sale price decile, single family homes are underassessed compared to their true sale price. However, the degree to which single family homes are underassessed is not equal. Regardless of efforts of the county, it is clear that in 2023 (for the months of Jan-Sep), houses within the lowest deciles tend to be assessed at higher ratios to their true sales price. The overall picture from 2021 to Sep 2023 is more enocouraging, but nevertheless the lowest decile tends to be assessed at higher rates than all other deciles and the 2nd to 5th lowest deciles seem to be asssed at lower rates than the higher deciles.\n\nBinned ScatterPercent AssessedCoefficient of DispersionPrice-Related DifferentialCoefficient of Price-Related Bias\n\n\n\n\nCode\nbinned &lt;- binned_scatter(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nknitr::asis_output(htmltools::htmlPreserve(binned[[1]]))\n\nbinned[[2]]\n\n\n\n\n\n\n\n\n\nIn 2023, the most expensive homes (the top decile) were assessed at 76.2% of their value and the least expensive homes (the bottom decile) were assessed at 93.1%. In other words, the least expensive homes were assessed at 1.22 times the rate applied to the most expensive homes. Across our sample from 2021 to 2023, the most expensive homes were assessed at 77.4% of their value and the least expensive homes were assessed at 84.6%, which is 1.09 times the rate applied to the most expensive homes.\n\n\n\n\n\n\nCode\npct_over &lt;- pct_over_under(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nknitr::asis_output(htmltools::htmlPreserve(pct_over[[1]]))\n\npct_over[[2]]\n\n\n\n\n\n\n\n\n\nIn Cook County, IL, 58% of the lowest value homes are overassessed and 52% of the highest value homes are overassessed.\n\n\n\n\n\n\nCode\niaao_rslt &lt;- iaao_graphs(stats,\n    ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, Illinois\")\n\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[1]]))\n\niaao_rslt[[2]]\n\n\n\n\n\n\n\n\n\nFor 2023, the COD in Cook County, Illinois was 19.6 which did not meet the IAAO standard for uniformity.\n\n\n\n\n\n\nCode\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[3]]))\n\niaao_rslt[[4]]\n\n\n\n\n\n\n\n\n\nIn 2023, the PRD in  Cook County, Illinois, was 1.074 which does not meet  the IAAO standard for vertical equity.\n\n\n\n\n\n\nCode\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[5]]))\n\niaao_rslt[[6]]\n\n\n\n\n\n\n\n\n\nIn 2023, the PRB in Cook County, Illinois was 0.004 which indicates that sales ratios increase by 0.4% when home values double. This meets the IAAO standard."
  },
  {
    "objectID": "posts/cook_part_1/index.html#explore-trends-and-relationships-with-property-sales-using-simple-regressions",
    "href": "posts/cook_part_1/index.html#explore-trends-and-relationships-with-property-sales-using-simple-regressions",
    "title": "Cook County Property Assessment - Part 1",
    "section": "",
    "text": "Let’s evaluate a couple different linear models (linear models were chosen simply because of the lower computing power necessary to train them). First, we’ll split our data.\n\n\nCode\nlibrary(tidymodels) \ntidymodels_prefer()\n\nset.seed(1)\nsplit &lt;- initial_split(sfh_characteristics)\ntrain_set &lt;- training(split)\ntest_set &lt;- testing(split)\n\nset.seed(2)\ntrain_resamples &lt;- bootstraps(train_set)\n\n\nWe’ll preprocess our data.\n\n\nCode\nbasic_rec &lt;- recipe(sale_price ~ char_yrblt + char_bldg_sf + char_land_sf + char_beds + char_rooms + char_fbath + char_hbath + township_code, data = sfh_characteristics) %&gt;% \n    step_mutate(years_old = 2023 - char_yrblt, role = \"predictor\") %&gt;%\n    remove_role(char_yrblt, old_role = \"predictor\") %&gt;%\n    step_string2factor(township_code) %&gt;% \n    step_naomit(all_predictors()) %&gt;% \n    step_novel(all_nominal_predictors()) %&gt;%\n    step_dummy(all_nominal_predictors()) %&gt;%\n    step_zv(all_predictors())\n\nnormalized_rec &lt;- basic_rec %&gt;% \n   step_normalize(all_predictors())\n\n\nSave the specifications of our models.\n\n\nCode\nols_spec &lt;- linear_reg() %&gt;% \n    set_engine(\"lm\") %&gt;%\n    set_mode(\"regression\")\n\nridge_spec &lt;- linear_reg(penalty = tune(), mixture = 0) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\nlasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\nenet_spec &lt;- linear_reg(penalty = tune(), mixture = tune()) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\n\nCreate our workflows.\n\n\nCode\nall_workflows &lt;- workflow_set(\n    preproc = list(normalize = normalized_rec),\n    models = list( \n        ols = ols_spec,\n        ridge = ridge_spec,\n        lasso = lasso_spec,\n        enet = enet_spec))\n\n\nRun our models.\n\n\nCode\nctrl_grid &lt;- control_grid(\n    save_pred = TRUE,\n    save_workflow = TRUE)\n\nres_grid &lt;- all_workflows %&gt;% \n    workflow_map(\n        resamples = train_resamples, \n        grid = 20, \n        control = ctrl_grid,\n        metrics = metric_set(rmse, rsq, ccc),\n        verbose = TRUE)\n\n\nFit our best model (Elastic Net).\n\n\nCode\nres_ranks &lt;- res_grid %&gt;% \n    rank_results('rmse') %&gt;% \n    filter(.metric == 'rmse') %&gt;%\n    select(wflow_id, model, .config, rmse = mean, rank) %&gt;% \n    group_by(wflow_id) %&gt;% \n    slice_min(rank, with_ties = FALSE) %&gt;% \n    ungroup() %&gt;% \n    arrange(rank)\n\nwflow_id_best &lt;- res_ranks %&gt;% \n    slice_min(rank, with_ties = FALSE) %&gt;% \n    pull(wflow_id)\n\nwf_best &lt;- res_grid %&gt;% \n    extract_workflow_set_result(wflow_id_best) %&gt;% \n    select_best(metric = 'rmse')\n\nfit_best &lt;- res_grid %&gt;% \n    extract_workflow(wflow_id_best) %&gt;% \n    finalize_workflow(wf_best) %&gt;% \n    last_fit(split = split)\n\n\nLet’s look at how well our model performs\n\n\nCode\ntrain_fit &lt;- res_grid %&gt;% \n    extract_workflow(wflow_id_best) %&gt;%\n    finalize_workflow(wf_best) %&gt;% \n    fit(data = train_set)\n\ntest_augment &lt;- augment(train_fit, test_set)\n\n\n\n\nCode\nmape(test_augment, truth = sale_price, estimate = .pred) %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nmape\nstandard\n434.6188\n\n\n\n\n\nCode\nrmse(test_augment, truth = sale_price, estimate = .pred) %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n264690.7\n\n\n\n\n\nIt looks like our model underestimates higher sale price homes. This would make our model regressive, which is concerning.\n\n\nCode\nggplot(test_augment, aes(x = sale_price, y = sale_price - .pred)) +\n    geom_point() +\n    labs(title = \"Elastic Net Residuals and Sale Price in Cook County, IL\", \n        x = \"Sale Price\", \n        y = \"Residuals\")\n\n\n\n\n\n\n\n\n\nLet’s see what variables have the largest impact on sale_price.\nNotice that building square feet seems to have the largest impact on the sale price. This makes implicit sense because larger single family homes tend to sell for more. We can also see that certain townships (ex: New Trier, Lake View, North Chicago) can have large impacts on the sale price of single family homes.\nAlthough our exploratory data analysis indicated that the number of years old a single family home was and how much land it has was associated with changes in sale prices within certain ranges it seems that the model was still able to pick up on some association.\nInterestingly, the number of beds that a single family home has was only the fifth strongest non-township predictor within this model. My guess is that this is because there is some multicolinearity between it and building square feet and number of full baths (two of our strongest non-township predictors). Elastic net takes some characteristics from ridge regression which means that it may shrink coefficients for parameters that exibit multicollinearity. In the future, we should take some caution to address concerns that may stem out of the fact that some of our parameters may exhibit multicollinearity.\n\n\nCode\nfit_best %&gt;%\n    extract_fit_parsnip() %&gt;%\n    tidy() %&gt;% \n    arrange(desc(abs(estimate))) %&gt;%\n    select(-penalty) %&gt;%\n    knitr::kable()\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n411430.1509\n\n\nchar_bldg_sf\n173102.1930\n\n\ntownship_code_X23\n122590.9790\n\n\ntownship_code_X73\n100464.1254\n\n\ntownship_code_X74\n98948.7028\n\n\nchar_fbath\n57515.9458\n\n\ntownship_code_X71\n44273.8193\n\n\ntownship_code_X77\n40171.8266\n\n\ntownship_code_X25\n37585.7469\n\n\ntownship_code_X17\n37127.8833\n\n\nyears_old\n-36310.3012\n\n\ntownship_code_X32\n-29412.3966\n\n\ntownship_code_X37\n-26423.4514\n\n\nchar_land_sf\n25928.7813\n\n\ntownship_code_X12\n-24590.2254\n\n\nchar_beds\n-23844.3942\n\n\ntownship_code_X27\n23571.0122\n\n\ntownship_code_X21\n22396.3105\n\n\ntownship_code_X22\n18702.2171\n\n\ntownship_code_X24\n18433.0435\n\n\ntownship_code_X33\n17375.9446\n\n\ntownship_code_X13\n-15277.9551\n\n\nchar_hbath\n13864.3441\n\n\ntownship_code_X28\n-13663.1957\n\n\ntownship_code_X70\n-11151.1800\n\n\ntownship_code_X18\n-10018.7998\n\n\ntownship_code_X16\n9804.5747\n\n\ntownship_code_X75\n9622.6161\n\n\ntownship_code_X26\n9527.2867\n\n\ntownship_code_X38\n8921.9784\n\n\ntownship_code_X39\n-7649.2568\n\n\ntownship_code_X76\n7577.2306\n\n\ntownship_code_X30\n-7055.2081\n\n\ntownship_code_X34\n6767.3835\n\n\ntownship_code_X72\n-6149.2097\n\n\ntownship_code_X19\n-5829.4375\n\n\ntownship_code_X14\n-5619.0157\n\n\ntownship_code_X31\n5335.3295\n\n\ntownship_code_X20\n5057.9514\n\n\nchar_rooms\n-3085.1155\n\n\ntownship_code_X29\n-2818.9065\n\n\ntownship_code_X11\n2720.7418\n\n\ntownship_code_X35\n-464.7437\n\n\ntownship_code_X36\n-291.2669\n\n\ntownship_code_X15\n0.0000"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PA470",
    "section": "",
    "text": "Coding Warmup 4\n\n\n\n\n\n\nCoding Warmup\n\n\n\n\n\n\n\n\n\nFeb 15, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCook County Property Assessment - Part 1\n\n\n\n\n\n\nCook County Assessments\n\n\n\n\n\n\n\n\n\nFeb 8, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCoding Warmup 3\n\n\n\n\n\n\nCoding Warmup\n\n\n\n\n\n\n\n\n\nFeb 1, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCoding Warmup 2\n\n\n\n\n\n\nCoding Warmup\n\n\n\n\n\n\n\n\n\nJan 25, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html",
    "href": "posts/coding_warmup_4/index.html",
    "title": "Coding Warmup 4",
    "section": "",
    "text": "We are going to use a toy dataset called bivariate. There is a training, testing, and validation dataset provided.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ndata(bivariate)\n\nggplot(bivariate_train, aes(x = A, y = B, color = Class)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nUse logistic_reg and glm to make a classification model of Class ~ A * B. Then use tidy and glance to see some summary information on our model. Anything stand out to you?\n\n\nCode\nlog_model &lt;- logistic_reg() %&gt;%\n    set_engine('glm') %&gt;%\n    set_mode('classification') %&gt;%\n    fit(Class ~ A * B, data = bivariate_train)\n\nlog_model %&gt;% tidy()\n\n\n# A tibble: 4 × 5\n  term          estimate  std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  0.115     0.404          0.284 7.76e- 1\n2 A            0.00433   0.000434       9.97  2.01e-23\n3 B           -0.0553    0.00633       -8.74  2.32e-18\n4 A:B         -0.0000101 0.00000222    -4.56  5.04e- 6\n\n\nCode\nlog_model %&gt;% glance()\n\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         1329.    1008  -549. 1106. 1126.    1098.        1005  1009"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-a",
    "href": "posts/coding_warmup_4/index.html#part-a",
    "title": "Coding Warmup 4",
    "section": "",
    "text": "We are going to use a toy dataset called bivariate. There is a training, testing, and validation dataset provided.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ndata(bivariate)\n\nggplot(bivariate_train, aes(x = A, y = B, color = Class)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nUse logistic_reg and glm to make a classification model of Class ~ A * B. Then use tidy and glance to see some summary information on our model. Anything stand out to you?\n\n\nCode\nlog_model &lt;- logistic_reg() %&gt;%\n    set_engine('glm') %&gt;%\n    set_mode('classification') %&gt;%\n    fit(Class ~ A * B, data = bivariate_train)\n\nlog_model %&gt;% tidy()\n\n\n# A tibble: 4 × 5\n  term          estimate  std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  0.115     0.404          0.284 7.76e- 1\n2 A            0.00433   0.000434       9.97  2.01e-23\n3 B           -0.0553    0.00633       -8.74  2.32e-18\n4 A:B         -0.0000101 0.00000222    -4.56  5.04e- 6\n\n\nCode\nlog_model %&gt;% glance()\n\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         1329.    1008  -549. 1106. 1126.    1098.        1005  1009"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-b",
    "href": "posts/coding_warmup_4/index.html#part-b",
    "title": "Coding Warmup 4",
    "section": "Part B",
    "text": "Part B\nUse augment to get predictions. Look at the predictions.\n\n\nCode\nlog_model %&gt;% augment(bivariate_test)\n\n\n# A tibble: 710 × 6\n   .pred_class .pred_One .pred_Two     A     B Class\n   &lt;fct&gt;           &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n 1 One           0.730      0.270   742.  68.8 One  \n 2 Two           0.491      0.509   709.  50.4 Two  \n 3 One           0.805      0.195  1006.  89.9 One  \n 4 Two           0.431      0.569  1983. 112.  Two  \n 5 Two           0.169      0.831  1698.  81.0 Two  \n 6 One           0.900      0.0996  948.  98.9 One  \n 7 One           0.521      0.479   751.  54.8 One  \n 8 Two           0.347      0.653  1254.  72.2 Two  \n 9 Two           0.00568    0.994  4243. 136.  One  \n10 One           0.910      0.0898  713.  88.2 One  \n# ℹ 700 more rows"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-c",
    "href": "posts/coding_warmup_4/index.html#part-c",
    "title": "Coding Warmup 4",
    "section": "Part C",
    "text": "Part C\nVisually inspect the predictions using the code below\n\n\nCode\npreds &lt;- expand.grid(\n    A = seq(min(bivariate_train$A), max(bivariate_train$A), length.out = 100),\n    B = seq(min(bivariate_train$B), max(bivariate_train$B), length.out = 100)) %&gt;%\n    augment(log_model, .)\n\nggplot(preds, aes(x = A, y = B)) +\n    geom_contour(aes(z = .pred_One), breaks = .5, col = \"black\") + \n    geom_point(data = bivariate_val, aes(col = Class), alpha = 0.3)"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-d",
    "href": "posts/coding_warmup_4/index.html#part-d",
    "title": "Coding Warmup 4",
    "section": "Part D",
    "text": "Part D\nEvaluate your model using the following functions (which dataset(s) should you use to do this train, test, or validation). See if you can provide a basic interpretation of the measures.\n\nroc_auc\naccuracy\nroc_curve and autoplot\nf_meas\n\n\n\nCode\nval_preds &lt;- log_model %&gt;% \n    augment(bivariate_val)\n\nmetrics &lt;- list(\n    val_preds %&gt;%\n        roc_auc(Class, .pred_One),\n    val_preds %&gt;%\n        accuracy(Class, .pred_class),\n    val_preds %&gt;%\n        f_meas(Class, .pred_class))\n\nmetrics %&gt;% bind_rows()\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc  binary         0.790\n2 accuracy binary         0.76 \n3 f_meas   binary         0.827\n\n\n\n\nCode\nval_preds %&gt;% \n    roc_curve(Class, .pred_One) %&gt;%\n    autoplot()"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-e",
    "href": "posts/coding_warmup_4/index.html#part-e",
    "title": "Coding Warmup 4",
    "section": "Part E",
    "text": "Part E\nRecall Table 8.4 from the textbook. If necessary, class one can be positive and class two can be negative. Using the output from conf_mat, visually verify you know how to calculate the following:\n\nTrue Positive Rate (TPR), Sensitivity, or Recall\nTrue Negative Rate (TNR) or Specificity\nFalse Positive Rate, Type I error\nFalse Negative Rate (FNR), Type II error\nPositive Predictive Value (PPV) or Precision\n\n\n\nCode\nval_preds %&gt;% \n    conf_mat(truth = Class, estimate = .pred_class)\n\n\n          Truth\nPrediction One Two\n       One 172  42\n       Two  30  56"
  },
  {
    "objectID": "posts/coding_warmup_2/index.html",
    "href": "posts/coding_warmup_2/index.html",
    "title": "Coding Warmup 2",
    "section": "",
    "text": "Create an RMarkdown file to use for this assignment. Use html as the output and change at least one option in the yaml. Complete the rest of the assignment using markdown and chunks to create readable code and output."
  },
  {
    "objectID": "posts/coding_warmup_2/index.html#part-1",
    "href": "posts/coding_warmup_2/index.html#part-1",
    "title": "Coding Warmup 2",
    "section": "",
    "text": "Create an RMarkdown file to use for this assignment. Use html as the output and change at least one option in the yaml. Complete the rest of the assignment using markdown and chunks to create readable code and output."
  },
  {
    "objectID": "posts/coding_warmup_2/index.html#part-2",
    "href": "posts/coding_warmup_2/index.html#part-2",
    "title": "Coding Warmup 2",
    "section": "Part 2",
    "text": "Part 2\nUsing censusreporter.org, pick an American Community Survey variable and a geographic area and division (e.g. nationwide and states, statewide and county, county and tracts).\nUsing tigris, tidycensus, and leaflet (encouraged, or your favorite R package for maps), map the variable over your chosen geographic divisions. Select an appropriate pallete, and consider adding popup labels. Write a few sentences describing your map in Markdown\n\n\nCode\nlibrary(leaflet)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tidycensus)\n\nacs_il20 &lt;- get_acs(geography = \"tract\", \n    variables = c(\n        medincome = \"B19013_001\",\n        totalpop = \"B02001_001\",\n        white_nh = \"B03002_003\",\n        black_nh = \"B03002_004\",\n        aian_nh = \"B03002_005\",\n        asian_nh = \"B03002_005\",\n        hispanic = \"B03002_012\"),\n    state = \"IL\", \n    year = 2020) %&gt;%\n    pivot_wider(names_from = variable, values_from = c(estimate, moe)) %&gt;%\n    select(GEOID, starts_with(\"estimate\"))\n\ntracts_il20 &lt;- tigris::tracts(state = \"IL\", year = 2020) %&gt;% \n    st_transform(4326)\n\nacs_il20 &lt;- tracts_il20 %&gt;%\n    left_join(acs_il20)\n\nchi20 &lt;- tigris::county_subdivisions(state = \"IL\", county = \"Cook\", year = 2020) %&gt;%\n    filter(NAME == \"Chicago\") %&gt;% \n    st_transform(4326)\n\nacs_chi20 &lt;- acs_il20 %&gt;%\n    st_intersection(chi20)\n\n\n\n\nCode\npal &lt;- colorQuantile(\"Greens\", \n    domain = acs_chi20$estimate_medincome,\n    n = 5)\n\nleaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n        data = acs_chi20,\n        fillColor = ~ pal(estimate_medincome),\n        fillOpacity = 0.7,\n        color = \"Black\",\n        weight = 0.5,\n        opacity = 0.5,\n        highlightOptions = highlightOptions(\n            weight = 2,\n            color = \"Black\",\n            fillOpacity = 1,\n            bringToFront = TRUE),\n        label = sprintf(\n            \"&lt;strong&gt;Tract %s&lt;/strong&gt;&lt;br&gt;Median Income: %s&lt;br/&gt;\",\n            acs_chi20$GEOID,\n            scales::dollar(acs_chi20$estimate_medincome)) %&gt;% \n                lapply(htmltools::HTML),\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"12px\",\n            direction = \"auto\")) %&gt;%\n    addLegend(\n        pal = pal,\n        values = acs_chi20$estimate_medincome,\n        opacity = 0.7,\n        title = NULL,\n        position = \"bottomright\",\n        na.label = \"Insufficient Data\")"
  },
  {
    "objectID": "posts/coding_warmup_2/index.html#part-3",
    "href": "posts/coding_warmup_2/index.html#part-3",
    "title": "Coding Warmup 2",
    "section": "Part 3",
    "text": "Part 3\nConsider expanding the divvy example from class with the following:\n\napproximate trip distance from start/end location\n\nshow some summary stats by hour or day of week or community area or “rideable” type\n\nconstruct a regression with some combination of the above\n\n\n\nCode\ntemp &lt;- tempfile()\ndownload.file(\"https://divvy-tripdata.s3.amazonaws.com/202307-divvy-tripdata.zip\", temp)\ndivvy202307 &lt;- read_csv(unz(temp, \"202307-divvy-tripdata.csv\"))\nunlink(temp)\n\n\n\n\nCode\nlibrary(sfheaders)\nlibrary(units)\n\ndivvy202307_sf &lt;- divvy202307 %&gt;%\n    filter(!is.na(end_lat)) %&gt;%\n    filter(start_lng != end_lng & start_lat != end_lat) %&gt;%\n    pivot_longer(c(start_lat, start_lng, end_lat, end_lng), names_to = c(\"Position\", \".value\"), names_pattern = \"(.*)_(.*)\") %&gt;%\n    sf_linestring(linestring_id = \"ride_id\", x = \"lng\", y = \"lat\", keep = TRUE) %&gt;%\n    st_set_crs(4326) %&gt;%\n    st_transform(26971) %&gt;%\n    mutate(edistance = set_units(st_length(geometry), mi)) %&gt;%\n    mutate(start_time = force_tz(started_at, tzone = \"America/Chicago\")) %&gt;%\n    mutate(end_time = force_tz(ended_at, tzone = \"America/Chicago\")) %&gt;%\n    mutate(duration_time = end_time - start_time)\n\n\n\n\nCode\ndivvy202307_sf %&gt;%\n    st_drop_geometry() %&gt;%\n    ggplot() + \n        geom_density(aes(x = edistance, fill = rideable_type, y = after_stat(count)), alpha = 0.5) + \n        labs(x = 'Euclidian Trip Distance',\n            y = 'Rides',\n            title = 'Divvy Euclidian Distances - July 2023') +\n        scale_fill_discrete(name = \"Ride Type\",\n            labels = c(\"Classic\", \"Docked\", \"Electric\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndivvy202307_sf %&gt;%\n    st_drop_geometry() %&gt;%\n    ggplot() + \n        geom_density(aes(x = duration_time, fill = rideable_type, y = after_stat(count)), alpha = 0.5) + \n        xlim(0, 7200) +\n        labs(x = 'Trip Duration [sec]',\n            y = 'Rides',\n            title = 'Divvy Trip Duration - July 2023') +\n        scale_fill_discrete(name = \"Ride Type\",\n            labels = c(\"Classic\", \"Docked\", \"Electric\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndivvy202307_sf %&gt;%\n    st_drop_geometry() %&gt;%\n    mutate(day = wday(started_at, label = TRUE)) %&gt;%\n    ggplot() +\n        geom_bar(aes(day, fill = rideable_type)) +\n        labs(x = 'Day of the Week',\n            y = 'Rides',\n            title = 'Divvy Trips by Day of the Week - July 2023') +\n        scale_fill_discrete(name = \"Ride Type\",\n            labels = c(\"Classic\", \"Docked\", \"Electric\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndivvy202307_sf %&gt;%\n    st_drop_geometry() %&gt;%\n    mutate(day = wday(started_at, label = TRUE)) %&gt;%\n    mutate(hour = hour(started_at)) %&gt;%\n    ggplot() +\n        geom_bar(aes(hour, fill = rideable_type)) +\n        labs(x = 'Hour',\n            y = 'Rides',\n            title = 'Divvy Trips by Hour for Each Day of the Week - July 2023') +\n        scale_fill_discrete(name = \"Ride Type\",\n            labels = c(\"Classic\", \"Docked\", \"Electric\")) +\n        facet_grid(rows = vars(day))"
  },
  {
    "objectID": "posts/coding_warmup_2/index.html#part-4",
    "href": "posts/coding_warmup_2/index.html#part-4",
    "title": "Coding Warmup 2",
    "section": "Part 4",
    "text": "Part 4\nGrab another variable for the same geographic area and divisions with the intent of exploring correlation between this variable and the one selected in the part 2. Replicate some of the analysis from Tidy Modeling Sec 3.1.\n\n\nCode\nacs_il20 %&gt;%\n    filter(str_starts(GEOID, \"17031\")) %&gt;%\n    mutate(white_nh_pct = estimate_white_nh / estimate_totalpop) %&gt;%\n    ggplot(aes(x = white_nh_pct, y = estimate_medincome)) +\n        geom_point(alpha=.2) +\n        geom_smooth(method = lm) +\n        theme_bw() +\n        scale_y_continuous(labels = scales::dollar_format()) +\n        scale_x_continuous(labels = scales::percent_format()) +\n        labs(x='Percent White Non-Hispanic', y='Median Income', title='Median Income and Percent White Non-Hispanic by Census Tract \\nin Cook County')\n\n\n\n\n\n\n\n\n\n\n\nCode\nlm_white_medincome &lt;- acs_il20 %&gt;%\n    filter(str_starts(GEOID, \"17031\")) %&gt;%\n    mutate(white_nh_pct = estimate_white_nh / estimate_totalpop) %&gt;%\n    lm(estimate_medincome ~ white_nh_pct, data = .)\n\nsummary(lm_white_medincome)\n\n\n\nCall:\nlm(formula = estimate_medincome ~ white_nh_pct, data = .)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-80818 -16432  -1898  12285 133946 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     36250       1164   31.15   &lt;2e-16 ***\nwhite_nh_pct    90189       2337   38.59   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25860 on 1321 degrees of freedom\n  (9 observations deleted due to missingness)\nMultiple R-squared:  0.5299,    Adjusted R-squared:  0.5295 \nF-statistic:  1489 on 1 and 1321 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\nplot(lm_white_medincome)"
  }
]
[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This repository houses the code submitted by me (Ryan Zomorrodi) for the Spring 2024 PA470 Course."
  },
  {
    "objectID": "posts/coding_warmup_3/index.html",
    "href": "posts/coding_warmup_3/index.html",
    "title": "Coding Warmup 3",
    "section": "",
    "text": "Exercise 7.2.3 from Data Science for Public Policy. Data can be found here.\n\nGraph and regress sale price against gross square feet interpret the results\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(scales)\n\nsales &lt;- read_csv(\"https://raw.githubusercontent.com/DataScienceForPublicPolicy/diys/main/data/home_sales_nyc.csv\")\n\nsales %&gt;%\n    ggplot(aes(x = gross.square.feet, y = sale.price)) +\n        geom_point(alpha = 0.1, size = 1, color = \"springgreen4\") +\n        geom_smooth(method = \"lm\", linewidth = 1, colour = \"black\") + \n        scale_x_continuous(labels = label_comma()) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Sale Price and Gross Square Feet of House Sales in New York City \", \n            x = \"Gross Square Feet\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\nCode\nlinear_reg() %&gt;% \n    set_engine(\"lm\") %&gt;%\n    set_mode(\"regression\") %&gt;%\n    fit(sale.price ~ gross.square.feet, data = sales) %&gt;%\n    extract_fit_engine() %&gt;%\n    summary()\n\n\n\nCall:\nstats::lm(formula = sale.price ~ gross.square.feet, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1700116  -212264   -44958   138638  8661923 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -42584.389  11534.260  -3.692 0.000223 ***\ngross.square.feet    466.176      7.097  65.684  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 463900 on 12666 degrees of freedom\nMultiple R-squared:  0.2541,    Adjusted R-squared:  0.254 \nF-statistic:  4314 on 1 and 12666 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/coding_warmup_3/index.html#part-1",
    "href": "posts/coding_warmup_3/index.html#part-1",
    "title": "Coding Warmup 3",
    "section": "",
    "text": "Exercise 7.2.3 from Data Science for Public Policy. Data can be found here.\n\nGraph and regress sale price against gross square feet interpret the results\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(scales)\n\nsales &lt;- read_csv(\"https://raw.githubusercontent.com/DataScienceForPublicPolicy/diys/main/data/home_sales_nyc.csv\")\n\nsales %&gt;%\n    ggplot(aes(x = gross.square.feet, y = sale.price)) +\n        geom_point(alpha = 0.1, size = 1, color = \"springgreen4\") +\n        geom_smooth(method = \"lm\", linewidth = 1, colour = \"black\") + \n        scale_x_continuous(labels = label_comma()) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Sale Price and Gross Square Feet of House Sales in New York City \", \n            x = \"Gross Square Feet\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\nCode\nlinear_reg() %&gt;% \n    set_engine(\"lm\") %&gt;%\n    set_mode(\"regression\") %&gt;%\n    fit(sale.price ~ gross.square.feet, data = sales) %&gt;%\n    extract_fit_engine() %&gt;%\n    summary()\n\n\n\nCall:\nstats::lm(formula = sale.price ~ gross.square.feet, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1700116  -212264   -44958   138638  8661923 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -42584.389  11534.260  -3.692 0.000223 ***\ngross.square.feet    466.176      7.097  65.684  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 463900 on 12666 degrees of freedom\nMultiple R-squared:  0.2541,    Adjusted R-squared:  0.254 \nF-statistic:  4314 on 1 and 12666 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/coding_warmup_3/index.html#part-2",
    "href": "posts/coding_warmup_3/index.html#part-2",
    "title": "Coding Warmup 3",
    "section": "Part 2",
    "text": "Part 2\nReproduce this figure from tidymodels 3.3\n\n\n\n\n  \n\n\n\n  \n    \n  \n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-1.0\n-0.5\n0.0\n0.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwt\ncyl\ndisp\nhp\ncarb\nqsec\ngear\nam\nvs\ndrat\nCorrelation with mpg\n\n\nCorr Plot 1\n\n\nwith the data from Part 1 replacing mpg with sale price for numeric variables.\n\n\nCode\nlibrary(broom)\n\nsales %&gt;%\n    select(where(is.numeric), -c(sale.price, borough, zip.code)) %&gt;%\n    map(function(col) cor.test(col, sales$sale.price)) %&gt;%\n    map_dfr(tidy, .id = \"predictor\") %&gt;% \n    ggplot(aes(y = fct_reorder(predictor, estimate))) + \n        geom_point(aes(x = estimate)) + \n        geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = .1) +\n        labs(title = \"Correlation of Predictors with Sale Price\", \n            x = \"Correlation\", \n            y = \"Predictor\")"
  },
  {
    "objectID": "posts/coding_warmup_3/index.html#part-3",
    "href": "posts/coding_warmup_3/index.html#part-3",
    "title": "Coding Warmup 3",
    "section": "Part 3",
    "text": "Part 3\nExercise 7.4.5\nEstimate a set of regressions, evaluate the pros and cons of each, and select the “best” specification.\nCreate and analyze the following four models from the textbook and one of your own:\n\nModel 1 (mod1) regresses sales prices and building area\nModel 2 (mod2) adds borough as a categorical variable\nModel 3 (mod3) incorporates an interaction to estimate borough-specific slopes for building area\nModel 4 (mod4) adds land area\n\nThis is obviously a very rudementary analysis, but it looks like model 4 has the lowest AIC and BIC of our 5 models. At a later point, we should conduct a more robust analysis of these models.\nAs with all models, the inclusion of certain predictors into our model requires some contemplation of the bias-variance tradeoff. If we were to simply analyse the RMSE of our models, we will always find that the model with all predictors will have the lowest RMSE. AIC on the other hand penalizes models with more variables and should give us a decent idea if the variance we may be adding is worth the bias we may be reducing.\n\n\nCode\nglm_spec &lt;- linear_reg() %&gt;% \n    set_engine(\"glm\") %&gt;%\n    set_mode(\"regression\")\n\nmod1_rec &lt;- recipe(sale.price ~ gross.square.feet, data = sales)\n\nmod2_rec &lt;- recipe(sale.price ~ gross.square.feet + borough, data = sales) %&gt;%\n    step_mutate(borough = factor(borough))\n\nmod3_rec &lt;- recipe(sale.price ~ gross.square.feet + borough, data = sales) %&gt;%\n    step_mutate(borough = factor(borough)) %&gt;%\n    step_interact(terms = ~ borough:gross.square.feet)\n\nmod4_rec &lt;- recipe(sale.price ~ gross.square.feet + borough + land.square.feet, data = sales) %&gt;%\n    step_mutate(borough = factor(borough)) %&gt;%\n    step_interact(terms = ~ borough:gross.square.feet)\n\nmod5_rec &lt;- recipe(sale.price ~ gross.square.feet + borough + age, data = sales) %&gt;%\n    step_mutate(borough = factor(borough))\n\nlist(mod1_rec, mod2_rec, mod3_rec, mod4_rec, mod5_rec) %&gt;% \n    map(\n        function (rec) {\n            workflow() %&gt;%\n                add_recipe(rec) %&gt;%\n                add_model(glm_spec) %&gt;%\n                fit(data = sales) %&gt;% \n                glance()\n        }) %&gt;%\n    bind_rows(.id = \"id\") %&gt;%\n    mutate(id = str_c(\"mod\", id)) %&gt;%\n    arrange(AIC)\n\n\n# A tibble: 5 × 9\n  id    null.deviance df.null   logLik     AIC    BIC deviance df.residual  nobs\n  &lt;chr&gt;         &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1 mod4        3.65e15   12667 -180884. 361791. 3.62e5  1.87e15       12657 12668\n2 mod3        3.65e15   12667 -181071. 362164. 3.62e5  1.93e15       12658 12668\n3 mod5        3.65e15   12667 -181709. 363433. 3.63e5  2.13e15       12661 12668\n4 mod2        3.65e15   12667 -181710. 363434. 3.63e5  2.13e15       12662 12668\n5 mod1        3.65e15   12667 -183258. 366522. 3.67e5  2.73e15       12666 12668\n\n\n\n\nCode\nworkflow() %&gt;%\n    add_recipe(mod4_rec) %&gt;%\n    add_model(glm_spec) %&gt;%\n    fit(data = sales) %&gt;%\n    tidy()\n\n\n# A tibble: 11 × 5\n   term                           estimate std.error statistic  p.value\n   &lt;chr&gt;                             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                    720684.  191646.        3.76 1.70e- 4\n 2 gross.square.feet                1034.      56.5      18.3  9.89e-74\n 3 borough2                      -627822.  195168.       -3.22 1.30e- 3\n 4 borough3                     -1072863.  192860.       -5.56 2.71e- 8\n 5 borough4                      -589096.  192262.       -3.06 2.19e- 3\n 6 borough5                      -557855.  192464.       -2.90 3.76e- 3\n 7 land.square.feet                   35.7      1.83     19.5  1.63e-83\n 8 borough2_x_gross.square.feet     -864.      60.5     -14.3  7.56e-46\n 9 borough3_x_gross.square.feet     -292.      57.8      -5.04 4.70e- 7\n10 borough4_x_gross.square.feet     -756.      57.5     -13.2  2.91e-39\n11 borough5_x_gross.square.feet     -882.      57.7     -15.3  2.71e-52"
  },
  {
    "objectID": "posts/coding_warmup_3/index.html#part-4",
    "href": "posts/coding_warmup_3/index.html#part-4",
    "title": "Coding Warmup 3",
    "section": "Part 4",
    "text": "Part 4\nIn the class divvy example (see the lectures page for code/files), we had a lot of missing values in our data. We also didn’t have a very rigorous treatment of time/seasonality. Explore how impactful these issues are by creating a few different models and comparing the predictions using the workflows we saw from class in rsample (splitting data), parsnip (linear_reg, set_engine, set_mode, fit), yardstick (mape, rmse), and broom (augment).\nDue to time constraints, I chose not to do this problem rather that give a sub par response."
  },
  {
    "objectID": "posts/cook_part_4/index.html",
    "href": "posts/cook_part_4/index.html",
    "title": "Cook County Property Assessment - Part 4",
    "section": "",
    "text": "There are over 1.8 million parcels in Cook County, Illinois [1]. Each of these parcels is assessed every three years using three to five years of prior sales information [1]. For this analysis, we will take a look at single family home assessments within three of the 36 political townships: Lemont (19), Palos (30), Orland (28). Using data provided on the Cook County data portal, we will will create a model predicting the sale price of a property.\nThere exist several technical challenges with predicting sale prices of properties. 1) There exists a great degree of multicolinearity in the dataset due to the tendency for housing attributes to be associated with one another. 2) There are aspects of the home buying process that the assessor is not allowed to use as part of their assessment. Given these challenges, we we will attempt to do the best to evaluate several models applicability,\n\n\nWe have 4 inclusion criteria:\n\nYear - 2021, 2022, 2023\nClass - 202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278. These conform to single family homes\nTownship Code - 19 (Lemont), 30 (Palos), 28 (Orland)\nIs Multisale - No\n\n\n\nCode\nlibrary(arrow)\nlibrary(data.table)\nlibrary(dtplyr)\nlibrary(tidyverse)\n\nsfh2123_assessment &lt;-\n  open_csv_dataset(\"../data/20240217_Assessed_Values.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"township_name\", string()),\n      field(\"mailed_bldg\", int32()),\n      field(\"mailed_land\", int32()),\n      field(\"mailed_tot\", int32()),\n      field(\"certified_bldg\", int32()),\n      field(\"certified_land\", int32()),\n      field(\"certified_tot\", int32()),\n      field(\"board_bldg\", int32()),\n      field(\"board_land\", int32()),\n      field(\"board_tot\", int32()),\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_sales &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Sales.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"year\", int32()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"class\", string()),\n      field(\"sale_date\", string()),\n      field(\"is_mydec_date\", bool()),\n      field(\"sale_price\", int32()),\n      field(\"sale_document_num\", string()),\n      field(\"sale_deed_type\", string()),\n      field(\"mydec_deed_type\", string()),\n      field(\"sale_seller_name\", string()),\n      field(\"is_multisale\", bool()),\n      field(\"num_parcels_sale\", int32()),\n      field(\"sale_buyer_name\", string()),\n      field(\"sale_type\", string()),\n      field(\"sale_filter_same_sale_within_365\", bool()),\n      field(\"sale_filter_less_than_10k\", bool()),\n      field(\"sale_filter_deed_type\", bool())\n    )\n  ) %&gt;%\n  filter(year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\")) %&gt;%\n  filter(!is_multisale) \n\nsfh2123_characteristics &lt;- \n  open_csv_dataset(\"../data/20240217_Improvement_Characteristics.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"card_num\", string()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"proration_key_pin\", string()),\n      field(\"pin_proration_rate\", double()),\n      field(\"card_proration_rate\", double()),\n      field(\"cdu\", string()),\n      field(\"pin_is_multicard\", bool()),\n      field(\"pin_num_cards\", int32()),\n      field(\"pin_is_multiland\", bool()),\n      field(\"pin_num_landlines\", int32()),\n      field(\"year_built\", int32()),\n      field(\"building_sqft\", int32()),\n      field(\"land_sqft\", int32()),\n      field(\"num_bedrooms\", int32()),\n      field(\"num_rooms\", int32()),\n      field(\"num_full_baths\", int32()),\n      field(\"num_half_baths\", int32()),\n      field(\"num_fireplaces\", int32()),\n      field(\"type_of_residence\", string()),\n      field(\"construction_quality\", string()),\n      field(\"num_apartments\", string()),\n      field(\"attic_finish\", string()),\n      field(\"garage_attached\", string()),\n      field(\"garage_area_included\", string()),\n      field(\"garage_size\", string()),\n      field(\"garage_ext_wall_material\", string()),\n      field(\"attic_type\", string()),\n      field(\"basement_type\", string()),\n      field(\"ext_wall_material\", string()),\n      field(\"central_heating\", string()),\n      field(\"repair_condition\", string()),\n      field(\"basement_finish\", string()),\n      field(\"roof_material\", string()),\n      field(\"single_v_multi_family\", string()),\n      field(\"site_desirability\", string()),\n      field(\"num_commercial_units\", string()),\n      field(\"renovation\", string()),\n      field(\"recent_renovation\", bool()),\n      field(\"porch\", string()),\n      field(\"central_air\", string()),\n      field(\"design_plan\", string())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_universe &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Universe.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"pin10\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"triad_name\", string()),\n      field(\"triad_code\", string()),\n      field(\"township_name\", string()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"tax_district_code\", string()),\n      field(\"zip_code\", string()),\n      field(\"longitude\", double()),\n      field(\"latitude\", double()),\n      field(\"centroid_x_crs_3435\", double()),\n      field(\"centroid_y_crs_3435\", double()),\n      field(\"census_block_group_geoid\", string()),\n      field(\"census_block_geoid\", string()),\n      field(\"census_congressional_district_geoid\", string()),\n      field(\"census_county_subdivision_geoid\", string()),\n      field(\"census_place_geoid\", string()),\n      field(\"census_puma_geoid\", string()),\n      field(\"census_school_district_elementary_geoid\", string()),\n      field(\"census_school_district_secondary_geoid\", string()),\n      field(\"census_school_district_unified_geoid\", string()),\n      field(\"census_state_representative_geoid\", string()),\n      field(\"census_state_senate_geoid\", string()),\n      field(\"census_tract_geoid\", string()),\n      field(\"census_zcta_geoid\", string()),\n      field(\"census_data_year\", int32()),\n      field(\"census_acs5_congressional_district_geoid\", string()),\n      field(\"census_acs5_county_subdivision_geoid\", string()),\n      field(\"census_acs5_place_geoid\", string()),\n      field(\"census_acs5_puma_geoid\", string()),\n      field(\"census_acs5_school_district_elementary_geoid\", string()),\n      field(\"census_acs5_school_district_secondary_geoid\", string()),\n      field(\"census_acs5_school_district_unified_geoid\", string()),\n      field(\"census_acs5_state_representative_geoid\", string()),\n      field(\"census_acs5_state_senate_geoid\", string()),\n      field(\"census_acs5_tract_geoid\", string()),\n      field(\"census_acs5_data_year\", int32()),\n      field(\"board_of_review_district_num\", string()),\n      field(\"board_of_review_district_data_year\", int32()),\n      field(\"commissioner_district_num\", string()),\n      field(\"commissioner_district_data_year\", int32()),\n      field(\"judicial_district_num\", string()),\n      field(\"judicial_district_data_year\", int32()),\n      field(\"ward_num\", string()),\n      field(\"ward_chicago_data_year\", int32()),\n      field(\"ward_evanston_data_year\", int32()),\n      field(\"chicago_community_area_num\", string()),\n      field(\"chicago_community_area_name\", string()),\n      field(\"chicago_community_area_data_year\", int32()),\n      field(\"chicago_industrial_corridor_num\", string()),\n      field(\"chicago_industrial_corridor_name\", string()),\n      field(\"chicago_industrial_corridor_data_year\", int32()),\n      field(\"chicago_police_district_num\", string()),\n      field(\"chicago_police_district_data_year\", int32()),\n      field(\"coordinated_care_area_num\", string()),\n      field(\"coordinated_care_area_data_year\", int32()),\n      field(\"enterprise_zone_num\", string()),\n      field(\"enterprise_zone_data_year\", int32()),\n      field(\"industrial_growth_zone_num\", string()),\n      field(\"industrial_growth_zone_data_year\", int32()),\n      field(\"qualified_opportunity_zone_num\", string()),\n      field(\"qualified_opportunity_zone_data_year\", int32()),\n      field(\"flood_fema_sfha\", bool()),\n      field(\"flood_fema_data_year\", int32()),\n      field(\"flood_fs_factor\", int32()),\n      field(\"flood_fs_risk_direction\", int32()),\n      field(\"flood_fs_data_year\", int32()),\n      field(\"ohare_noise_contour_no_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_half_mile_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_data_year\", int32()),\n      field(\"airport_noise_dnl\", double()),\n      field(\"airport_noise_data_year\", string()),\n      field(\"school_elementary_district_geoid\", string()),\n      field(\"school_elementary_district_name\", string()),\n      field(\"school_secondary_district_geoid\", string()),\n      field(\"school_secondary_district_name\", string()),\n      field(\"school_unified_district_geoid\", string()),\n      field(\"school_unified_district_name\", string()),\n      field(\"school_year\", string()),\n      field(\"school_data_year\", int32()),\n      field(\"tax_municipality_num\", string()),\n      field(\"tax_municipality_name\", string()),\n      field(\"tax_school_elementary_district_num\", string()),\n      field(\"tax_school_elementary_district_name\", string()),\n      field(\"tax_school_secondary_district_num\", string()),\n      field(\"tax_school_secondary_district_name\", string()),\n      field(\"tax_school_unified_district_num\", string()),\n      field(\"tax_school_unified_district_name\", string()),\n      field(\"tax_community_college_district_num\", string()),\n      field(\"tax_community_college_district_name\", string()),\n      field(\"tax_fire_protection_district_num\", string()),\n      field(\"tax_fire_protection_district_name\", string()),\n      field(\"tax_library_district_num\", string()),\n      field(\"tax_library_district_name\", string()),\n      field(\"tax_park_district_num\", string()),\n      field(\"tax_park_district_name\", string()),\n      field(\"tax_sanitation_district_num\", string()),\n      field(\"tax_sanitation_district_name\", string()),\n      field(\"tax_special_service_area_num\", string()),\n      field(\"tax_special_service_area_name\", string()),\n      field(\"tax_tif_district_num\", string()),\n      field(\"tax_tif_district_name\", string()),\n      field(\"tax_districts_data_year\", int32()),\n      field(\"cmap_walkability_grid_id\", string()),\n      field(\"cmap_walkability_no_transit_score\", double()),\n      field(\"cmap_walkability_total_score\", double()),\n      field(\"cmap_walkability_data_year\", int32()),\n      field(\"subdivision_id\", string()),\n      field(\"subdivision_data_year\", int32())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_assessment_dt &lt;- sfh2123_assessment %&gt;% as.data.table()\nsfh2123_sales_dt &lt;- sfh2123_sales %&gt;% as.data.table()\nsfh2123_characteristics_dt &lt;- sfh2123_characteristics %&gt;% as.data.table()\nsfh2123_universe_dt &lt;- sfh2123_universe %&gt;% as.data.table()\n\n\n\n\n\n\n\nCode\nsfh2123_sales_AT &lt;- sfh2123_sales_dt %&gt;%\n  lazy_dt() %&gt;%\n  left_join(sfh2123_assessment_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"neighborhood_code\", \"township_code\", \"township_name\", \"class\", \"year\" = \"tax_year\")) %&gt;%\n  mutate(sale_price_ratio = 10 * certified_tot / sale_price) %&gt;%\n  collect()\n\nsfh2123_assessment_AT &lt;- sfh2123_assessment_dt %&gt;% \n  lazy_dt() %&gt;%\n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"township_code\", \"township_name\", \"class\", \"tax_year\")) %&gt;%\n  collect()\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\n\nsfh2123_sales_AT %&gt;%\n  mutate(id = row_number()) %&gt;%\n  tidyr::gather(-id, key = \"key\", value = \"val\") %&gt;%\n  mutate(isna = is.na(val)) %&gt;%\n  ggplot(aes(key, id, fill = isna)) +\n    geom_raster(alpha=0.8) +\n    scale_fill_manual(name = \"\",\n        values = c('steelblue', 'tomato3'),\n        labels = c(\"Present\", \"Missing\")) +\n    labs(x = \"Variable\",\n           y = \"Row Number\", title = \"Missing Values for Housing Sales\") +\n    coord_flip()\n\n\n\n\n\n\n\n\n\nIt seems like we have quite a few measures that are either entirely missing or have quite a few missing values. This is okay because we won’t be using all of our variables in order to reduce the complexity and increase the interpretability of our model.\n\n\n\n\n\nCode\nlibrary(corrr)\n\nsfh2123_sales_AT %&gt;%\n  select(c(sale_price, certified_tot, year_built, building_sqft, land_sqft, num_bedrooms, num_rooms, num_full_baths, num_half_baths, num_fireplaces, cmap_walkability_no_transit_score, cmap_walkability_total_score)) %&gt;%\n  select(where(is.numeric)) %&gt;%\n  select(where(function(x) sum(!is.na(x)) != 0)) %&gt;%\n  select(where(function(x) var(x, na.rm = TRUE) != 0)) %&gt;% \n  correlate(method = \"spearman\") %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\nThere seems to be a high level of correlation between many of the housing characteristics. Perhaps using a model that takes in account multicollinearity would be a good idea.\n\n\n\n\nYear BuiltBuilding SqFtLand SqFtBedsRoomsBathroomsWalkability\n\n\n\n\nCode\nlibrary(scales)\n\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = year_built, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Year Built \\nand Sale Price in Cook County, IL\", \n      x = \"Year Built\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nMore recently built houses seem to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = building_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Building Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Building Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nLarger building houses tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = land_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Land Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Land Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nThe relationship here isn’t entirely clear, but it seems that more land sells for more, up until some point\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_bedrooms, y = sale_price, fill = factor(num_bedrooms))) +\n    scale_x_continuous(n.breaks = 9) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Bedrooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Bedrooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bedrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_rooms, y = sale_price, fill = factor(num_rooms))) +\n    geom_smooth(aes(x = num_rooms, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Rooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Rooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more rooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price, fill = factor(num_full_baths + num_half_baths * 0.5))) +\n    geom_smooth(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Total Number of Baths \\nand Sale Price in Cook County, IL\", \n      x = \"Total Number of Baths\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bathrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = cmap_walkability_total_score, y = sale_price, fill = factor(cmap_walkability_total_score))) +\n    geom_smooth(aes(x = cmap_walkability_total_score, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home CMAP Walkability and \\nSale Price in Cook County, IL\", \n      x = \"Total Walkability Score\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with in less walkable communities tend to sell for more. Although it seems like individuals might want to live in more walkable communities. The kind of large single family homes that tend to sell for more actually contribute toward reducing walkability, which is most likely why we see a downward trend.\n\n\n\n\n\n\nLet us take a look at how our outcome variables are distributed spatially. Clustering might indicate that there is a spatial modeling technique is required.\n\n\nCode\nlibrary(sf)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n  filter(NAME %in% c(\"LEMONT\", \"PALOS\", \"ORLAND\")) %&gt;%\n  left_join(\n    sfh2123_sales_AT %&gt;%\n      group_by(township_code) %&gt;%\n      summarize(\n        median_sp = median(sale_price), \n        median_spr = median(sale_price_ratio))  %&gt;%\n      transmute(median_sp, median_spr, NAME = case_when(\n        township_code == \"19\" ~ \"LEMONT\",\n        township_code == \"30\" ~ \"PALOS\",\n        township_code == \"28\" ~ \"ORLAND\",\n      )\n    )\n  )\n\nsfh2123_sales_sf &lt;- sfh2123_sales_AT %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"))\n\n\n\n\nCode\nlibrary(leaflet)\n\nqpal1 &lt;- colorQuantile(\"Greens\", sfh2123_sales_sf$sale_price, n = 5)\n\nsfh2123_sales_sf %&gt;%\n  leaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n      data = townships,\n      fillColor = \"black\",\n      fillOpacity = 0.1,\n      color = \"black\",\n      weight = 2,\n      opacity = 0.5,\n      highlightOptions = highlightOptions(\n        fillOpacity = 0.2,\n        weight = 3),\n      label = sprintf(\n        \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Median Sale: %s&lt;br/&gt;\",\n        townships$NAME,\n        label_currency()(townships$median_sp)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addCircleMarkers(\n      radius = 3,\n      fillColor = ~ qpal1(sale_price),\n      fillOpacity = 0.7,\n      stroke = FALSE,\n      label = sprintf(\n        \"&lt;strong&gt;Sale Price:&lt;/strong&gt; %s\",\n        label_currency()(sfh2123_sales_sf$sale_price)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addLegend(\n      pal = qpal1,\n      values = sfh2123_sales_sf$sale_price,\n      opacity = 0.7,\n      title = \"Sale Price of Single &lt;br&gt;Family Homes in Cook &lt;br&gt;County\",\n      position = \"topright\",\n      na.label = \"Insufficient Data\",\n      labFormat = function(type, cuts, p) {\n        n = length(cuts)\n        p = str_c(round(p * 100), '%')\n        cuts = str_c(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n        str_c('&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts, '&lt;/span&gt;')\n      })\n\n\n\n\n\n\nIt seems that there is clustering of similarly priced homes within our three townships. Lemont has the highest median sale price, but Palos and Orland have similar median sale prices. Perhaps using a spatial modeling technique like a spatial Bayesian or conditional autoregressive model is waranted.\n\n\nCode\nlibrary(spdep)\n\nknn &lt;- knearneigh(sfh2123_sales_sf, k = 20)\nnb &lt;- knn2nb(knn)\nweights &lt;- nb2listw(nb, style = \"B\")\n\nmoran.test(x = sfh2123_sales_sf$sale_price, listw = weights, zero.policy = TRUE) %&gt;% \n  broom::tidy() %&gt;% \n  select(estimate1, p.value, method) %&gt;%\n  rename(`Moran I statistic` = estimate1) %&gt;%\n  knitr::kable()\n\n\n\n\n\nMoran I statistic\np.value\nmethod\n\n\n\n\n0.4998853\n0\nMoran I test under randomisation\n\n\n\n\n\n\n\n\n\n\nCode\nsfh2123_sales_data &lt;- sfh2123_sales_AT %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;% \n  filter(year != 2023) %&gt;%\n  mutate(month = str_extract(sale_date, \"^([:alpha:]*)(?= )\"))\n\n\n\n\n\n\nCode\nlibrary(tidycensus)\n\nacs2022vars &lt;- load_variables(2022, \"acs5\")\ntables &lt;- list(\"B01001\", \"B15003\")\n\nacs2022vars &lt;- acs2022vars %&gt;%\n  mutate(table = str_sub(name, 1, 7)) %&gt;%\n  filter(table %in% str_c(tables, \"_\")) %&gt;% \n  mutate(table = str_sub(table, 1, 6)) %&gt;% \n  mutate(name = str_c(\"estimate_\", name)) %&gt;%\n  mutate(label = str_sub(label, 11)) %&gt;%\n  separate_wider_delim(label, \"!!\", names = c(\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\"), too_few = \"align_start\")\n\nACS_data &lt;- map_df(tables,\n    \\(table) get_acs(geography = \"tract\", state =\"IL\", county = \"Cook\", table = table, year = 2022)\n  ) %&gt;%\n  pivot_wider(names_from = variable, values_from = c(estimate, moe))\n\n# gets the sum of ACS estimates for a single tract\nget_var_rowsums &lt;- function (ACS_data, var_df) {\n  ACS_data %&gt;%\n    select(.,\n      var_df %&gt;%\n        select(name) %&gt;%\n        unlist() %&gt;%\n        matches()\n    ) %&gt;% rowSums()\n}\n\nprocessed_ACS_data &lt;- ACS_data %&gt;%\n  mutate(\n    TotalPop = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B01001\",\n          `1st` == \"Total:\",\n          is.na(`2nd`)\n        )\n      ),\n    Age00_17 = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B01001\",\n          `3rd` %in% c(\"Under 5 years\", \"5 to 9 years\", \"10 to 14 years\", \"15 to 17 years\"),\n          is.na(`4th`)\n        )\n      ),\n    Age65p = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B01001\",\n          `3rd` %in% c(\"65 and 66 years\", \"67 to 69 years\", \"70 to 74 years\", \"75 to 79 years\", \"80 to 84 years\", \"85 years and over\"),\n          is.na(`4th`)\n        )\n      ),\n    Pct00_17 = Age00_17 / TotalPop,\n    Pct65p = Age65p / TotalPop,\n    EduHS = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` %in% c(\"Regular high school diploma\", \"GED or alternative credential\", \"Some college, less than 1 year\", \"Some college, 1 or more years, no degree\"),\n          is.na(`3rd`)\n        )\n      ),\n    TotalEdu = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `1st` == \"Total:\",\n          is.na(`2nd`)\n        )\n      ),\n    EduAS = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` == \"Associate's degree\",\n          is.na(`3rd`)\n        )\n      ),\n    EduBA = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` == \"Bachelor's degree\",\n          is.na(`3rd`)\n        )\n      ),\n    EduGA = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` %in% c(\"Master's degree\", \"Professional school degree\", \"Doctorate degree\"),\n          is.na(`3rd`)\n        )\n      ),\n    PctEdHS = EduHS / TotalEdu,\n    PctEduAS = EduAS / TotalEdu,\n    PctEduBA = EduBA / TotalEdu,\n    PctEduGA = EduGA / TotalEdu\n  ) %&gt;%\n  select(GEOID, starts_with(\"Pct\"))\n\n\n\n\nCode\nsales_data &lt;- sfh2123_sales_data %&gt;%\n  left_join(processed_ACS_data, by = c(\"census_tract_geoid\" = \"GEOID\"))\n\n\n\n\n\n\n\n\nCode\nlibrary(tidymodels)\ntidymodels_prefer()\n\n\n\n\n\n\nCode\nset.seed(123) \nsales_split &lt;- initial_split(sales_data, strata = sale_price)\nsales_train &lt;- training(sales_split)\nsales_test  &lt;- testing(sales_split)\n\nset.seed(234) \nsales_resamples &lt;- vfold_cv(sales_train, v = 5, strata = sale_price)\n\n\n\n\n\n\n\nCode\nlibrary(rules)\n\ndefault_recipe &lt;- sales_data %&gt;%    \n  recipe(sale_price ~ year_built + building_sqft + land_sqft + num_bedrooms + num_rooms + num_full_baths + num_half_baths + num_fireplaces + type_of_residence + construction_quality + attic_finish + garage_size + ext_wall_material + basement_type + central_heating + roof_material + porch + central_air + neighborhood_code + school_elementary_district_name + Pct00_17 + Pct65p + PctEdHS + PctEduAS + PctEduBA + PctEduGA, data = .) %&gt;%    \n  step_string2factor(all_string()) %&gt;%    \n  step_impute_knn(all_predictors()) %&gt;%   \n  step_novel(all_nominal_predictors()) %&gt;%   \n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors())\n\nnormalized_recipe &lt;- default_recipe %&gt;%\n  step_normalize(all_predictors())\n\n\n\n\n\n\n\nCode\nlinear_reg_spec &lt;- \n  linear_reg(penalty = tune(), mixture = tune()) %&gt;% \n  set_engine(\"glmnet\")\n\nrf_spec &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 500) %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"regression\")\n\nxgb_spec &lt;- \n  boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), min_n = tune(), sample_size = tune(), trees = tune()) %&gt;% \n  set_engine(\"xgboost\") %&gt;% \n  set_mode(\"regression\")\n\ncubist_spec &lt;- \n   cubist_rules(committees = tune(), neighbors = tune()) %&gt;% \n   set_engine(\"Cubist\") \n\n\n\n\n\n\n\nCode\nnormalized &lt;- workflow_set(\n  preproc = list(normalized = normalized_recipe),\n  models = list(linear_reg = linear_reg_spec))\n\nno_pre_proc &lt;- workflow_set(\n  preproc = list(simple = default_recipe), \n  models = list(RF = rf_spec, boosting = xgb_spec, Cubist = cubist_spec))\n\n\n\n\nCode\nall_workflows &lt;- bind_rows(no_pre_proc, normalized)\n\n\n\n\nCode\nlibrary(finetune)\n\ngrid_results &lt;- all_workflows %&gt;%\n  workflow_map(\n    \"tune_race_anova\",\n    seed = 345,\n    resamples = sales_resamples,\n    grid = 20,\n    control = control_race(\n      save_pred = FALSE,\n      save_workflow = FALSE,\n      parallel_over = \"everything\"),\n    verbose = TRUE)\n\n\n\n\n\n\n\nCode\ngrid_results %&gt;% \n  rank_results() %&gt;%\n  filter(.metric == \"rmse\") %&gt;% \n  select(model, .config, rmse = mean, rank) %&gt;%\n  knitr::kable()\n\n\n\n\n\nmodel\n.config\nrmse\nrank\n\n\n\n\nboost_tree\nPreprocessor1_Model06\n99370.41\n1\n\n\nboost_tree\nPreprocessor1_Model03\n99735.99\n2\n\n\nboost_tree\nPreprocessor1_Model12\n99814.43\n3\n\n\ncubist_rules\nPreprocessor1_Model11\n100449.81\n4\n\n\nlinear_reg\nPreprocessor1_Model02\n100467.61\n5\n\n\nlinear_reg\nPreprocessor1_Model09\n100468.87\n6\n\n\nlinear_reg\nPreprocessor1_Model06\n100469.72\n7\n\n\nlinear_reg\nPreprocessor1_Model04\n100471.87\n8\n\n\nlinear_reg\nPreprocessor1_Model05\n100473.77\n9\n\n\nlinear_reg\nPreprocessor1_Model14\n100495.85\n10\n\n\nlinear_reg\nPreprocessor1_Model17\n100509.72\n11\n\n\nlinear_reg\nPreprocessor1_Model07\n100596.77\n12\n\n\nlinear_reg\nPreprocessor1_Model03\n100607.02\n13\n\n\nlinear_reg\nPreprocessor1_Model08\n100609.04\n14\n\n\nlinear_reg\nPreprocessor1_Model10\n100618.31\n15\n\n\nlinear_reg\nPreprocessor1_Model01\n100619.02\n16\n\n\nlinear_reg\nPreprocessor1_Model11\n100623.54\n17\n\n\nlinear_reg\nPreprocessor1_Model12\n100623.87\n18\n\n\nlinear_reg\nPreprocessor1_Model13\n100625.73\n19\n\n\nlinear_reg\nPreprocessor1_Model20\n100626.77\n20\n\n\nlinear_reg\nPreprocessor1_Model15\n100636.52\n21\n\n\nlinear_reg\nPreprocessor1_Model18\n100639.10\n22\n\n\nlinear_reg\nPreprocessor1_Model16\n100639.61\n23\n\n\nlinear_reg\nPreprocessor1_Model19\n100639.78\n24\n\n\ncubist_rules\nPreprocessor1_Model18\n100685.93\n25\n\n\nboost_tree\nPreprocessor1_Model17\n100872.65\n26\n\n\ncubist_rules\nPreprocessor1_Model10\n101008.70\n27\n\n\nrand_forest\nPreprocessor1_Model10\n101067.44\n28\n\n\ncubist_rules\nPreprocessor1_Model05\n101168.22\n29\n\n\nrand_forest\nPreprocessor1_Model20\n101281.61\n30\n\n\ncubist_rules\nPreprocessor1_Model13\n101345.31\n31\n\n\nrand_forest\nPreprocessor1_Model04\n101447.32\n32\n\n\nrand_forest\nPreprocessor1_Model06\n101563.37\n33\n\n\nrand_forest\nPreprocessor1_Model08\n101605.92\n34\n\n\nrand_forest\nPreprocessor1_Model09\n101621.71\n35\n\n\nrand_forest\nPreprocessor1_Model15\n101802.36\n36\n\n\nrand_forest\nPreprocessor1_Model13\n101962.18\n37\n\n\ncubist_rules\nPreprocessor1_Model15\n102245.67\n38\n\n\nrand_forest\nPreprocessor1_Model07\n102303.67\n39\n\n\ncubist_rules\nPreprocessor1_Model08\n102579.22\n40\n\n\nrand_forest\nPreprocessor1_Model11\n102676.19\n41\n\n\ncubist_rules\nPreprocessor1_Model03\n102720.11\n42\n\n\ncubist_rules\nPreprocessor1_Model02\n102905.93\n43\n\n\nrand_forest\nPreprocessor1_Model12\n102954.36\n44\n\n\nrand_forest\nPreprocessor1_Model05\n103011.92\n45\n\n\nrand_forest\nPreprocessor1_Model19\n103225.46\n46\n\n\nrand_forest\nPreprocessor1_Model17\n103241.71\n47\n\n\nrand_forest\nPreprocessor1_Model02\n103569.38\n48\n\n\nboost_tree\nPreprocessor1_Model14\n103886.69\n49\n\n\nrand_forest\nPreprocessor1_Model01\n103956.00\n50\n\n\nboost_tree\nPreprocessor1_Model07\n104158.37\n51\n\n\nrand_forest\nPreprocessor1_Model16\n104162.49\n52\n\n\nboost_tree\nPreprocessor1_Model16\n104173.77\n53\n\n\nboost_tree\nPreprocessor1_Model20\n104218.78\n54\n\n\nboost_tree\nPreprocessor1_Model15\n104251.63\n55\n\n\nboost_tree\nPreprocessor1_Model10\n104264.46\n56\n\n\nboost_tree\nPreprocessor1_Model01\n104790.26\n57\n\n\nboost_tree\nPreprocessor1_Model09\n104876.53\n58\n\n\nrand_forest\nPreprocessor1_Model18\n104881.21\n59\n\n\nrand_forest\nPreprocessor1_Model03\n104989.63\n60\n\n\n\n\n\n\n\nCode\nautoplot(\n  grid_results,\n  rank_metric = \"rmse\",\n  metric = \"rmse\", \n  select_best = TRUE\n ) +\n  geom_text(aes(y = mean - 1/2, label = wflow_id), angle = 90, vjust = -0.5) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbest_wf &lt;- grid_results %&gt;% \n  rank_results() %&gt;%\n  filter(.metric == \"rmse\", rank == 1) %&gt;%\n  pull(wflow_id)\n\nbest_results &lt;- grid_results %&gt;%\n  extract_workflow_set_result(best_wf) %&gt;% \n  select_best(metric = \"rmse\") \n\nbest_results_fit &lt;- \n  grid_results %&gt;% \n  extract_workflow(best_wf) %&gt;%\n  finalize_workflow(best_results) %&gt;% \n  last_fit(split = sales_split)\n\n\n\n\n\n\n\nCode\nbest_results_fit %&gt;% \n  collect_predictions() %&gt;% \n  ggplot(aes(x = sale_price, y = .pred)) + \n  geom_abline(color = \"gray50\", lty = 2) + \n  geom_point(alpha = 0.5) + \n  coord_obs_pred() + \n  labs(x = \"observed\", y = \"predicted\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbayes_results &lt;- grid_results %&gt;% \n  extract_workflow(best_wf) %&gt;%\n  tune_bayes(\n    resamples = sales_resamples,\n    initial = 6,\n    iter = 25,\n    control = control_bayes(verbose = TRUE)\n  )\n\n\n\n\n\n\n\nCode\nbayes_results %&gt;%\n  show_best(metric = \"rmse\") %&gt;% \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrees\nmin_n\ntree_depth\nlearn_rate\nloss_reduction\nsample_size\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n.iter\n\n\n\n\n1531\n13\n2\n0.0145856\n0.0000095\n0.2282499\nrmse\nstandard\n98862.69\n5\n10018.769\nPreprocessor1_Model2\n0\n\n\n402\n13\n5\n0.0121933\n24.3073101\n0.1917696\nrmse\nstandard\n100612.56\n5\n10541.353\nIter10\n10\n\n\n833\n35\n10\n0.0055546\n6.5822950\n0.4633506\nrmse\nstandard\n103436.17\n5\n10745.935\nPreprocessor1_Model6\n0\n\n\n1516\n29\n1\n0.0153796\n30.9923970\n0.7996068\nrmse\nstandard\n103598.27\n5\n8617.141\nIter2\n2\n\n\n1224\n33\n8\n0.0090024\n0.0005782\n0.2168532\nrmse\nstandard\n104194.76\n5\n10192.453\nIter1\n1\n\n\n\n\n\nFinal fit\n\n\nCode\nfinal_fit &lt;- grid_results %&gt;% \n  extract_workflow(best_wf) %&gt;%\n  finalize_workflow(select_best(bayes_results, metric = \"rmse\")) %&gt;% \n  last_fit(split = sales_split)\n\n\nMAPE and RMSE\n\n\nCode\nsales_preds &lt;- final_fit %&gt;% \n  pull(.predictions) %&gt;% \n  pluck(1)\n\nsales_metrics &lt;- list(   \n  sales_preds %&gt;%     \n    rmse(sale_price, .pred),   \n  sales_preds %&gt;%     \n    mape(sale_price, .pred)) \n\nsales_metrics %&gt;% bind_rows() %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n93988.148\n\n\nmape\nstandard\n16.027\n\n\n\n\n\n\n\n\n\nOver the course of the Cook County assessment project, I have tested several different models. All of these models exhibited RMSEs in excess of 90,000. This means that on average predictions produced by the models deviated from the true sale price by at least $90,000. Although the predictions seem quite awful, I think that these predictions point to the fact that house value prediction is a difficult problem. There exists a multitude of factors that the assessor is barred from using to predict house values and there exists a large number of factors which are not easily translated into machine learning features (e.g., housing aesthetics, human psychology, etc.).\nAs compared to the assessor’s model, my model seems to have a similar RMSE; however, the assessor’s model median assessment tends to be less than 85% of the sale price. So the assessor’s model continually underassesses the true value of the homes. Both the my model and the assessor’s are variants of Gradient Boosted Machines. Light GBM and XGBoost often yield similar predictions; however, LightGBM is often quite faster to train.\nThere are quite a few ethical concerns that come with assessing home values through the use of machine learning. As we discussed in Part 1, housing assessments, even for the year of 2023, exhibit regressivity (i.e., lower value homes are assessed a higher proportion of their true house price). This can be hugely detrimental to the residents of these homes because it has the effect of imposing the highest tax rate on those with the least. We can see from the chart below that my model also exhibits a high degree of regresivity.\nAdditionally, machine learning cannot capture the many human aspects of a home price, which means that there are some technical challenges with distilling aspects that affect a home’s price into features usable by a machine learning algorithm.\n\n\nCode\nlibrary(cmfproperty)\n\nratios &lt;- grid_results %&gt;% \n  extract_workflow(best_wf) %&gt;%\n  finalize_workflow(select_best(bayes_results, metric = \"rmse\")) %&gt;%\n  fit(sales_train) %&gt;%\n  augment(sales_test) %&gt;%\n  select(pin, year, sale_price, .pred) %&gt;%\n  reformat_data(\n    sale_col = \"sale_price\",\n    assessment_col = \".pred\",\n    sale_year_col = \"year\")\n\nbinned &lt;- binned_scatter(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nbinned[[2]]\n\n\n\n\n\n\n\n\n\n[1] \"Filtered out non-arm's length transactions\"\n[1] \"Inflation adjusted to 2021\"\n\n\nOverall, I do not think that my model is quite as effective as that of the assessor’s, and it exhibits a high degree of regressivity. I think the model could be improved by providing it with more years of data and working to refine some additional measures not currently captured by the model. I also wonder if a more comprehensive model including data from all of the Cook County townships would produce better predictions due to the larger amount of data provided. At this point, I would not recommend that the assessor use my model."
  },
  {
    "objectID": "posts/cook_part_4/index.html#final-submission",
    "href": "posts/cook_part_4/index.html#final-submission",
    "title": "Cook County Property Assessment - Part 4",
    "section": "",
    "text": "There are over 1.8 million parcels in Cook County, Illinois [1]. Each of these parcels is assessed every three years using three to five years of prior sales information [1]. For this analysis, we will take a look at single family home assessments within three of the 36 political townships: Lemont (19), Palos (30), Orland (28). Using data provided on the Cook County data portal, we will will create a model predicting the sale price of a property.\nThere exist several technical challenges with predicting sale prices of properties. 1) There exists a great degree of multicolinearity in the dataset due to the tendency for housing attributes to be associated with one another. 2) There are aspects of the home buying process that the assessor is not allowed to use as part of their assessment. Given these challenges, we we will attempt to do the best to evaluate several models applicability,\n\n\nWe have 4 inclusion criteria:\n\nYear - 2021, 2022, 2023\nClass - 202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278. These conform to single family homes\nTownship Code - 19 (Lemont), 30 (Palos), 28 (Orland)\nIs Multisale - No\n\n\n\nCode\nlibrary(arrow)\nlibrary(data.table)\nlibrary(dtplyr)\nlibrary(tidyverse)\n\nsfh2123_assessment &lt;-\n  open_csv_dataset(\"../data/20240217_Assessed_Values.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"township_name\", string()),\n      field(\"mailed_bldg\", int32()),\n      field(\"mailed_land\", int32()),\n      field(\"mailed_tot\", int32()),\n      field(\"certified_bldg\", int32()),\n      field(\"certified_land\", int32()),\n      field(\"certified_tot\", int32()),\n      field(\"board_bldg\", int32()),\n      field(\"board_land\", int32()),\n      field(\"board_tot\", int32()),\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_sales &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Sales.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"year\", int32()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"class\", string()),\n      field(\"sale_date\", string()),\n      field(\"is_mydec_date\", bool()),\n      field(\"sale_price\", int32()),\n      field(\"sale_document_num\", string()),\n      field(\"sale_deed_type\", string()),\n      field(\"mydec_deed_type\", string()),\n      field(\"sale_seller_name\", string()),\n      field(\"is_multisale\", bool()),\n      field(\"num_parcels_sale\", int32()),\n      field(\"sale_buyer_name\", string()),\n      field(\"sale_type\", string()),\n      field(\"sale_filter_same_sale_within_365\", bool()),\n      field(\"sale_filter_less_than_10k\", bool()),\n      field(\"sale_filter_deed_type\", bool())\n    )\n  ) %&gt;%\n  filter(year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\")) %&gt;%\n  filter(!is_multisale) \n\nsfh2123_characteristics &lt;- \n  open_csv_dataset(\"../data/20240217_Improvement_Characteristics.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"card_num\", string()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"proration_key_pin\", string()),\n      field(\"pin_proration_rate\", double()),\n      field(\"card_proration_rate\", double()),\n      field(\"cdu\", string()),\n      field(\"pin_is_multicard\", bool()),\n      field(\"pin_num_cards\", int32()),\n      field(\"pin_is_multiland\", bool()),\n      field(\"pin_num_landlines\", int32()),\n      field(\"year_built\", int32()),\n      field(\"building_sqft\", int32()),\n      field(\"land_sqft\", int32()),\n      field(\"num_bedrooms\", int32()),\n      field(\"num_rooms\", int32()),\n      field(\"num_full_baths\", int32()),\n      field(\"num_half_baths\", int32()),\n      field(\"num_fireplaces\", int32()),\n      field(\"type_of_residence\", string()),\n      field(\"construction_quality\", string()),\n      field(\"num_apartments\", string()),\n      field(\"attic_finish\", string()),\n      field(\"garage_attached\", string()),\n      field(\"garage_area_included\", string()),\n      field(\"garage_size\", string()),\n      field(\"garage_ext_wall_material\", string()),\n      field(\"attic_type\", string()),\n      field(\"basement_type\", string()),\n      field(\"ext_wall_material\", string()),\n      field(\"central_heating\", string()),\n      field(\"repair_condition\", string()),\n      field(\"basement_finish\", string()),\n      field(\"roof_material\", string()),\n      field(\"single_v_multi_family\", string()),\n      field(\"site_desirability\", string()),\n      field(\"num_commercial_units\", string()),\n      field(\"renovation\", string()),\n      field(\"recent_renovation\", bool()),\n      field(\"porch\", string()),\n      field(\"central_air\", string()),\n      field(\"design_plan\", string())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_universe &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Universe.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"pin10\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"triad_name\", string()),\n      field(\"triad_code\", string()),\n      field(\"township_name\", string()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"tax_district_code\", string()),\n      field(\"zip_code\", string()),\n      field(\"longitude\", double()),\n      field(\"latitude\", double()),\n      field(\"centroid_x_crs_3435\", double()),\n      field(\"centroid_y_crs_3435\", double()),\n      field(\"census_block_group_geoid\", string()),\n      field(\"census_block_geoid\", string()),\n      field(\"census_congressional_district_geoid\", string()),\n      field(\"census_county_subdivision_geoid\", string()),\n      field(\"census_place_geoid\", string()),\n      field(\"census_puma_geoid\", string()),\n      field(\"census_school_district_elementary_geoid\", string()),\n      field(\"census_school_district_secondary_geoid\", string()),\n      field(\"census_school_district_unified_geoid\", string()),\n      field(\"census_state_representative_geoid\", string()),\n      field(\"census_state_senate_geoid\", string()),\n      field(\"census_tract_geoid\", string()),\n      field(\"census_zcta_geoid\", string()),\n      field(\"census_data_year\", int32()),\n      field(\"census_acs5_congressional_district_geoid\", string()),\n      field(\"census_acs5_county_subdivision_geoid\", string()),\n      field(\"census_acs5_place_geoid\", string()),\n      field(\"census_acs5_puma_geoid\", string()),\n      field(\"census_acs5_school_district_elementary_geoid\", string()),\n      field(\"census_acs5_school_district_secondary_geoid\", string()),\n      field(\"census_acs5_school_district_unified_geoid\", string()),\n      field(\"census_acs5_state_representative_geoid\", string()),\n      field(\"census_acs5_state_senate_geoid\", string()),\n      field(\"census_acs5_tract_geoid\", string()),\n      field(\"census_acs5_data_year\", int32()),\n      field(\"board_of_review_district_num\", string()),\n      field(\"board_of_review_district_data_year\", int32()),\n      field(\"commissioner_district_num\", string()),\n      field(\"commissioner_district_data_year\", int32()),\n      field(\"judicial_district_num\", string()),\n      field(\"judicial_district_data_year\", int32()),\n      field(\"ward_num\", string()),\n      field(\"ward_chicago_data_year\", int32()),\n      field(\"ward_evanston_data_year\", int32()),\n      field(\"chicago_community_area_num\", string()),\n      field(\"chicago_community_area_name\", string()),\n      field(\"chicago_community_area_data_year\", int32()),\n      field(\"chicago_industrial_corridor_num\", string()),\n      field(\"chicago_industrial_corridor_name\", string()),\n      field(\"chicago_industrial_corridor_data_year\", int32()),\n      field(\"chicago_police_district_num\", string()),\n      field(\"chicago_police_district_data_year\", int32()),\n      field(\"coordinated_care_area_num\", string()),\n      field(\"coordinated_care_area_data_year\", int32()),\n      field(\"enterprise_zone_num\", string()),\n      field(\"enterprise_zone_data_year\", int32()),\n      field(\"industrial_growth_zone_num\", string()),\n      field(\"industrial_growth_zone_data_year\", int32()),\n      field(\"qualified_opportunity_zone_num\", string()),\n      field(\"qualified_opportunity_zone_data_year\", int32()),\n      field(\"flood_fema_sfha\", bool()),\n      field(\"flood_fema_data_year\", int32()),\n      field(\"flood_fs_factor\", int32()),\n      field(\"flood_fs_risk_direction\", int32()),\n      field(\"flood_fs_data_year\", int32()),\n      field(\"ohare_noise_contour_no_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_half_mile_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_data_year\", int32()),\n      field(\"airport_noise_dnl\", double()),\n      field(\"airport_noise_data_year\", string()),\n      field(\"school_elementary_district_geoid\", string()),\n      field(\"school_elementary_district_name\", string()),\n      field(\"school_secondary_district_geoid\", string()),\n      field(\"school_secondary_district_name\", string()),\n      field(\"school_unified_district_geoid\", string()),\n      field(\"school_unified_district_name\", string()),\n      field(\"school_year\", string()),\n      field(\"school_data_year\", int32()),\n      field(\"tax_municipality_num\", string()),\n      field(\"tax_municipality_name\", string()),\n      field(\"tax_school_elementary_district_num\", string()),\n      field(\"tax_school_elementary_district_name\", string()),\n      field(\"tax_school_secondary_district_num\", string()),\n      field(\"tax_school_secondary_district_name\", string()),\n      field(\"tax_school_unified_district_num\", string()),\n      field(\"tax_school_unified_district_name\", string()),\n      field(\"tax_community_college_district_num\", string()),\n      field(\"tax_community_college_district_name\", string()),\n      field(\"tax_fire_protection_district_num\", string()),\n      field(\"tax_fire_protection_district_name\", string()),\n      field(\"tax_library_district_num\", string()),\n      field(\"tax_library_district_name\", string()),\n      field(\"tax_park_district_num\", string()),\n      field(\"tax_park_district_name\", string()),\n      field(\"tax_sanitation_district_num\", string()),\n      field(\"tax_sanitation_district_name\", string()),\n      field(\"tax_special_service_area_num\", string()),\n      field(\"tax_special_service_area_name\", string()),\n      field(\"tax_tif_district_num\", string()),\n      field(\"tax_tif_district_name\", string()),\n      field(\"tax_districts_data_year\", int32()),\n      field(\"cmap_walkability_grid_id\", string()),\n      field(\"cmap_walkability_no_transit_score\", double()),\n      field(\"cmap_walkability_total_score\", double()),\n      field(\"cmap_walkability_data_year\", int32()),\n      field(\"subdivision_id\", string()),\n      field(\"subdivision_data_year\", int32())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_assessment_dt &lt;- sfh2123_assessment %&gt;% as.data.table()\nsfh2123_sales_dt &lt;- sfh2123_sales %&gt;% as.data.table()\nsfh2123_characteristics_dt &lt;- sfh2123_characteristics %&gt;% as.data.table()\nsfh2123_universe_dt &lt;- sfh2123_universe %&gt;% as.data.table()\n\n\n\n\n\n\n\nCode\nsfh2123_sales_AT &lt;- sfh2123_sales_dt %&gt;%\n  lazy_dt() %&gt;%\n  left_join(sfh2123_assessment_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"neighborhood_code\", \"township_code\", \"township_name\", \"class\", \"year\" = \"tax_year\")) %&gt;%\n  mutate(sale_price_ratio = 10 * certified_tot / sale_price) %&gt;%\n  collect()\n\nsfh2123_assessment_AT &lt;- sfh2123_assessment_dt %&gt;% \n  lazy_dt() %&gt;%\n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"township_code\", \"township_name\", \"class\", \"tax_year\")) %&gt;%\n  collect()\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\n\nsfh2123_sales_AT %&gt;%\n  mutate(id = row_number()) %&gt;%\n  tidyr::gather(-id, key = \"key\", value = \"val\") %&gt;%\n  mutate(isna = is.na(val)) %&gt;%\n  ggplot(aes(key, id, fill = isna)) +\n    geom_raster(alpha=0.8) +\n    scale_fill_manual(name = \"\",\n        values = c('steelblue', 'tomato3'),\n        labels = c(\"Present\", \"Missing\")) +\n    labs(x = \"Variable\",\n           y = \"Row Number\", title = \"Missing Values for Housing Sales\") +\n    coord_flip()\n\n\n\n\n\n\n\n\n\nIt seems like we have quite a few measures that are either entirely missing or have quite a few missing values. This is okay because we won’t be using all of our variables in order to reduce the complexity and increase the interpretability of our model.\n\n\n\n\n\nCode\nlibrary(corrr)\n\nsfh2123_sales_AT %&gt;%\n  select(c(sale_price, certified_tot, year_built, building_sqft, land_sqft, num_bedrooms, num_rooms, num_full_baths, num_half_baths, num_fireplaces, cmap_walkability_no_transit_score, cmap_walkability_total_score)) %&gt;%\n  select(where(is.numeric)) %&gt;%\n  select(where(function(x) sum(!is.na(x)) != 0)) %&gt;%\n  select(where(function(x) var(x, na.rm = TRUE) != 0)) %&gt;% \n  correlate(method = \"spearman\") %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\nThere seems to be a high level of correlation between many of the housing characteristics. Perhaps using a model that takes in account multicollinearity would be a good idea.\n\n\n\n\nYear BuiltBuilding SqFtLand SqFtBedsRoomsBathroomsWalkability\n\n\n\n\nCode\nlibrary(scales)\n\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = year_built, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Year Built \\nand Sale Price in Cook County, IL\", \n      x = \"Year Built\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nMore recently built houses seem to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = building_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Building Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Building Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nLarger building houses tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = land_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Land Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Land Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nThe relationship here isn’t entirely clear, but it seems that more land sells for more, up until some point\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_bedrooms, y = sale_price, fill = factor(num_bedrooms))) +\n    scale_x_continuous(n.breaks = 9) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Bedrooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Bedrooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bedrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_rooms, y = sale_price, fill = factor(num_rooms))) +\n    geom_smooth(aes(x = num_rooms, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Rooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Rooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more rooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price, fill = factor(num_full_baths + num_half_baths * 0.5))) +\n    geom_smooth(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Total Number of Baths \\nand Sale Price in Cook County, IL\", \n      x = \"Total Number of Baths\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bathrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = cmap_walkability_total_score, y = sale_price, fill = factor(cmap_walkability_total_score))) +\n    geom_smooth(aes(x = cmap_walkability_total_score, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home CMAP Walkability and \\nSale Price in Cook County, IL\", \n      x = \"Total Walkability Score\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with in less walkable communities tend to sell for more. Although it seems like individuals might want to live in more walkable communities. The kind of large single family homes that tend to sell for more actually contribute toward reducing walkability, which is most likely why we see a downward trend.\n\n\n\n\n\n\nLet us take a look at how our outcome variables are distributed spatially. Clustering might indicate that there is a spatial modeling technique is required.\n\n\nCode\nlibrary(sf)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n  filter(NAME %in% c(\"LEMONT\", \"PALOS\", \"ORLAND\")) %&gt;%\n  left_join(\n    sfh2123_sales_AT %&gt;%\n      group_by(township_code) %&gt;%\n      summarize(\n        median_sp = median(sale_price), \n        median_spr = median(sale_price_ratio))  %&gt;%\n      transmute(median_sp, median_spr, NAME = case_when(\n        township_code == \"19\" ~ \"LEMONT\",\n        township_code == \"30\" ~ \"PALOS\",\n        township_code == \"28\" ~ \"ORLAND\",\n      )\n    )\n  )\n\nsfh2123_sales_sf &lt;- sfh2123_sales_AT %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"))\n\n\n\n\nCode\nlibrary(leaflet)\n\nqpal1 &lt;- colorQuantile(\"Greens\", sfh2123_sales_sf$sale_price, n = 5)\n\nsfh2123_sales_sf %&gt;%\n  leaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n      data = townships,\n      fillColor = \"black\",\n      fillOpacity = 0.1,\n      color = \"black\",\n      weight = 2,\n      opacity = 0.5,\n      highlightOptions = highlightOptions(\n        fillOpacity = 0.2,\n        weight = 3),\n      label = sprintf(\n        \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Median Sale: %s&lt;br/&gt;\",\n        townships$NAME,\n        label_currency()(townships$median_sp)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addCircleMarkers(\n      radius = 3,\n      fillColor = ~ qpal1(sale_price),\n      fillOpacity = 0.7,\n      stroke = FALSE,\n      label = sprintf(\n        \"&lt;strong&gt;Sale Price:&lt;/strong&gt; %s\",\n        label_currency()(sfh2123_sales_sf$sale_price)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addLegend(\n      pal = qpal1,\n      values = sfh2123_sales_sf$sale_price,\n      opacity = 0.7,\n      title = \"Sale Price of Single &lt;br&gt;Family Homes in Cook &lt;br&gt;County\",\n      position = \"topright\",\n      na.label = \"Insufficient Data\",\n      labFormat = function(type, cuts, p) {\n        n = length(cuts)\n        p = str_c(round(p * 100), '%')\n        cuts = str_c(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n        str_c('&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts, '&lt;/span&gt;')\n      })\n\n\n\n\n\n\nIt seems that there is clustering of similarly priced homes within our three townships. Lemont has the highest median sale price, but Palos and Orland have similar median sale prices. Perhaps using a spatial modeling technique like a spatial Bayesian or conditional autoregressive model is waranted.\n\n\nCode\nlibrary(spdep)\n\nknn &lt;- knearneigh(sfh2123_sales_sf, k = 20)\nnb &lt;- knn2nb(knn)\nweights &lt;- nb2listw(nb, style = \"B\")\n\nmoran.test(x = sfh2123_sales_sf$sale_price, listw = weights, zero.policy = TRUE) %&gt;% \n  broom::tidy() %&gt;% \n  select(estimate1, p.value, method) %&gt;%\n  rename(`Moran I statistic` = estimate1) %&gt;%\n  knitr::kable()\n\n\n\n\n\nMoran I statistic\np.value\nmethod\n\n\n\n\n0.4998853\n0\nMoran I test under randomisation\n\n\n\n\n\n\n\n\n\n\nCode\nsfh2123_sales_data &lt;- sfh2123_sales_AT %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;% \n  filter(year != 2023) %&gt;%\n  mutate(month = str_extract(sale_date, \"^([:alpha:]*)(?= )\"))\n\n\n\n\n\n\nCode\nlibrary(tidycensus)\n\nacs2022vars &lt;- load_variables(2022, \"acs5\")\ntables &lt;- list(\"B01001\", \"B15003\")\n\nacs2022vars &lt;- acs2022vars %&gt;%\n  mutate(table = str_sub(name, 1, 7)) %&gt;%\n  filter(table %in% str_c(tables, \"_\")) %&gt;% \n  mutate(table = str_sub(table, 1, 6)) %&gt;% \n  mutate(name = str_c(\"estimate_\", name)) %&gt;%\n  mutate(label = str_sub(label, 11)) %&gt;%\n  separate_wider_delim(label, \"!!\", names = c(\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\"), too_few = \"align_start\")\n\nACS_data &lt;- map_df(tables,\n    \\(table) get_acs(geography = \"tract\", state =\"IL\", county = \"Cook\", table = table, year = 2022)\n  ) %&gt;%\n  pivot_wider(names_from = variable, values_from = c(estimate, moe))\n\n# gets the sum of ACS estimates for a single tract\nget_var_rowsums &lt;- function (ACS_data, var_df) {\n  ACS_data %&gt;%\n    select(.,\n      var_df %&gt;%\n        select(name) %&gt;%\n        unlist() %&gt;%\n        matches()\n    ) %&gt;% rowSums()\n}\n\nprocessed_ACS_data &lt;- ACS_data %&gt;%\n  mutate(\n    TotalPop = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B01001\",\n          `1st` == \"Total:\",\n          is.na(`2nd`)\n        )\n      ),\n    Age00_17 = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B01001\",\n          `3rd` %in% c(\"Under 5 years\", \"5 to 9 years\", \"10 to 14 years\", \"15 to 17 years\"),\n          is.na(`4th`)\n        )\n      ),\n    Age65p = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B01001\",\n          `3rd` %in% c(\"65 and 66 years\", \"67 to 69 years\", \"70 to 74 years\", \"75 to 79 years\", \"80 to 84 years\", \"85 years and over\"),\n          is.na(`4th`)\n        )\n      ),\n    Pct00_17 = Age00_17 / TotalPop,\n    Pct65p = Age65p / TotalPop,\n    EduHS = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` %in% c(\"Regular high school diploma\", \"GED or alternative credential\", \"Some college, less than 1 year\", \"Some college, 1 or more years, no degree\"),\n          is.na(`3rd`)\n        )\n      ),\n    TotalEdu = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `1st` == \"Total:\",\n          is.na(`2nd`)\n        )\n      ),\n    EduAS = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` == \"Associate's degree\",\n          is.na(`3rd`)\n        )\n      ),\n    EduBA = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` == \"Bachelor's degree\",\n          is.na(`3rd`)\n        )\n      ),\n    EduGA = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` %in% c(\"Master's degree\", \"Professional school degree\", \"Doctorate degree\"),\n          is.na(`3rd`)\n        )\n      ),\n    PctEdHS = EduHS / TotalEdu,\n    PctEduAS = EduAS / TotalEdu,\n    PctEduBA = EduBA / TotalEdu,\n    PctEduGA = EduGA / TotalEdu\n  ) %&gt;%\n  select(GEOID, starts_with(\"Pct\"))\n\n\n\n\nCode\nsales_data &lt;- sfh2123_sales_data %&gt;%\n  left_join(processed_ACS_data, by = c(\"census_tract_geoid\" = \"GEOID\"))\n\n\n\n\n\n\n\n\nCode\nlibrary(tidymodels)\ntidymodels_prefer()\n\n\n\n\n\n\nCode\nset.seed(123) \nsales_split &lt;- initial_split(sales_data, strata = sale_price)\nsales_train &lt;- training(sales_split)\nsales_test  &lt;- testing(sales_split)\n\nset.seed(234) \nsales_resamples &lt;- vfold_cv(sales_train, v = 5, strata = sale_price)\n\n\n\n\n\n\n\nCode\nlibrary(rules)\n\ndefault_recipe &lt;- sales_data %&gt;%    \n  recipe(sale_price ~ year_built + building_sqft + land_sqft + num_bedrooms + num_rooms + num_full_baths + num_half_baths + num_fireplaces + type_of_residence + construction_quality + attic_finish + garage_size + ext_wall_material + basement_type + central_heating + roof_material + porch + central_air + neighborhood_code + school_elementary_district_name + Pct00_17 + Pct65p + PctEdHS + PctEduAS + PctEduBA + PctEduGA, data = .) %&gt;%    \n  step_string2factor(all_string()) %&gt;%    \n  step_impute_knn(all_predictors()) %&gt;%   \n  step_novel(all_nominal_predictors()) %&gt;%   \n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors())\n\nnormalized_recipe &lt;- default_recipe %&gt;%\n  step_normalize(all_predictors())\n\n\n\n\n\n\n\nCode\nlinear_reg_spec &lt;- \n  linear_reg(penalty = tune(), mixture = tune()) %&gt;% \n  set_engine(\"glmnet\")\n\nrf_spec &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 500) %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"regression\")\n\nxgb_spec &lt;- \n  boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), min_n = tune(), sample_size = tune(), trees = tune()) %&gt;% \n  set_engine(\"xgboost\") %&gt;% \n  set_mode(\"regression\")\n\ncubist_spec &lt;- \n   cubist_rules(committees = tune(), neighbors = tune()) %&gt;% \n   set_engine(\"Cubist\") \n\n\n\n\n\n\n\nCode\nnormalized &lt;- workflow_set(\n  preproc = list(normalized = normalized_recipe),\n  models = list(linear_reg = linear_reg_spec))\n\nno_pre_proc &lt;- workflow_set(\n  preproc = list(simple = default_recipe), \n  models = list(RF = rf_spec, boosting = xgb_spec, Cubist = cubist_spec))\n\n\n\n\nCode\nall_workflows &lt;- bind_rows(no_pre_proc, normalized)\n\n\n\n\nCode\nlibrary(finetune)\n\ngrid_results &lt;- all_workflows %&gt;%\n  workflow_map(\n    \"tune_race_anova\",\n    seed = 345,\n    resamples = sales_resamples,\n    grid = 20,\n    control = control_race(\n      save_pred = FALSE,\n      save_workflow = FALSE,\n      parallel_over = \"everything\"),\n    verbose = TRUE)\n\n\n\n\n\n\n\nCode\ngrid_results %&gt;% \n  rank_results() %&gt;%\n  filter(.metric == \"rmse\") %&gt;% \n  select(model, .config, rmse = mean, rank) %&gt;%\n  knitr::kable()\n\n\n\n\n\nmodel\n.config\nrmse\nrank\n\n\n\n\nboost_tree\nPreprocessor1_Model06\n99370.41\n1\n\n\nboost_tree\nPreprocessor1_Model03\n99735.99\n2\n\n\nboost_tree\nPreprocessor1_Model12\n99814.43\n3\n\n\ncubist_rules\nPreprocessor1_Model11\n100449.81\n4\n\n\nlinear_reg\nPreprocessor1_Model02\n100467.61\n5\n\n\nlinear_reg\nPreprocessor1_Model09\n100468.87\n6\n\n\nlinear_reg\nPreprocessor1_Model06\n100469.72\n7\n\n\nlinear_reg\nPreprocessor1_Model04\n100471.87\n8\n\n\nlinear_reg\nPreprocessor1_Model05\n100473.77\n9\n\n\nlinear_reg\nPreprocessor1_Model14\n100495.85\n10\n\n\nlinear_reg\nPreprocessor1_Model17\n100509.72\n11\n\n\nlinear_reg\nPreprocessor1_Model07\n100596.77\n12\n\n\nlinear_reg\nPreprocessor1_Model03\n100607.02\n13\n\n\nlinear_reg\nPreprocessor1_Model08\n100609.04\n14\n\n\nlinear_reg\nPreprocessor1_Model10\n100618.31\n15\n\n\nlinear_reg\nPreprocessor1_Model01\n100619.02\n16\n\n\nlinear_reg\nPreprocessor1_Model11\n100623.54\n17\n\n\nlinear_reg\nPreprocessor1_Model12\n100623.87\n18\n\n\nlinear_reg\nPreprocessor1_Model13\n100625.73\n19\n\n\nlinear_reg\nPreprocessor1_Model20\n100626.77\n20\n\n\nlinear_reg\nPreprocessor1_Model15\n100636.52\n21\n\n\nlinear_reg\nPreprocessor1_Model18\n100639.10\n22\n\n\nlinear_reg\nPreprocessor1_Model16\n100639.61\n23\n\n\nlinear_reg\nPreprocessor1_Model19\n100639.78\n24\n\n\ncubist_rules\nPreprocessor1_Model18\n100685.93\n25\n\n\nboost_tree\nPreprocessor1_Model17\n100872.65\n26\n\n\ncubist_rules\nPreprocessor1_Model10\n101008.70\n27\n\n\nrand_forest\nPreprocessor1_Model10\n101067.44\n28\n\n\ncubist_rules\nPreprocessor1_Model05\n101168.22\n29\n\n\nrand_forest\nPreprocessor1_Model20\n101281.61\n30\n\n\ncubist_rules\nPreprocessor1_Model13\n101345.31\n31\n\n\nrand_forest\nPreprocessor1_Model04\n101447.32\n32\n\n\nrand_forest\nPreprocessor1_Model06\n101563.37\n33\n\n\nrand_forest\nPreprocessor1_Model08\n101605.92\n34\n\n\nrand_forest\nPreprocessor1_Model09\n101621.71\n35\n\n\nrand_forest\nPreprocessor1_Model15\n101802.36\n36\n\n\nrand_forest\nPreprocessor1_Model13\n101962.18\n37\n\n\ncubist_rules\nPreprocessor1_Model15\n102245.67\n38\n\n\nrand_forest\nPreprocessor1_Model07\n102303.67\n39\n\n\ncubist_rules\nPreprocessor1_Model08\n102579.22\n40\n\n\nrand_forest\nPreprocessor1_Model11\n102676.19\n41\n\n\ncubist_rules\nPreprocessor1_Model03\n102720.11\n42\n\n\ncubist_rules\nPreprocessor1_Model02\n102905.93\n43\n\n\nrand_forest\nPreprocessor1_Model12\n102954.36\n44\n\n\nrand_forest\nPreprocessor1_Model05\n103011.92\n45\n\n\nrand_forest\nPreprocessor1_Model19\n103225.46\n46\n\n\nrand_forest\nPreprocessor1_Model17\n103241.71\n47\n\n\nrand_forest\nPreprocessor1_Model02\n103569.38\n48\n\n\nboost_tree\nPreprocessor1_Model14\n103886.69\n49\n\n\nrand_forest\nPreprocessor1_Model01\n103956.00\n50\n\n\nboost_tree\nPreprocessor1_Model07\n104158.37\n51\n\n\nrand_forest\nPreprocessor1_Model16\n104162.49\n52\n\n\nboost_tree\nPreprocessor1_Model16\n104173.77\n53\n\n\nboost_tree\nPreprocessor1_Model20\n104218.78\n54\n\n\nboost_tree\nPreprocessor1_Model15\n104251.63\n55\n\n\nboost_tree\nPreprocessor1_Model10\n104264.46\n56\n\n\nboost_tree\nPreprocessor1_Model01\n104790.26\n57\n\n\nboost_tree\nPreprocessor1_Model09\n104876.53\n58\n\n\nrand_forest\nPreprocessor1_Model18\n104881.21\n59\n\n\nrand_forest\nPreprocessor1_Model03\n104989.63\n60\n\n\n\n\n\n\n\nCode\nautoplot(\n  grid_results,\n  rank_metric = \"rmse\",\n  metric = \"rmse\", \n  select_best = TRUE\n ) +\n  geom_text(aes(y = mean - 1/2, label = wflow_id), angle = 90, vjust = -0.5) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbest_wf &lt;- grid_results %&gt;% \n  rank_results() %&gt;%\n  filter(.metric == \"rmse\", rank == 1) %&gt;%\n  pull(wflow_id)\n\nbest_results &lt;- grid_results %&gt;%\n  extract_workflow_set_result(best_wf) %&gt;% \n  select_best(metric = \"rmse\") \n\nbest_results_fit &lt;- \n  grid_results %&gt;% \n  extract_workflow(best_wf) %&gt;%\n  finalize_workflow(best_results) %&gt;% \n  last_fit(split = sales_split)\n\n\n\n\n\n\n\nCode\nbest_results_fit %&gt;% \n  collect_predictions() %&gt;% \n  ggplot(aes(x = sale_price, y = .pred)) + \n  geom_abline(color = \"gray50\", lty = 2) + \n  geom_point(alpha = 0.5) + \n  coord_obs_pred() + \n  labs(x = \"observed\", y = \"predicted\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbayes_results &lt;- grid_results %&gt;% \n  extract_workflow(best_wf) %&gt;%\n  tune_bayes(\n    resamples = sales_resamples,\n    initial = 6,\n    iter = 25,\n    control = control_bayes(verbose = TRUE)\n  )\n\n\n\n\n\n\n\nCode\nbayes_results %&gt;%\n  show_best(metric = \"rmse\") %&gt;% \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrees\nmin_n\ntree_depth\nlearn_rate\nloss_reduction\nsample_size\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n.iter\n\n\n\n\n1531\n13\n2\n0.0145856\n0.0000095\n0.2282499\nrmse\nstandard\n98862.69\n5\n10018.769\nPreprocessor1_Model2\n0\n\n\n402\n13\n5\n0.0121933\n24.3073101\n0.1917696\nrmse\nstandard\n100612.56\n5\n10541.353\nIter10\n10\n\n\n833\n35\n10\n0.0055546\n6.5822950\n0.4633506\nrmse\nstandard\n103436.17\n5\n10745.935\nPreprocessor1_Model6\n0\n\n\n1516\n29\n1\n0.0153796\n30.9923970\n0.7996068\nrmse\nstandard\n103598.27\n5\n8617.141\nIter2\n2\n\n\n1224\n33\n8\n0.0090024\n0.0005782\n0.2168532\nrmse\nstandard\n104194.76\n5\n10192.453\nIter1\n1\n\n\n\n\n\nFinal fit\n\n\nCode\nfinal_fit &lt;- grid_results %&gt;% \n  extract_workflow(best_wf) %&gt;%\n  finalize_workflow(select_best(bayes_results, metric = \"rmse\")) %&gt;% \n  last_fit(split = sales_split)\n\n\nMAPE and RMSE\n\n\nCode\nsales_preds &lt;- final_fit %&gt;% \n  pull(.predictions) %&gt;% \n  pluck(1)\n\nsales_metrics &lt;- list(   \n  sales_preds %&gt;%     \n    rmse(sale_price, .pred),   \n  sales_preds %&gt;%     \n    mape(sale_price, .pred)) \n\nsales_metrics %&gt;% bind_rows() %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n93988.148\n\n\nmape\nstandard\n16.027\n\n\n\n\n\n\n\n\n\nOver the course of the Cook County assessment project, I have tested several different models. All of these models exhibited RMSEs in excess of 90,000. This means that on average predictions produced by the models deviated from the true sale price by at least $90,000. Although the predictions seem quite awful, I think that these predictions point to the fact that house value prediction is a difficult problem. There exists a multitude of factors that the assessor is barred from using to predict house values and there exists a large number of factors which are not easily translated into machine learning features (e.g., housing aesthetics, human psychology, etc.).\nAs compared to the assessor’s model, my model seems to have a similar RMSE; however, the assessor’s model median assessment tends to be less than 85% of the sale price. So the assessor’s model continually underassesses the true value of the homes. Both the my model and the assessor’s are variants of Gradient Boosted Machines. Light GBM and XGBoost often yield similar predictions; however, LightGBM is often quite faster to train.\nThere are quite a few ethical concerns that come with assessing home values through the use of machine learning. As we discussed in Part 1, housing assessments, even for the year of 2023, exhibit regressivity (i.e., lower value homes are assessed a higher proportion of their true house price). This can be hugely detrimental to the residents of these homes because it has the effect of imposing the highest tax rate on those with the least. We can see from the chart below that my model also exhibits a high degree of regresivity.\nAdditionally, machine learning cannot capture the many human aspects of a home price, which means that there are some technical challenges with distilling aspects that affect a home’s price into features usable by a machine learning algorithm.\n\n\nCode\nlibrary(cmfproperty)\n\nratios &lt;- grid_results %&gt;% \n  extract_workflow(best_wf) %&gt;%\n  finalize_workflow(select_best(bayes_results, metric = \"rmse\")) %&gt;%\n  fit(sales_train) %&gt;%\n  augment(sales_test) %&gt;%\n  select(pin, year, sale_price, .pred) %&gt;%\n  reformat_data(\n    sale_col = \"sale_price\",\n    assessment_col = \".pred\",\n    sale_year_col = \"year\")\n\nbinned &lt;- binned_scatter(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nbinned[[2]]\n\n\n\n\n\n\n\n\n\n[1] \"Filtered out non-arm's length transactions\"\n[1] \"Inflation adjusted to 2021\"\n\n\nOverall, I do not think that my model is quite as effective as that of the assessor’s, and it exhibits a high degree of regressivity. I think the model could be improved by providing it with more years of data and working to refine some additional measures not currently captured by the model. I also wonder if a more comprehensive model including data from all of the Cook County townships would produce better predictions due to the larger amount of data provided. At this point, I would not recommend that the assessor use my model."
  },
  {
    "objectID": "posts/cook_part_2/index.html",
    "href": "posts/cook_part_2/index.html",
    "title": "Cook County Property Assessment - Part 2",
    "section": "",
    "text": "There are over 1.8 million parcels in Cook County, Illinois [1]. Each of these parcels is assessed every three years using three to five years of prior sales information [1]. For this analysis, we will take a look at single family home assessments within three of the 36 political townships: Lemont (19), Palos (30), Orland (28). Using data provided on the Cook County data portal, we will will create a series of two models. Our first model will predict the likelihood of overassessment for the year of 2022, and our second model will predict home value for the year of 2023.\n\n\nWe have 4 inclusion criteria:\n\nYear - 2021, 2022, 2023\nClass - 202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278. These conform to single family homes\nTownship Code - 19 (Lemont), 30 (Palos), 28 (Orland)\nIs Multisale - No\n\n\n\nCode\nlibrary(arrow)\nlibrary(data.table)\nlibrary(dtplyr)\nlibrary(tidyverse)\n\nsfh2123_assessment &lt;-\n  open_csv_dataset(\"../data/20240217_Assessed_Values.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"township_name\", string()),\n      field(\"mailed_bldg\", int32()),\n      field(\"mailed_land\", int32()),\n      field(\"mailed_tot\", int32()),\n      field(\"certified_bldg\", int32()),\n      field(\"certified_land\", int32()),\n      field(\"certified_tot\", int32()),\n      field(\"board_bldg\", int32()),\n      field(\"board_land\", int32()),\n      field(\"board_tot\", int32()),\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_sales &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Sales.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"year\", int32()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"class\", string()),\n      field(\"sale_date\", string()),\n      field(\"is_mydec_date\", bool()),\n      field(\"sale_price\", int32()),\n      field(\"sale_document_num\", string()),\n      field(\"sale_deed_type\", string()),\n      field(\"mydec_deed_type\", string()),\n      field(\"sale_seller_name\", string()),\n      field(\"is_multisale\", bool()),\n      field(\"num_parcels_sale\", int32()),\n      field(\"sale_buyer_name\", string()),\n      field(\"sale_type\", string()),\n      field(\"sale_filter_same_sale_within_365\", bool()),\n      field(\"sale_filter_less_than_10k\", bool()),\n      field(\"sale_filter_deed_type\", bool())\n    )\n  ) %&gt;%\n  filter(year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\")) %&gt;%\n  filter(!is_multisale) \n\nsfh2123_characteristics &lt;- \n  open_csv_dataset(\"../data/20240217_Improvement_Characteristics.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"card_num\", string()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"proration_key_pin\", string()),\n      field(\"pin_proration_rate\", double()),\n      field(\"card_proration_rate\", double()),\n      field(\"cdu\", string()),\n      field(\"pin_is_multicard\", bool()),\n      field(\"pin_num_cards\", int32()),\n      field(\"pin_is_multiland\", bool()),\n      field(\"pin_num_landlines\", int32()),\n      field(\"year_built\", int32()),\n      field(\"building_sqft\", int32()),\n      field(\"land_sqft\", int32()),\n      field(\"num_bedrooms\", int32()),\n      field(\"num_rooms\", int32()),\n      field(\"num_full_baths\", int32()),\n      field(\"num_half_baths\", int32()),\n      field(\"num_fireplaces\", int32()),\n      field(\"type_of_residence\", string()),\n      field(\"construction_quality\", string()),\n      field(\"num_apartments\", string()),\n      field(\"attic_finish\", string()),\n      field(\"garage_attached\", string()),\n      field(\"garage_area_included\", string()),\n      field(\"garage_size\", string()),\n      field(\"garage_ext_wall_material\", string()),\n      field(\"attic_type\", string()),\n      field(\"basement_type\", string()),\n      field(\"ext_wall_material\", string()),\n      field(\"central_heating\", string()),\n      field(\"repair_condition\", string()),\n      field(\"basement_finish\", string()),\n      field(\"roof_material\", string()),\n      field(\"single_v_multi_family\", string()),\n      field(\"site_desirability\", string()),\n      field(\"num_commercial_units\", string()),\n      field(\"renovation\", string()),\n      field(\"recent_renovation\", bool()),\n      field(\"porch\", string()),\n      field(\"central_air\", string()),\n      field(\"design_plan\", string())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_universe &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Universe.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"pin10\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"triad_name\", string()),\n      field(\"triad_code\", string()),\n      field(\"township_name\", string()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"tax_district_code\", string()),\n      field(\"zip_code\", string()),\n      field(\"longitude\", double()),\n      field(\"latitude\", double()),\n      field(\"centroid_x_crs_3435\", double()),\n      field(\"centroid_y_crs_3435\", double()),\n      field(\"census_block_group_geoid\", string()),\n      field(\"census_block_geoid\", string()),\n      field(\"census_congressional_district_geoid\", string()),\n      field(\"census_county_subdivision_geoid\", string()),\n      field(\"census_place_geoid\", string()),\n      field(\"census_puma_geoid\", string()),\n      field(\"census_school_district_elementary_geoid\", string()),\n      field(\"census_school_district_secondary_geoid\", string()),\n      field(\"census_school_district_unified_geoid\", string()),\n      field(\"census_state_representative_geoid\", string()),\n      field(\"census_state_senate_geoid\", string()),\n      field(\"census_tract_geoid\", string()),\n      field(\"census_zcta_geoid\", string()),\n      field(\"census_data_year\", int32()),\n      field(\"census_acs5_congressional_district_geoid\", string()),\n      field(\"census_acs5_county_subdivision_geoid\", string()),\n      field(\"census_acs5_place_geoid\", string()),\n      field(\"census_acs5_puma_geoid\", string()),\n      field(\"census_acs5_school_district_elementary_geoid\", string()),\n      field(\"census_acs5_school_district_secondary_geoid\", string()),\n      field(\"census_acs5_school_district_unified_geoid\", string()),\n      field(\"census_acs5_state_representative_geoid\", string()),\n      field(\"census_acs5_state_senate_geoid\", string()),\n      field(\"census_acs5_tract_geoid\", string()),\n      field(\"census_acs5_data_year\", int32()),\n      field(\"board_of_review_district_num\", string()),\n      field(\"board_of_review_district_data_year\", int32()),\n      field(\"commissioner_district_num\", string()),\n      field(\"commissioner_district_data_year\", int32()),\n      field(\"judicial_district_num\", string()),\n      field(\"judicial_district_data_year\", int32()),\n      field(\"ward_num\", string()),\n      field(\"ward_chicago_data_year\", int32()),\n      field(\"ward_evanston_data_year\", int32()),\n      field(\"chicago_community_area_num\", string()),\n      field(\"chicago_community_area_name\", string()),\n      field(\"chicago_community_area_data_year\", int32()),\n      field(\"chicago_industrial_corridor_num\", string()),\n      field(\"chicago_industrial_corridor_name\", string()),\n      field(\"chicago_industrial_corridor_data_year\", int32()),\n      field(\"chicago_police_district_num\", string()),\n      field(\"chicago_police_district_data_year\", int32()),\n      field(\"coordinated_care_area_num\", string()),\n      field(\"coordinated_care_area_data_year\", int32()),\n      field(\"enterprise_zone_num\", string()),\n      field(\"enterprise_zone_data_year\", int32()),\n      field(\"industrial_growth_zone_num\", string()),\n      field(\"industrial_growth_zone_data_year\", int32()),\n      field(\"qualified_opportunity_zone_num\", string()),\n      field(\"qualified_opportunity_zone_data_year\", int32()),\n      field(\"flood_fema_sfha\", bool()),\n      field(\"flood_fema_data_year\", int32()),\n      field(\"flood_fs_factor\", int32()),\n      field(\"flood_fs_risk_direction\", int32()),\n      field(\"flood_fs_data_year\", int32()),\n      field(\"ohare_noise_contour_no_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_half_mile_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_data_year\", int32()),\n      field(\"airport_noise_dnl\", double()),\n      field(\"airport_noise_data_year\", string()),\n      field(\"school_elementary_district_geoid\", string()),\n      field(\"school_elementary_district_name\", string()),\n      field(\"school_secondary_district_geoid\", string()),\n      field(\"school_secondary_district_name\", string()),\n      field(\"school_unified_district_geoid\", string()),\n      field(\"school_unified_district_name\", string()),\n      field(\"school_year\", string()),\n      field(\"school_data_year\", int32()),\n      field(\"tax_municipality_num\", string()),\n      field(\"tax_municipality_name\", string()),\n      field(\"tax_school_elementary_district_num\", string()),\n      field(\"tax_school_elementary_district_name\", string()),\n      field(\"tax_school_secondary_district_num\", string()),\n      field(\"tax_school_secondary_district_name\", string()),\n      field(\"tax_school_unified_district_num\", string()),\n      field(\"tax_school_unified_district_name\", string()),\n      field(\"tax_community_college_district_num\", string()),\n      field(\"tax_community_college_district_name\", string()),\n      field(\"tax_fire_protection_district_num\", string()),\n      field(\"tax_fire_protection_district_name\", string()),\n      field(\"tax_library_district_num\", string()),\n      field(\"tax_library_district_name\", string()),\n      field(\"tax_park_district_num\", string()),\n      field(\"tax_park_district_name\", string()),\n      field(\"tax_sanitation_district_num\", string()),\n      field(\"tax_sanitation_district_name\", string()),\n      field(\"tax_special_service_area_num\", string()),\n      field(\"tax_special_service_area_name\", string()),\n      field(\"tax_tif_district_num\", string()),\n      field(\"tax_tif_district_name\", string()),\n      field(\"tax_districts_data_year\", int32()),\n      field(\"cmap_walkability_grid_id\", string()),\n      field(\"cmap_walkability_no_transit_score\", double()),\n      field(\"cmap_walkability_total_score\", double()),\n      field(\"cmap_walkability_data_year\", int32()),\n      field(\"subdivision_id\", string()),\n      field(\"subdivision_data_year\", int32())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_assessment_dt &lt;- sfh2123_assessment %&gt;% as.data.table()\nsfh2123_sales_dt &lt;- sfh2123_sales %&gt;% as.data.table()\nsfh2123_characteristics_dt &lt;- sfh2123_characteristics %&gt;% as.data.table()\nsfh2123_universe_dt &lt;- sfh2123_universe %&gt;% as.data.table()\n\n\n\n\n\n\n\nCode\nsfh2123_sales_AT &lt;- sfh2123_sales_dt %&gt;%\n  lazy_dt() %&gt;%\n  left_join(sfh2123_assessment_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"neighborhood_code\", \"township_code\", \"township_name\", \"class\", \"year\" = \"tax_year\")) %&gt;%\n  mutate(sale_price_ratio = 10 * certified_tot / sale_price) %&gt;%\n  collect()\n\nsfh2123_assessment_AT &lt;- sfh2123_assessment_dt %&gt;% \n  lazy_dt() %&gt;%\n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"township_code\", \"township_name\", \"class\", \"tax_year\")) %&gt;%\n  collect()\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\n\nsfh2123_sales_AT %&gt;%\n  mutate(id = row_number()) %&gt;%\n  tidyr::gather(-id, key = \"key\", value = \"val\") %&gt;%\n  mutate(isna = is.na(val)) %&gt;%\n  ggplot(aes(key, id, fill = isna)) +\n    geom_raster(alpha=0.8) +\n    scale_fill_manual(name = \"\",\n        values = c('steelblue', 'tomato3'),\n        labels = c(\"Present\", \"Missing\")) +\n    labs(x = \"Variable\",\n           y = \"Row Number\", title = \"Missing Values for Housing Sales\") +\n    coord_flip()\n\n\n\n\n\n\n\n\n\nIt seems like we have quite a few measures that are either entirely missing or have quite a few missing values. This is okay because we won’t be using all of our variables in order to reduce the complexity and increase the interpretability of our model.\n\n\n\n\n\nCode\nlibrary(corrr)\n\nsfh2123_sales_AT %&gt;%\n  select(c(sale_price, certified_tot, year_built, building_sqft, land_sqft, num_bedrooms, num_rooms, num_full_baths, num_half_baths, num_fireplaces, cmap_walkability_no_transit_score, cmap_walkability_total_score)) %&gt;%\n  select(where(is.numeric)) %&gt;%\n  select(where(function(x) sum(!is.na(x)) != 0)) %&gt;%\n  select(where(function(x) var(x, na.rm = TRUE) != 0)) %&gt;% \n  correlate(method = \"spearman\") %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\nThere seems to be a high level of correlation between many of the housing characteristics. Perhaps using a model that takes in account multicollinearity would be a good idea.\n\n\n\n\nYear BuiltBuilding SqFtLand SqFtBedsRoomsBathroomsWalkability\n\n\n\n\nCode\nlibrary(scales)\n\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = year_built, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Year Built \\nand Sale Price in Cook County, IL\", \n      x = \"Year Built\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nMore recently built houses seem to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = building_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Building Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Building Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nLarger building houses tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = land_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Land Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Land Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nThe relationship here isn’t entirely clear, but it seems that more land sells for more, up until some point\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_bedrooms, y = sale_price, fill = factor(num_bedrooms))) +\n    scale_x_continuous(n.breaks = 9) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Bedrooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Bedrooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bedrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_rooms, y = sale_price, fill = factor(num_rooms))) +\n    geom_smooth(aes(x = num_rooms, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Rooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Rooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more rooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price, fill = factor(num_full_baths + num_half_baths * 0.5))) +\n    geom_smooth(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Total Number of Baths \\nand Sale Price in Cook County, IL\", \n      x = \"Total Number of Baths\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bathrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = cmap_walkability_total_score, y = sale_price, fill = factor(cmap_walkability_total_score))) +\n    geom_smooth(aes(x = cmap_walkability_total_score, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home CMAP Walkability and \\nSale Price in Cook County, IL\", \n      x = \"Total Walkability Score\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with in less walkable communities tend to sell for more. Although it seems like individuals might want to live in more walkable communities. The kind of large single family homes that tend to sell for more actually contribute toward reducing walkability, which is most likely why we see a downward trend.\n\n\n\n\n\n\nJoining our geospatial data.\n\n\nCode\nlibrary(sf)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n  filter(NAME %in% c(\"LEMONT\", \"PALOS\", \"ORLAND\")) %&gt;%\n  left_join(\n    sfh2123_sales_AT %&gt;%\n      group_by(township_code) %&gt;%\n      summarize(\n        median_sp = median(sale_price), \n        median_spr = median(sale_price_ratio))  %&gt;%\n      transmute(median_sp, median_spr, NAME = case_when(\n        township_code == \"19\" ~ \"LEMONT\",\n        township_code == \"30\" ~ \"PALOS\",\n        township_code == \"28\" ~ \"ORLAND\",\n      )\n    )\n  )\n\nsfh2123_sales_sf &lt;- sfh2123_sales_AT %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"))\n\n\n\nSale PricesAssessment to Sale Price Ratio\n\n\n\n\nCode\nlibrary(leaflet)\n\nqpal1 &lt;- colorQuantile(\"Greens\", sfh2123_sales_sf$sale_price, n = 5)\n\nsfh2123_sales_sf %&gt;%\n  leaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n      data = townships,\n      fillColor = \"black\",\n      fillOpacity = 0.1,\n      color = \"black\",\n      weight = 2,\n      opacity = 0.5,\n      highlightOptions = highlightOptions(\n        fillOpacity = 0.2,\n        weight = 3),\n      label = sprintf(\n        \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Median Sale: %s&lt;br/&gt;\",\n        townships$NAME,\n        label_currency()(townships$median_sp)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addCircleMarkers(\n      radius = 3,\n      fillColor = ~ qpal1(sale_price),\n      fillOpacity = 0.7,\n      stroke = FALSE,\n      label = sprintf(\n        \"&lt;strong&gt;Sale Price:&lt;/strong&gt; %s\",\n        label_currency()(sfh2123_sales_sf$sale_price)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addLegend(\n      pal = qpal1,\n      values = sfh2123_sales_sf$sale_price,\n      opacity = 0.7,\n      title = \"Sale Price of Single &lt;br&gt;Family Homes in Cook &lt;br&gt;County\",\n      position = \"topright\",\n      na.label = \"Insufficient Data\",\n      labFormat = function(type, cuts, p) {\n        n = length(cuts)\n        p = str_c(round(p * 100), '%')\n        cuts = str_c(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n        str_c('&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts, '&lt;/span&gt;')\n      })\n\n\n\n\n\n\nIt seems that there is clustering of similarly priced homes within our three townships. Lemont has the highest median sale price, but Palos and Orland have similar median sale prices. Perhaps using a spatial modeling technique like a spatial Bayesian or conditional autoregressive model is waranted.\n\n\nCode\nlibrary(spdep)\n\nknn &lt;- knearneigh(sfh2123_sales_sf, k = 20)\nnb &lt;- knn2nb(knn)\nweights &lt;- nb2listw(nb, style = \"B\")\n\nmoran.test(x = sfh2123_sales_sf$sale_price, listw = weights, zero.policy = TRUE) %&gt;% \n  broom::tidy() %&gt;% \n  select(estimate1, p.value, method) %&gt;%\n  rename(`Moran I statistic` = estimate1) %&gt;%\n  knitr::kable()\n\n\n\n\n\nMoran I statistic\np.value\nmethod\n\n\n\n\n0.4998853\n0\nMoran I test under randomisation\n\n\n\n\n\n\n\n\n\nCode\nqpal2 &lt;- colorQuantile(\"RdBu\", sfh2123_sales_sf$sale_price_ratio, n = 5)\n\nsfh2123_sales_sf %&gt;%\n  leaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n      data = townships,\n      fillColor = \"black\",\n      fillOpacity = 0.1,\n      color = \"black\",\n      weight = 2,\n      opacity = 0.5,\n      highlightOptions = highlightOptions(\n        fillOpacity = 0.2,\n        weight = 3),\n      label = sprintf(\n        \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Median Sale Price Ratio: %s&lt;br/&gt;\",\n        townships$NAME,\n        label_number(0.001)(townships$median_spr)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addCircleMarkers(\n      radius = 3,\n      fillColor = ~ qpal2(sale_price_ratio),\n      fillOpacity = 0.7,\n      stroke = FALSE,\n      label = sprintf(\n        \"&lt;strong&gt;Sale Price Ratio:&lt;/strong&gt; %s\",\n        label_number(0.001)(sfh2123_sales_sf$sale_price_ratio)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addLegend(\n      pal = qpal2,\n      values = sfh2123_sales_sf$sale_price_ratio,\n      opacity = 0.7,\n      title = \"Assessment to Sale Price &lt;br&gt;Ratio of Single Family&lt;br&gt; Homes in Cook County\",\n      position = \"topright\",\n      na.label = \"Insufficient Data\",\n      labFormat = function(type, cuts, p) {\n        n = length(cuts)\n        p = str_c(round(p * 100), '%')\n        cuts = str_c(label_number(0.001)(cuts[-n]), \" - \", label_number(0.001)(cuts[-1]))\n        str_c('&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts, '&lt;/span&gt;')\n      })\n\n\n\n\n\n\nIt seems like the over/under assessment of properties does not exhibit much clustering so perhaps there are other variables that we should have to consider. There are some values that seem like they may be large outliers.\n\n\n\n\n\n\nFor our over/under assessment model, I will define over assessment as greater than the median sale_price_ratio. Theoretically, this should be 1, but parcels are so routinely under assessed as compared to their true sale value that a threshold of 1 would place almost all houses in the under assessed category. I also chose a two class outcome in order to avoid potential complexities related to multiple classification models. I also considered creating a regression model that predicted assessment ratios and simply discretizing the predictions later, but opted against it.\nIt also important to note that our assessment model will only include data from 2022 and our sale price model will include data from 2021 and 2022. Although prices may be slightly different in these years,\n\n\nCode\nassessment_data &lt;- sfh2123_sales_AT %&gt;%\n  filter(year == 2022) %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;%\n  ungroup() %&gt;%\n  mutate(overassessed = factor(sale_price_ratio &lt; median(sale_price_ratio)))\n\nsales_data &lt;- sfh2123_sales_AT %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\")) %&gt;%\n  st_set_crs(4326)"
  },
  {
    "objectID": "posts/cook_part_2/index.html#part-a",
    "href": "posts/cook_part_2/index.html#part-a",
    "title": "Cook County Property Assessment - Part 2",
    "section": "",
    "text": "There are over 1.8 million parcels in Cook County, Illinois [1]. Each of these parcels is assessed every three years using three to five years of prior sales information [1]. For this analysis, we will take a look at single family home assessments within three of the 36 political townships: Lemont (19), Palos (30), Orland (28). Using data provided on the Cook County data portal, we will will create a series of two models. Our first model will predict the likelihood of overassessment for the year of 2022, and our second model will predict home value for the year of 2023.\n\n\nWe have 4 inclusion criteria:\n\nYear - 2021, 2022, 2023\nClass - 202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278. These conform to single family homes\nTownship Code - 19 (Lemont), 30 (Palos), 28 (Orland)\nIs Multisale - No\n\n\n\nCode\nlibrary(arrow)\nlibrary(data.table)\nlibrary(dtplyr)\nlibrary(tidyverse)\n\nsfh2123_assessment &lt;-\n  open_csv_dataset(\"../data/20240217_Assessed_Values.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"township_name\", string()),\n      field(\"mailed_bldg\", int32()),\n      field(\"mailed_land\", int32()),\n      field(\"mailed_tot\", int32()),\n      field(\"certified_bldg\", int32()),\n      field(\"certified_land\", int32()),\n      field(\"certified_tot\", int32()),\n      field(\"board_bldg\", int32()),\n      field(\"board_land\", int32()),\n      field(\"board_tot\", int32()),\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_sales &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Sales.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"year\", int32()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"class\", string()),\n      field(\"sale_date\", string()),\n      field(\"is_mydec_date\", bool()),\n      field(\"sale_price\", int32()),\n      field(\"sale_document_num\", string()),\n      field(\"sale_deed_type\", string()),\n      field(\"mydec_deed_type\", string()),\n      field(\"sale_seller_name\", string()),\n      field(\"is_multisale\", bool()),\n      field(\"num_parcels_sale\", int32()),\n      field(\"sale_buyer_name\", string()),\n      field(\"sale_type\", string()),\n      field(\"sale_filter_same_sale_within_365\", bool()),\n      field(\"sale_filter_less_than_10k\", bool()),\n      field(\"sale_filter_deed_type\", bool())\n    )\n  ) %&gt;%\n  filter(year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\")) %&gt;%\n  filter(!is_multisale) \n\nsfh2123_characteristics &lt;- \n  open_csv_dataset(\"../data/20240217_Improvement_Characteristics.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"card_num\", string()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"proration_key_pin\", string()),\n      field(\"pin_proration_rate\", double()),\n      field(\"card_proration_rate\", double()),\n      field(\"cdu\", string()),\n      field(\"pin_is_multicard\", bool()),\n      field(\"pin_num_cards\", int32()),\n      field(\"pin_is_multiland\", bool()),\n      field(\"pin_num_landlines\", int32()),\n      field(\"year_built\", int32()),\n      field(\"building_sqft\", int32()),\n      field(\"land_sqft\", int32()),\n      field(\"num_bedrooms\", int32()),\n      field(\"num_rooms\", int32()),\n      field(\"num_full_baths\", int32()),\n      field(\"num_half_baths\", int32()),\n      field(\"num_fireplaces\", int32()),\n      field(\"type_of_residence\", string()),\n      field(\"construction_quality\", string()),\n      field(\"num_apartments\", string()),\n      field(\"attic_finish\", string()),\n      field(\"garage_attached\", string()),\n      field(\"garage_area_included\", string()),\n      field(\"garage_size\", string()),\n      field(\"garage_ext_wall_material\", string()),\n      field(\"attic_type\", string()),\n      field(\"basement_type\", string()),\n      field(\"ext_wall_material\", string()),\n      field(\"central_heating\", string()),\n      field(\"repair_condition\", string()),\n      field(\"basement_finish\", string()),\n      field(\"roof_material\", string()),\n      field(\"single_v_multi_family\", string()),\n      field(\"site_desirability\", string()),\n      field(\"num_commercial_units\", string()),\n      field(\"renovation\", string()),\n      field(\"recent_renovation\", bool()),\n      field(\"porch\", string()),\n      field(\"central_air\", string()),\n      field(\"design_plan\", string())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_universe &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Universe.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"pin10\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"triad_name\", string()),\n      field(\"triad_code\", string()),\n      field(\"township_name\", string()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"tax_district_code\", string()),\n      field(\"zip_code\", string()),\n      field(\"longitude\", double()),\n      field(\"latitude\", double()),\n      field(\"centroid_x_crs_3435\", double()),\n      field(\"centroid_y_crs_3435\", double()),\n      field(\"census_block_group_geoid\", string()),\n      field(\"census_block_geoid\", string()),\n      field(\"census_congressional_district_geoid\", string()),\n      field(\"census_county_subdivision_geoid\", string()),\n      field(\"census_place_geoid\", string()),\n      field(\"census_puma_geoid\", string()),\n      field(\"census_school_district_elementary_geoid\", string()),\n      field(\"census_school_district_secondary_geoid\", string()),\n      field(\"census_school_district_unified_geoid\", string()),\n      field(\"census_state_representative_geoid\", string()),\n      field(\"census_state_senate_geoid\", string()),\n      field(\"census_tract_geoid\", string()),\n      field(\"census_zcta_geoid\", string()),\n      field(\"census_data_year\", int32()),\n      field(\"census_acs5_congressional_district_geoid\", string()),\n      field(\"census_acs5_county_subdivision_geoid\", string()),\n      field(\"census_acs5_place_geoid\", string()),\n      field(\"census_acs5_puma_geoid\", string()),\n      field(\"census_acs5_school_district_elementary_geoid\", string()),\n      field(\"census_acs5_school_district_secondary_geoid\", string()),\n      field(\"census_acs5_school_district_unified_geoid\", string()),\n      field(\"census_acs5_state_representative_geoid\", string()),\n      field(\"census_acs5_state_senate_geoid\", string()),\n      field(\"census_acs5_tract_geoid\", string()),\n      field(\"census_acs5_data_year\", int32()),\n      field(\"board_of_review_district_num\", string()),\n      field(\"board_of_review_district_data_year\", int32()),\n      field(\"commissioner_district_num\", string()),\n      field(\"commissioner_district_data_year\", int32()),\n      field(\"judicial_district_num\", string()),\n      field(\"judicial_district_data_year\", int32()),\n      field(\"ward_num\", string()),\n      field(\"ward_chicago_data_year\", int32()),\n      field(\"ward_evanston_data_year\", int32()),\n      field(\"chicago_community_area_num\", string()),\n      field(\"chicago_community_area_name\", string()),\n      field(\"chicago_community_area_data_year\", int32()),\n      field(\"chicago_industrial_corridor_num\", string()),\n      field(\"chicago_industrial_corridor_name\", string()),\n      field(\"chicago_industrial_corridor_data_year\", int32()),\n      field(\"chicago_police_district_num\", string()),\n      field(\"chicago_police_district_data_year\", int32()),\n      field(\"coordinated_care_area_num\", string()),\n      field(\"coordinated_care_area_data_year\", int32()),\n      field(\"enterprise_zone_num\", string()),\n      field(\"enterprise_zone_data_year\", int32()),\n      field(\"industrial_growth_zone_num\", string()),\n      field(\"industrial_growth_zone_data_year\", int32()),\n      field(\"qualified_opportunity_zone_num\", string()),\n      field(\"qualified_opportunity_zone_data_year\", int32()),\n      field(\"flood_fema_sfha\", bool()),\n      field(\"flood_fema_data_year\", int32()),\n      field(\"flood_fs_factor\", int32()),\n      field(\"flood_fs_risk_direction\", int32()),\n      field(\"flood_fs_data_year\", int32()),\n      field(\"ohare_noise_contour_no_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_half_mile_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_data_year\", int32()),\n      field(\"airport_noise_dnl\", double()),\n      field(\"airport_noise_data_year\", string()),\n      field(\"school_elementary_district_geoid\", string()),\n      field(\"school_elementary_district_name\", string()),\n      field(\"school_secondary_district_geoid\", string()),\n      field(\"school_secondary_district_name\", string()),\n      field(\"school_unified_district_geoid\", string()),\n      field(\"school_unified_district_name\", string()),\n      field(\"school_year\", string()),\n      field(\"school_data_year\", int32()),\n      field(\"tax_municipality_num\", string()),\n      field(\"tax_municipality_name\", string()),\n      field(\"tax_school_elementary_district_num\", string()),\n      field(\"tax_school_elementary_district_name\", string()),\n      field(\"tax_school_secondary_district_num\", string()),\n      field(\"tax_school_secondary_district_name\", string()),\n      field(\"tax_school_unified_district_num\", string()),\n      field(\"tax_school_unified_district_name\", string()),\n      field(\"tax_community_college_district_num\", string()),\n      field(\"tax_community_college_district_name\", string()),\n      field(\"tax_fire_protection_district_num\", string()),\n      field(\"tax_fire_protection_district_name\", string()),\n      field(\"tax_library_district_num\", string()),\n      field(\"tax_library_district_name\", string()),\n      field(\"tax_park_district_num\", string()),\n      field(\"tax_park_district_name\", string()),\n      field(\"tax_sanitation_district_num\", string()),\n      field(\"tax_sanitation_district_name\", string()),\n      field(\"tax_special_service_area_num\", string()),\n      field(\"tax_special_service_area_name\", string()),\n      field(\"tax_tif_district_num\", string()),\n      field(\"tax_tif_district_name\", string()),\n      field(\"tax_districts_data_year\", int32()),\n      field(\"cmap_walkability_grid_id\", string()),\n      field(\"cmap_walkability_no_transit_score\", double()),\n      field(\"cmap_walkability_total_score\", double()),\n      field(\"cmap_walkability_data_year\", int32()),\n      field(\"subdivision_id\", string()),\n      field(\"subdivision_data_year\", int32())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_assessment_dt &lt;- sfh2123_assessment %&gt;% as.data.table()\nsfh2123_sales_dt &lt;- sfh2123_sales %&gt;% as.data.table()\nsfh2123_characteristics_dt &lt;- sfh2123_characteristics %&gt;% as.data.table()\nsfh2123_universe_dt &lt;- sfh2123_universe %&gt;% as.data.table()\n\n\n\n\n\n\n\nCode\nsfh2123_sales_AT &lt;- sfh2123_sales_dt %&gt;%\n  lazy_dt() %&gt;%\n  left_join(sfh2123_assessment_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"neighborhood_code\", \"township_code\", \"township_name\", \"class\", \"year\" = \"tax_year\")) %&gt;%\n  mutate(sale_price_ratio = 10 * certified_tot / sale_price) %&gt;%\n  collect()\n\nsfh2123_assessment_AT &lt;- sfh2123_assessment_dt %&gt;% \n  lazy_dt() %&gt;%\n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"township_code\", \"township_name\", \"class\", \"tax_year\")) %&gt;%\n  collect()\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\n\nsfh2123_sales_AT %&gt;%\n  mutate(id = row_number()) %&gt;%\n  tidyr::gather(-id, key = \"key\", value = \"val\") %&gt;%\n  mutate(isna = is.na(val)) %&gt;%\n  ggplot(aes(key, id, fill = isna)) +\n    geom_raster(alpha=0.8) +\n    scale_fill_manual(name = \"\",\n        values = c('steelblue', 'tomato3'),\n        labels = c(\"Present\", \"Missing\")) +\n    labs(x = \"Variable\",\n           y = \"Row Number\", title = \"Missing Values for Housing Sales\") +\n    coord_flip()\n\n\n\n\n\n\n\n\n\nIt seems like we have quite a few measures that are either entirely missing or have quite a few missing values. This is okay because we won’t be using all of our variables in order to reduce the complexity and increase the interpretability of our model.\n\n\n\n\n\nCode\nlibrary(corrr)\n\nsfh2123_sales_AT %&gt;%\n  select(c(sale_price, certified_tot, year_built, building_sqft, land_sqft, num_bedrooms, num_rooms, num_full_baths, num_half_baths, num_fireplaces, cmap_walkability_no_transit_score, cmap_walkability_total_score)) %&gt;%\n  select(where(is.numeric)) %&gt;%\n  select(where(function(x) sum(!is.na(x)) != 0)) %&gt;%\n  select(where(function(x) var(x, na.rm = TRUE) != 0)) %&gt;% \n  correlate(method = \"spearman\") %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\nThere seems to be a high level of correlation between many of the housing characteristics. Perhaps using a model that takes in account multicollinearity would be a good idea.\n\n\n\n\nYear BuiltBuilding SqFtLand SqFtBedsRoomsBathroomsWalkability\n\n\n\n\nCode\nlibrary(scales)\n\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = year_built, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Year Built \\nand Sale Price in Cook County, IL\", \n      x = \"Year Built\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nMore recently built houses seem to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = building_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Building Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Building Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nLarger building houses tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = land_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Land Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Land Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nThe relationship here isn’t entirely clear, but it seems that more land sells for more, up until some point\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_bedrooms, y = sale_price, fill = factor(num_bedrooms))) +\n    scale_x_continuous(n.breaks = 9) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Bedrooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Bedrooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bedrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_rooms, y = sale_price, fill = factor(num_rooms))) +\n    geom_smooth(aes(x = num_rooms, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Rooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Rooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more rooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price, fill = factor(num_full_baths + num_half_baths * 0.5))) +\n    geom_smooth(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Total Number of Baths \\nand Sale Price in Cook County, IL\", \n      x = \"Total Number of Baths\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bathrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = cmap_walkability_total_score, y = sale_price, fill = factor(cmap_walkability_total_score))) +\n    geom_smooth(aes(x = cmap_walkability_total_score, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home CMAP Walkability and \\nSale Price in Cook County, IL\", \n      x = \"Total Walkability Score\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with in less walkable communities tend to sell for more. Although it seems like individuals might want to live in more walkable communities. The kind of large single family homes that tend to sell for more actually contribute toward reducing walkability, which is most likely why we see a downward trend.\n\n\n\n\n\n\nJoining our geospatial data.\n\n\nCode\nlibrary(sf)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n  filter(NAME %in% c(\"LEMONT\", \"PALOS\", \"ORLAND\")) %&gt;%\n  left_join(\n    sfh2123_sales_AT %&gt;%\n      group_by(township_code) %&gt;%\n      summarize(\n        median_sp = median(sale_price), \n        median_spr = median(sale_price_ratio))  %&gt;%\n      transmute(median_sp, median_spr, NAME = case_when(\n        township_code == \"19\" ~ \"LEMONT\",\n        township_code == \"30\" ~ \"PALOS\",\n        township_code == \"28\" ~ \"ORLAND\",\n      )\n    )\n  )\n\nsfh2123_sales_sf &lt;- sfh2123_sales_AT %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"))\n\n\n\nSale PricesAssessment to Sale Price Ratio\n\n\n\n\nCode\nlibrary(leaflet)\n\nqpal1 &lt;- colorQuantile(\"Greens\", sfh2123_sales_sf$sale_price, n = 5)\n\nsfh2123_sales_sf %&gt;%\n  leaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n      data = townships,\n      fillColor = \"black\",\n      fillOpacity = 0.1,\n      color = \"black\",\n      weight = 2,\n      opacity = 0.5,\n      highlightOptions = highlightOptions(\n        fillOpacity = 0.2,\n        weight = 3),\n      label = sprintf(\n        \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Median Sale: %s&lt;br/&gt;\",\n        townships$NAME,\n        label_currency()(townships$median_sp)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addCircleMarkers(\n      radius = 3,\n      fillColor = ~ qpal1(sale_price),\n      fillOpacity = 0.7,\n      stroke = FALSE,\n      label = sprintf(\n        \"&lt;strong&gt;Sale Price:&lt;/strong&gt; %s\",\n        label_currency()(sfh2123_sales_sf$sale_price)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addLegend(\n      pal = qpal1,\n      values = sfh2123_sales_sf$sale_price,\n      opacity = 0.7,\n      title = \"Sale Price of Single &lt;br&gt;Family Homes in Cook &lt;br&gt;County\",\n      position = \"topright\",\n      na.label = \"Insufficient Data\",\n      labFormat = function(type, cuts, p) {\n        n = length(cuts)\n        p = str_c(round(p * 100), '%')\n        cuts = str_c(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n        str_c('&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts, '&lt;/span&gt;')\n      })\n\n\n\n\n\n\nIt seems that there is clustering of similarly priced homes within our three townships. Lemont has the highest median sale price, but Palos and Orland have similar median sale prices. Perhaps using a spatial modeling technique like a spatial Bayesian or conditional autoregressive model is waranted.\n\n\nCode\nlibrary(spdep)\n\nknn &lt;- knearneigh(sfh2123_sales_sf, k = 20)\nnb &lt;- knn2nb(knn)\nweights &lt;- nb2listw(nb, style = \"B\")\n\nmoran.test(x = sfh2123_sales_sf$sale_price, listw = weights, zero.policy = TRUE) %&gt;% \n  broom::tidy() %&gt;% \n  select(estimate1, p.value, method) %&gt;%\n  rename(`Moran I statistic` = estimate1) %&gt;%\n  knitr::kable()\n\n\n\n\n\nMoran I statistic\np.value\nmethod\n\n\n\n\n0.4998853\n0\nMoran I test under randomisation\n\n\n\n\n\n\n\n\n\nCode\nqpal2 &lt;- colorQuantile(\"RdBu\", sfh2123_sales_sf$sale_price_ratio, n = 5)\n\nsfh2123_sales_sf %&gt;%\n  leaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n      data = townships,\n      fillColor = \"black\",\n      fillOpacity = 0.1,\n      color = \"black\",\n      weight = 2,\n      opacity = 0.5,\n      highlightOptions = highlightOptions(\n        fillOpacity = 0.2,\n        weight = 3),\n      label = sprintf(\n        \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Median Sale Price Ratio: %s&lt;br/&gt;\",\n        townships$NAME,\n        label_number(0.001)(townships$median_spr)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addCircleMarkers(\n      radius = 3,\n      fillColor = ~ qpal2(sale_price_ratio),\n      fillOpacity = 0.7,\n      stroke = FALSE,\n      label = sprintf(\n        \"&lt;strong&gt;Sale Price Ratio:&lt;/strong&gt; %s\",\n        label_number(0.001)(sfh2123_sales_sf$sale_price_ratio)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addLegend(\n      pal = qpal2,\n      values = sfh2123_sales_sf$sale_price_ratio,\n      opacity = 0.7,\n      title = \"Assessment to Sale Price &lt;br&gt;Ratio of Single Family&lt;br&gt; Homes in Cook County\",\n      position = \"topright\",\n      na.label = \"Insufficient Data\",\n      labFormat = function(type, cuts, p) {\n        n = length(cuts)\n        p = str_c(round(p * 100), '%')\n        cuts = str_c(label_number(0.001)(cuts[-n]), \" - \", label_number(0.001)(cuts[-1]))\n        str_c('&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts, '&lt;/span&gt;')\n      })\n\n\n\n\n\n\nIt seems like the over/under assessment of properties does not exhibit much clustering so perhaps there are other variables that we should have to consider. There are some values that seem like they may be large outliers.\n\n\n\n\n\n\nFor our over/under assessment model, I will define over assessment as greater than the median sale_price_ratio. Theoretically, this should be 1, but parcels are so routinely under assessed as compared to their true sale value that a threshold of 1 would place almost all houses in the under assessed category. I also chose a two class outcome in order to avoid potential complexities related to multiple classification models. I also considered creating a regression model that predicted assessment ratios and simply discretizing the predictions later, but opted against it.\nIt also important to note that our assessment model will only include data from 2022 and our sale price model will include data from 2021 and 2022. Although prices may be slightly different in these years,\n\n\nCode\nassessment_data &lt;- sfh2123_sales_AT %&gt;%\n  filter(year == 2022) %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;%\n  ungroup() %&gt;%\n  mutate(overassessed = factor(sale_price_ratio &lt; median(sale_price_ratio)))\n\nsales_data &lt;- sfh2123_sales_AT %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\")) %&gt;%\n  st_set_crs(4326)"
  },
  {
    "objectID": "posts/cook_part_2/index.html#part-b",
    "href": "posts/cook_part_2/index.html#part-b",
    "title": "Cook County Property Assessment - Part 2",
    "section": "Part B",
    "text": "Part B\n\nCreate workflow\n\n\nCode\nlibrary(tidymodels)\ntidymodels_prefer()\na_workflow &lt;- workflow()\n\n\n\n\nAdd Model To Workflow\n\n\nCode\na_rf_spec &lt;- rand_forest(mtry = tune(),trees = 1000, min_n = tune()) %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"classification\")\n\na_workflow &lt;- workflow() %&gt;%\n  add_model(a_rf_spec)\n\n\n\n\nAdd Recipe To Workflow\nI chose to use variables that I know are typically considered when buying a house, but we could definitely construct a workflow evaluating models with various predictors.\n\n\nCode\na_rec &lt;- assessment_data %&gt;%\n  recipe(overassessed ~ year_built + building_sqft + land_sqft + num_bedrooms + num_rooms + num_full_baths + num_half_baths + num_fireplaces + type_of_residence + construction_quality + attic_finish + garage_size + ext_wall_material + basement_type + central_heating + roof_material + porch + central_air + school_elementary_district_name, data = .) %&gt;% \n  step_string2factor(all_string()) %&gt;% \n  step_impute_knn(all_predictors()) %&gt;%\n  step_novel(all_nominal_predictors()) %&gt;%\n  step_dummy(all_nominal_predictors())\n\na_workflow &lt;- a_workflow %&gt;%\n  add_recipe(a_rec)\n\n\n\n\nCreate testing/training data and evaluate your model\n\n\nCode\nset.seed(123)\na_split &lt;- initial_split(assessment_data)\na_train_set &lt;- training(a_split)\na_test_set &lt;- testing(a_split)\n\nset.seed(234)\na_train_resamples &lt;- bootstraps(a_train_set)\n\n\nIn order to reduce the model tuning time, we will use a repeated measure ANOVA model to eliminate tuning parameter combinations that are unlikely to yield the best results.\n\n\nCode\nlibrary(finetune)\n\nset.seed(345)\na_tune &lt;- a_workflow %&gt;%\n  tune_race_anova(\n    resamples = a_train_resamples,\n    grid = 20,\n    metrics = metric_set(mn_log_loss, roc_auc),\n    control = control_race(verbose = TRUE))\n\n\nFinalize our model\n\n\nCode\na_best &lt;- select_best(a_tune, \"mn_log_loss\")\na_final_rf &lt;- finalize_model(a_rf_spec, a_best)\n\na_final_wf &lt;- workflow() %&gt;%\n  add_recipe(a_rec) %&gt;%\n  add_model(a_final_rf)\n\n\nLet’s see if there is an obvious spatial trend to our predictions\n\n\nCode\na_final_wf %&gt;% \n  fit(a_train_set) %&gt;%\n  augment(a_test_set) %&gt;%\n  mutate(correct = case_when(\n    overassessed == .pred_class ~ \"Correct\",\n    TRUE ~ \"Incorrect\"\n  )) %&gt;%\n  select(pin, correct, longitude, latitude) %&gt;%\n  ggplot(aes(longitude, latitude, color = correct)) +\n    geom_point(size = 0.5, alpha = 0.5) +\n    labs(color = NULL) +\n    scale_color_manual(values = c(\"gray80\", \"darkred\"))\n\n\n\n\n\n\n\n\n\n… not really\n\n\nCode\na_val_preds &lt;- a_final_wf %&gt;% \n  fit(a_train_set) %&gt;%\n  augment(a_test_set)\n\na_metrics &lt;- list(\n  a_val_preds %&gt;%\n    roc_auc(overassessed, .pred_FALSE),\n  a_val_preds %&gt;%\n    accuracy(overassessed, .pred_class),\n  a_val_preds %&gt;%\n    f_meas(overassessed, .pred_class))\n\na_metrics %&gt;% bind_rows() %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nroc_auc\nbinary\n0.6553524\n\n\naccuracy\nbinary\n0.6049724\n\n\nf_meas\nbinary\n0.5902579\n\n\n\n\n\nOur accuracy and auc is not that much higher than what would be expected by random chance. This is not really that encouraging for our model, but perhaps it indicates that there are no obvious trends in the overassessment/underassessment. That could reflect well on the assessor predictions.\n\n\nCode\na_val_preds %&gt;% \n  conf_mat(truth = overassessed, estimate = .pred_class)\n\n\n          Truth\nPrediction FALSE TRUE\n     FALSE   103   65\n     TRUE     78  116\n\n\nAgain, we see that our results are not too great.\n\n\nCode\na_val_preds %&gt;% \n  conf_mat(truth = overassessed, estimate = .pred_class) %&gt;%\n  tidy() %&gt;%\n  pivot_wider() %&gt;%\n  rename(TN = cell_1_1, TP = cell_2_2, FN = cell_2_1, FP = cell_1_2) %&gt;%\n  summarize(\n    TPR = TP/(TP+FN),\n    TNR = TN/(TN+TP),\n    FPR = FP/(FP+TN),\n    FNR = FN/(TP+FN),\n    PPV = TP/(TP+FP)\n  ) %&gt;% \n  knitr::kable()\n\n\n\n\n\nTPR\nTNR\nFPR\nFNR\nPPV\n\n\n\n\n0.5979381\n0.4703196\n0.3869048\n0.4020619\n0.640884\n\n\n\n\n\nIt seems that we may be slightly better at predicting true “overassessments”.\n\n\nCode\nlibrary(vip)\n\na_vip_rf_spec &lt;- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %&gt;% \n  set_engine(\"ranger\", importance = \"impurity\") %&gt;% \n  set_mode(\"classification\")\n\na_vip_rf &lt;- finalize_model(a_vip_rf_spec, a_best)  \na_vip_wf &lt;- workflow() %&gt;%   \n  add_recipe(a_rec) %&gt;%   \n  add_model(a_vip_rf) \n\na_vip_rf_fit &lt;- a_vip_wf %&gt;%    \n  fit(a_train_set)\n\na_vip_rf_fit %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip::vip(geom = \"point\")\n\n\n\n\n\n\n\n\n\nBuilding square footage, land square footage, and year built seem to be the most important to this model, but its difficult to truly interpret what that means in the context of this model."
  },
  {
    "objectID": "posts/cook_part_2/index.html#part-c",
    "href": "posts/cook_part_2/index.html#part-c",
    "title": "Cook County Property Assessment - Part 2",
    "section": "Part C",
    "text": "Part C\n\nCreate workflow\n\n\nCode\ns_workflow &lt;- workflow()\n\n\n\n\nAdd Model To Workflow\n\n\nCode\ns_rf_spec &lt;- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %&gt;%    \n  set_engine(\"ranger\") %&gt;%    \n  set_mode(\"regression\")  \n\ns_workflow &lt;- workflow() %&gt;%   \n  add_model(s_rf_spec)\n\n\n\n\nAdd Recipe To Workflow\nI chose to use variables that I know are typically considered when buying a house, but we could definitely construct a workflow evaluating models with various predictors.\n\n\nCode\ns_rec &lt;- sales_data %&gt;%    \n  st_drop_geometry() %&gt;%   \n  recipe(sale_price ~ year_built + building_sqft + land_sqft + num_bedrooms + num_rooms + num_full_baths + num_half_baths + num_fireplaces + type_of_residence + construction_quality + attic_finish + garage_size + ext_wall_material + basement_type + central_heating + roof_material + porch + central_air + school_elementary_district_name, data = .) %&gt;%    \n  step_string2factor(all_string()) %&gt;%    \n  step_impute_knn(all_predictors()) %&gt;%   \n  step_novel(all_nominal_predictors()) %&gt;%   \n  step_dummy(all_nominal_predictors())  \n\ns_workflow &lt;- s_workflow %&gt;%   \n  add_recipe(s_rec)\n\n\n\n\nCreate Testing/Training Data and Evaluate Your Model\nWe are going to utilize spatial resampling to hopefully adjust for the clustering that we saw when mapping. Instead of utilizing the typical split, we have\n\n\nCode\nlibrary(spatialsample)  \n\nset.seed(123) \ns_train_set &lt;- sales_data %&gt;% filter(year != 2023)\ns_test_set &lt;- sales_data %&gt;% filter(year == 2023)\n\nset.seed(234) \ns_train_resamples &lt;- spatial_clustering_cv(s_train_set)  \n\nautoplot(s_train_resamples)\n\n\n\n\n\n\n\n\n\nIn order to reduce the model tuning time, we will use a repeated measure ANOVA model to eliminate tuning parameter combinations that are unlikely to yield the best results.\n\n\nCode\nset.seed(345) \ns_tune &lt;- s_workflow %&gt;%   \n  tune_race_anova(\n    resamples = s_train_resamples,     \n    grid = 20,     \n    metrics = metric_set(rmse, mape),     \n    control = control_race(verbose = TRUE))\n\n\nFinalize our model\n\n\nCode\ns_best &lt;- select_best(s_tune, \"rmse\") \ns_final_rf &lt;- finalize_model(s_rf_spec, s_best)  \ns_final_wf &lt;- workflow() %&gt;%   \n  add_recipe(s_rec) %&gt;%   \n  add_model(s_final_rf)  \n\n\nMake our predictions and get the RMSE and MAPE\n\n\nCode\ns_val_preds &lt;- s_final_wf %&gt;%    \n  fit(s_train_set) %&gt;%   \n  augment(s_test_set)  \n\ns_metrics &lt;- list(   \n  s_val_preds %&gt;%     \n    rmse(sale_price, .pred),   \n  s_val_preds %&gt;%     \n    mape(sale_price, .pred))  \n\ns_metrics %&gt;% bind_rows() %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n97462.33147\n\n\nmape\nstandard\n18.66952\n\n\n\n\n\nIt seems the average deviation of our predicted prices from the true sale price is about $97,500. That is pretty high all things considered. We definitely have quite a lot of refining to do.\n\n\nCode\ns_vip_rf_spec &lt;- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %&gt;% \n  set_engine(\"ranger\", importance = \"impurity\") %&gt;% \n  set_mode(\"regression\")\n\ns_vip_rf &lt;- finalize_model(s_vip_rf_spec, s_best)  \ns_vip_wf &lt;- workflow() %&gt;%   \n  add_recipe(s_rec) %&gt;%   \n  add_model(s_vip_rf) \n\ns_vip_rf_fit &lt;- s_vip_wf %&gt;%    \n  fit(s_train_set)\n\ns_vip_rf_fit %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip::vip(geom = \"point\")\n\n\n\n\n\n\n\n\n\nBuilding square footage is by far the most important variable within our model. This makes a lot of sense given our prior EDA and just intuitively. I think the results line up pretty fairly with what one would expect."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PA470",
    "section": "",
    "text": "Final Project\n\n\n\n\n\n\nFinal Project\n\n\n\n\n\n\n\n\n\nApr 25, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCook County Property Assessment - Part 4\n\n\n\n\n\n\nCook County Assessments\n\n\n\n\n\n\n\n\n\nApr 7, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCook County Property Assessment - Part 3\n\n\n\n\n\n\nCook County Assessments\n\n\n\n\n\n\n\n\n\nMar 22, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCook County Property Assessment - Part 2\n\n\n\n\n\n\nCook County Assessments\n\n\n\n\n\n\n\n\n\nFeb 27, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCoding Warmup 4\n\n\n\n\n\n\nCoding Warmup\n\n\n\n\n\n\n\n\n\nFeb 15, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCook County Property Assessment - Part 1\n\n\n\n\n\n\nCook County Assessments\n\n\n\n\n\n\n\n\n\nFeb 8, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCoding Warmup 3\n\n\n\n\n\n\nCoding Warmup\n\n\n\n\n\n\n\n\n\nFeb 1, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\n\nCoding Warmup 2\n\n\n\n\n\n\nCoding Warmup\n\n\n\n\n\n\n\n\n\nJan 25, 2024\n\n\nRyan Zomorrodi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/cook_part_3/index.html",
    "href": "posts/cook_part_3/index.html",
    "title": "Cook County Property Assessment - Part 3",
    "section": "",
    "text": "There are over 1.8 million parcels in Cook County, Illinois [1]. Each of these parcels is assessed every three years using three to five years of prior sales information [1]. For this analysis, we will take a look at single family home assessments within three of the 36 political townships: Lemont (19), Palos (30), Orland (28). Using data provided on the Cook County data portal, we will will create a series of two models. Our first model will predict the likelihood of overassessment for the year of 2022, and our second model will predict home value for the year of 2023.\n\n\nWe have 4 inclusion criteria:\n\nYear - 2021, 2022, 2023\nClass - 202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278. These conform to single family homes\nTownship Code - 19 (Lemont), 30 (Palos), 28 (Orland)\nIs Multisale - No\n\n\n\nCode\nlibrary(arrow)\nlibrary(data.table)\nlibrary(dtplyr)\nlibrary(tidyverse)\n\nsfh2123_assessment &lt;-\n  open_csv_dataset(\"../data/20240217_Assessed_Values.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"township_name\", string()),\n      field(\"mailed_bldg\", int32()),\n      field(\"mailed_land\", int32()),\n      field(\"mailed_tot\", int32()),\n      field(\"certified_bldg\", int32()),\n      field(\"certified_land\", int32()),\n      field(\"certified_tot\", int32()),\n      field(\"board_bldg\", int32()),\n      field(\"board_land\", int32()),\n      field(\"board_tot\", int32()),\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_sales &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Sales.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"year\", int32()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"class\", string()),\n      field(\"sale_date\", string()),\n      field(\"is_mydec_date\", bool()),\n      field(\"sale_price\", int32()),\n      field(\"sale_document_num\", string()),\n      field(\"sale_deed_type\", string()),\n      field(\"mydec_deed_type\", string()),\n      field(\"sale_seller_name\", string()),\n      field(\"is_multisale\", bool()),\n      field(\"num_parcels_sale\", int32()),\n      field(\"sale_buyer_name\", string()),\n      field(\"sale_type\", string()),\n      field(\"sale_filter_same_sale_within_365\", bool()),\n      field(\"sale_filter_less_than_10k\", bool()),\n      field(\"sale_filter_deed_type\", bool())\n    )\n  ) %&gt;%\n  filter(year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\")) %&gt;%\n  filter(!is_multisale) \n\nsfh2123_characteristics &lt;- \n  open_csv_dataset(\"../data/20240217_Improvement_Characteristics.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"card_num\", string()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"proration_key_pin\", string()),\n      field(\"pin_proration_rate\", double()),\n      field(\"card_proration_rate\", double()),\n      field(\"cdu\", string()),\n      field(\"pin_is_multicard\", bool()),\n      field(\"pin_num_cards\", int32()),\n      field(\"pin_is_multiland\", bool()),\n      field(\"pin_num_landlines\", int32()),\n      field(\"year_built\", int32()),\n      field(\"building_sqft\", int32()),\n      field(\"land_sqft\", int32()),\n      field(\"num_bedrooms\", int32()),\n      field(\"num_rooms\", int32()),\n      field(\"num_full_baths\", int32()),\n      field(\"num_half_baths\", int32()),\n      field(\"num_fireplaces\", int32()),\n      field(\"type_of_residence\", string()),\n      field(\"construction_quality\", string()),\n      field(\"num_apartments\", string()),\n      field(\"attic_finish\", string()),\n      field(\"garage_attached\", string()),\n      field(\"garage_area_included\", string()),\n      field(\"garage_size\", string()),\n      field(\"garage_ext_wall_material\", string()),\n      field(\"attic_type\", string()),\n      field(\"basement_type\", string()),\n      field(\"ext_wall_material\", string()),\n      field(\"central_heating\", string()),\n      field(\"repair_condition\", string()),\n      field(\"basement_finish\", string()),\n      field(\"roof_material\", string()),\n      field(\"single_v_multi_family\", string()),\n      field(\"site_desirability\", string()),\n      field(\"num_commercial_units\", string()),\n      field(\"renovation\", string()),\n      field(\"recent_renovation\", bool()),\n      field(\"porch\", string()),\n      field(\"central_air\", string()),\n      field(\"design_plan\", string())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_universe &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Universe.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"pin10\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"triad_name\", string()),\n      field(\"triad_code\", string()),\n      field(\"township_name\", string()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"tax_district_code\", string()),\n      field(\"zip_code\", string()),\n      field(\"longitude\", double()),\n      field(\"latitude\", double()),\n      field(\"centroid_x_crs_3435\", double()),\n      field(\"centroid_y_crs_3435\", double()),\n      field(\"census_block_group_geoid\", string()),\n      field(\"census_block_geoid\", string()),\n      field(\"census_congressional_district_geoid\", string()),\n      field(\"census_county_subdivision_geoid\", string()),\n      field(\"census_place_geoid\", string()),\n      field(\"census_puma_geoid\", string()),\n      field(\"census_school_district_elementary_geoid\", string()),\n      field(\"census_school_district_secondary_geoid\", string()),\n      field(\"census_school_district_unified_geoid\", string()),\n      field(\"census_state_representative_geoid\", string()),\n      field(\"census_state_senate_geoid\", string()),\n      field(\"census_tract_geoid\", string()),\n      field(\"census_zcta_geoid\", string()),\n      field(\"census_data_year\", int32()),\n      field(\"census_acs5_congressional_district_geoid\", string()),\n      field(\"census_acs5_county_subdivision_geoid\", string()),\n      field(\"census_acs5_place_geoid\", string()),\n      field(\"census_acs5_puma_geoid\", string()),\n      field(\"census_acs5_school_district_elementary_geoid\", string()),\n      field(\"census_acs5_school_district_secondary_geoid\", string()),\n      field(\"census_acs5_school_district_unified_geoid\", string()),\n      field(\"census_acs5_state_representative_geoid\", string()),\n      field(\"census_acs5_state_senate_geoid\", string()),\n      field(\"census_acs5_tract_geoid\", string()),\n      field(\"census_acs5_data_year\", int32()),\n      field(\"board_of_review_district_num\", string()),\n      field(\"board_of_review_district_data_year\", int32()),\n      field(\"commissioner_district_num\", string()),\n      field(\"commissioner_district_data_year\", int32()),\n      field(\"judicial_district_num\", string()),\n      field(\"judicial_district_data_year\", int32()),\n      field(\"ward_num\", string()),\n      field(\"ward_chicago_data_year\", int32()),\n      field(\"ward_evanston_data_year\", int32()),\n      field(\"chicago_community_area_num\", string()),\n      field(\"chicago_community_area_name\", string()),\n      field(\"chicago_community_area_data_year\", int32()),\n      field(\"chicago_industrial_corridor_num\", string()),\n      field(\"chicago_industrial_corridor_name\", string()),\n      field(\"chicago_industrial_corridor_data_year\", int32()),\n      field(\"chicago_police_district_num\", string()),\n      field(\"chicago_police_district_data_year\", int32()),\n      field(\"coordinated_care_area_num\", string()),\n      field(\"coordinated_care_area_data_year\", int32()),\n      field(\"enterprise_zone_num\", string()),\n      field(\"enterprise_zone_data_year\", int32()),\n      field(\"industrial_growth_zone_num\", string()),\n      field(\"industrial_growth_zone_data_year\", int32()),\n      field(\"qualified_opportunity_zone_num\", string()),\n      field(\"qualified_opportunity_zone_data_year\", int32()),\n      field(\"flood_fema_sfha\", bool()),\n      field(\"flood_fema_data_year\", int32()),\n      field(\"flood_fs_factor\", int32()),\n      field(\"flood_fs_risk_direction\", int32()),\n      field(\"flood_fs_data_year\", int32()),\n      field(\"ohare_noise_contour_no_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_half_mile_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_data_year\", int32()),\n      field(\"airport_noise_dnl\", double()),\n      field(\"airport_noise_data_year\", string()),\n      field(\"school_elementary_district_geoid\", string()),\n      field(\"school_elementary_district_name\", string()),\n      field(\"school_secondary_district_geoid\", string()),\n      field(\"school_secondary_district_name\", string()),\n      field(\"school_unified_district_geoid\", string()),\n      field(\"school_unified_district_name\", string()),\n      field(\"school_year\", string()),\n      field(\"school_data_year\", int32()),\n      field(\"tax_municipality_num\", string()),\n      field(\"tax_municipality_name\", string()),\n      field(\"tax_school_elementary_district_num\", string()),\n      field(\"tax_school_elementary_district_name\", string()),\n      field(\"tax_school_secondary_district_num\", string()),\n      field(\"tax_school_secondary_district_name\", string()),\n      field(\"tax_school_unified_district_num\", string()),\n      field(\"tax_school_unified_district_name\", string()),\n      field(\"tax_community_college_district_num\", string()),\n      field(\"tax_community_college_district_name\", string()),\n      field(\"tax_fire_protection_district_num\", string()),\n      field(\"tax_fire_protection_district_name\", string()),\n      field(\"tax_library_district_num\", string()),\n      field(\"tax_library_district_name\", string()),\n      field(\"tax_park_district_num\", string()),\n      field(\"tax_park_district_name\", string()),\n      field(\"tax_sanitation_district_num\", string()),\n      field(\"tax_sanitation_district_name\", string()),\n      field(\"tax_special_service_area_num\", string()),\n      field(\"tax_special_service_area_name\", string()),\n      field(\"tax_tif_district_num\", string()),\n      field(\"tax_tif_district_name\", string()),\n      field(\"tax_districts_data_year\", int32()),\n      field(\"cmap_walkability_grid_id\", string()),\n      field(\"cmap_walkability_no_transit_score\", double()),\n      field(\"cmap_walkability_total_score\", double()),\n      field(\"cmap_walkability_data_year\", int32()),\n      field(\"subdivision_id\", string()),\n      field(\"subdivision_data_year\", int32())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_assessment_dt &lt;- sfh2123_assessment %&gt;% as.data.table()\nsfh2123_sales_dt &lt;- sfh2123_sales %&gt;% as.data.table()\nsfh2123_characteristics_dt &lt;- sfh2123_characteristics %&gt;% as.data.table()\nsfh2123_universe_dt &lt;- sfh2123_universe %&gt;% as.data.table()\n\n\n\n\n\n\n\nCode\nsfh2123_sales_AT &lt;- sfh2123_sales_dt %&gt;%\n  lazy_dt() %&gt;%\n  left_join(sfh2123_assessment_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"neighborhood_code\", \"township_code\", \"township_name\", \"class\", \"year\" = \"tax_year\")) %&gt;%\n  mutate(sale_price_ratio = 10 * certified_tot / sale_price) %&gt;%\n  collect()\n\nsfh2123_assessment_AT &lt;- sfh2123_assessment_dt %&gt;% \n  lazy_dt() %&gt;%\n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"township_code\", \"township_name\", \"class\", \"tax_year\")) %&gt;%\n  collect()\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\n\nsfh2123_sales_AT %&gt;%\n  mutate(id = row_number()) %&gt;%\n  tidyr::gather(-id, key = \"key\", value = \"val\") %&gt;%\n  mutate(isna = is.na(val)) %&gt;%\n  ggplot(aes(key, id, fill = isna)) +\n    geom_raster(alpha=0.8) +\n    scale_fill_manual(name = \"\",\n        values = c('steelblue', 'tomato3'),\n        labels = c(\"Present\", \"Missing\")) +\n    labs(x = \"Variable\",\n           y = \"Row Number\", title = \"Missing Values for Housing Sales\") +\n    coord_flip()\n\n\n\n\n\n\n\n\n\nIt seems like we have quite a few measures that are either entirely missing or have quite a few missing values. This is okay because we won’t be using all of our variables in order to reduce the complexity and increase the interpretability of our model.\n\n\n\n\n\nCode\nlibrary(corrr)\n\nsfh2123_sales_AT %&gt;%\n  select(c(sale_price, certified_tot, year_built, building_sqft, land_sqft, num_bedrooms, num_rooms, num_full_baths, num_half_baths, num_fireplaces, cmap_walkability_no_transit_score, cmap_walkability_total_score)) %&gt;%\n  select(where(is.numeric)) %&gt;%\n  select(where(function(x) sum(!is.na(x)) != 0)) %&gt;%\n  select(where(function(x) var(x, na.rm = TRUE) != 0)) %&gt;% \n  correlate(method = \"spearman\") %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\nThere seems to be a high level of correlation between many of the housing characteristics. Perhaps using a model that takes in account multicollinearity would be a good idea.\n\n\n\n\nYear BuiltBuilding SqFtLand SqFtBedsRoomsBathroomsWalkability\n\n\n\n\nCode\nlibrary(scales)\n\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = year_built, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Year Built \\nand Sale Price in Cook County, IL\", \n      x = \"Year Built\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nMore recently built houses seem to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = building_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Building Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Building Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nLarger building houses tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = land_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Land Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Land Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nThe relationship here isn’t entirely clear, but it seems that more land sells for more, up until some point\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_bedrooms, y = sale_price, fill = factor(num_bedrooms))) +\n    scale_x_continuous(n.breaks = 9) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Bedrooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Bedrooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bedrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_rooms, y = sale_price, fill = factor(num_rooms))) +\n    geom_smooth(aes(x = num_rooms, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Rooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Rooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more rooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price, fill = factor(num_full_baths + num_half_baths * 0.5))) +\n    geom_smooth(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Total Number of Baths \\nand Sale Price in Cook County, IL\", \n      x = \"Total Number of Baths\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bathrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = cmap_walkability_total_score, y = sale_price, fill = factor(cmap_walkability_total_score))) +\n    geom_smooth(aes(x = cmap_walkability_total_score, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home CMAP Walkability and \\nSale Price in Cook County, IL\", \n      x = \"Total Walkability Score\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with in less walkable communities tend to sell for more. Although it seems like individuals might want to live in more walkable communities. The kind of large single family homes that tend to sell for more actually contribute toward reducing walkability, which is most likely why we see a downward trend.\n\n\n\n\n\n\nLet us take a look at how our outcome variables are distributed spatially. Clustering might indicate that there is a spatial modeling technique is required.\n\n\nCode\nlibrary(sf)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n  filter(NAME %in% c(\"LEMONT\", \"PALOS\", \"ORLAND\")) %&gt;%\n  left_join(\n    sfh2123_sales_AT %&gt;%\n      group_by(township_code) %&gt;%\n      summarize(\n        median_sp = median(sale_price), \n        median_spr = median(sale_price_ratio))  %&gt;%\n      transmute(median_sp, median_spr, NAME = case_when(\n        township_code == \"19\" ~ \"LEMONT\",\n        township_code == \"30\" ~ \"PALOS\",\n        township_code == \"28\" ~ \"ORLAND\",\n      )\n    )\n  )\n\nsfh2123_sales_sf &lt;- sfh2123_sales_AT %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"))\n\n\n\n\nCode\nlibrary(leaflet)\n\nqpal1 &lt;- colorQuantile(\"Greens\", sfh2123_sales_sf$sale_price, n = 5)\n\nsfh2123_sales_sf %&gt;%\n  leaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n      data = townships,\n      fillColor = \"black\",\n      fillOpacity = 0.1,\n      color = \"black\",\n      weight = 2,\n      opacity = 0.5,\n      highlightOptions = highlightOptions(\n        fillOpacity = 0.2,\n        weight = 3),\n      label = sprintf(\n        \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Median Sale: %s&lt;br/&gt;\",\n        townships$NAME,\n        label_currency()(townships$median_sp)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addCircleMarkers(\n      radius = 3,\n      fillColor = ~ qpal1(sale_price),\n      fillOpacity = 0.7,\n      stroke = FALSE,\n      label = sprintf(\n        \"&lt;strong&gt;Sale Price:&lt;/strong&gt; %s\",\n        label_currency()(sfh2123_sales_sf$sale_price)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addLegend(\n      pal = qpal1,\n      values = sfh2123_sales_sf$sale_price,\n      opacity = 0.7,\n      title = \"Sale Price of Single &lt;br&gt;Family Homes in Cook &lt;br&gt;County\",\n      position = \"topright\",\n      na.label = \"Insufficient Data\",\n      labFormat = function(type, cuts, p) {\n        n = length(cuts)\n        p = str_c(round(p * 100), '%')\n        cuts = str_c(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n        str_c('&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts, '&lt;/span&gt;')\n      })\n\n\n\n\n\n\nIt seems that there is clustering of similarly priced homes within our three townships. Lemont has the highest median sale price, but Palos and Orland have similar median sale prices. Perhaps using a spatial modeling technique like a spatial Bayesian or conditional autoregressive model is waranted.\n\n\nCode\nlibrary(spdep)\n\nknn &lt;- knearneigh(sfh2123_sales_sf, k = 20)\nnb &lt;- knn2nb(knn)\nweights &lt;- nb2listw(nb, style = \"B\")\n\nmoran.test(x = sfh2123_sales_sf$sale_price, listw = weights, zero.policy = TRUE) %&gt;% \n  broom::tidy() %&gt;% \n  select(estimate1, p.value, method) %&gt;%\n  rename(`Moran I statistic` = estimate1) %&gt;%\n  knitr::kable()\n\n\n\n\n\nMoran I statistic\np.value\nmethod\n\n\n\n\n0.4998853\n0\nMoran I test under randomisation\n\n\n\n\n\n\n\n\nFor our over/under assessment model, I will define over assessment as greater than the median sale_price_ratio. Theoretically, this should be 1, but parcels are so routinely under assessed as compared to their true sale value that a threshold of 1 would place almost all houses in the under assessed category. I also chose a two class outcome in order to avoid potential complexities related to multiple classification models. I also considered creating a regression model that predicted assessment ratios and simply discretizing the predictions later, but opted against it.\nIt also important to note that our assessment model will only include data from 2022 and our sale price model will include data from 2021 and 2022. Although prices may be slightly different in these years,\n\n\nCode\nassessment_data &lt;- sfh2123_sales_AT %&gt;%\n  filter(year == 2022) %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;%\n  ungroup() %&gt;%\n  mutate(overassessed = factor(sale_price_ratio &lt; median(sale_price_ratio)))\n\nsales_data &lt;- sfh2123_sales_AT %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\")) %&gt;%\n  st_set_crs(4326)\n\n\n\n\n\n\n\nCode\nlibrary(tidymodels)\ntidymodels_prefer()\n\ns_workflow &lt;- workflow()\n\n\n\n\n\n\n\nCode\ns_rf_spec &lt;- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %&gt;%    \n  set_engine(\"ranger\") %&gt;%    \n  set_mode(\"regression\")  \n\ns_workflow &lt;- workflow() %&gt;%   \n  add_model(s_rf_spec)\n\n\n\n\n\nI chose to use variables that I know are typically considered when buying a house, but we could definitely construct a workflow evaluating models with various predictors.\n\n\nCode\ns_rec &lt;- sales_data %&gt;%    \n  st_drop_geometry() %&gt;%   \n  recipe(sale_price ~ year_built + building_sqft + land_sqft + num_bedrooms + num_rooms + num_full_baths + num_half_baths + num_fireplaces + type_of_residence + construction_quality + attic_finish + garage_size + ext_wall_material + basement_type + central_heating + roof_material + porch + central_air + school_elementary_district_name, data = .) %&gt;%    \n  step_string2factor(all_string()) %&gt;%    \n  step_impute_knn(all_predictors()) %&gt;%   \n  step_novel(all_nominal_predictors()) %&gt;%   \n  step_dummy(all_nominal_predictors())  \n\ns_workflow &lt;- s_workflow %&gt;%   \n  add_recipe(s_rec)\n\n\n\n\n\n\n\nCode\nset.seed(123) \ns_train_set &lt;- sales_data %&gt;% filter(year != 2023)\ns_test_set &lt;- sales_data %&gt;% filter(year == 2023)\n\nset.seed(234) \ns_train_resamples &lt;- bootstraps(s_train_set)  \n\n\nIn order to reduce the model tuning time, we will use a repeated measure ANOVA model to eliminate tuning parameter combinations that are unlikely to yield the best results.\n\n\nCode\nlibrary(finetune)\n\nset.seed(345) \ns_tune &lt;- s_workflow %&gt;%   \n  tune_race_anova(\n    resamples = s_train_resamples,     \n    grid = 20,     \n    metrics = metric_set(rmse, mape),     \n    control = control_race(verbose = TRUE))\n\n\nFinalize our model\n\n\nCode\ns_best &lt;- select_best(s_tune, \"rmse\") \ns_final_rf &lt;- finalize_model(s_rf_spec, s_best)  \ns_final_wf &lt;- workflow() %&gt;%   \n  add_recipe(s_rec) %&gt;%   \n  add_model(s_final_rf)  \n\n\nMake our predictions and get the RMSE and MAPE\n\n\nCode\ns_val_preds &lt;- s_final_wf %&gt;%    \n  fit(s_train_set) %&gt;%   \n  augment(s_test_set)  \n\ns_metrics &lt;- list(   \n  s_val_preds %&gt;%     \n    rmse(sale_price, .pred),   \n  s_val_preds %&gt;%     \n    mape(sale_price, .pred))  \n\ns_metrics %&gt;% bind_rows() %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n97375.92563\n\n\nmape\nstandard\n18.67622\n\n\n\n\n\nIt seems the average deviation of our predicted prices from the true sale price is about $97,500. That is pretty high all things considered. We definitely have quite a lot of refining to do.\n\n\nCode\ns_vip_rf_spec &lt;- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %&gt;% \n  set_engine(\"ranger\", importance = \"impurity\") %&gt;% \n  set_mode(\"regression\")\n\ns_vip_rf &lt;- finalize_model(s_vip_rf_spec, s_best)  \ns_vip_wf &lt;- workflow() %&gt;%   \n  add_recipe(s_rec) %&gt;%   \n  add_model(s_vip_rf) \n\ns_vip_rf_fit &lt;- s_vip_wf %&gt;%    \n  fit(s_train_set)\n\ns_vip_rf_fit %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip::vip(geom = \"point\")\n\n\n\n\n\n\n\n\n\nBuilding square footage is by far the most important variable within our model. This makes a lot of sense given our prior EDA and just intuitively. I think the results line up pretty fairly with what one would expect."
  },
  {
    "objectID": "posts/cook_part_3/index.html#part-a",
    "href": "posts/cook_part_3/index.html#part-a",
    "title": "Cook County Property Assessment - Part 3",
    "section": "",
    "text": "There are over 1.8 million parcels in Cook County, Illinois [1]. Each of these parcels is assessed every three years using three to five years of prior sales information [1]. For this analysis, we will take a look at single family home assessments within three of the 36 political townships: Lemont (19), Palos (30), Orland (28). Using data provided on the Cook County data portal, we will will create a series of two models. Our first model will predict the likelihood of overassessment for the year of 2022, and our second model will predict home value for the year of 2023.\n\n\nWe have 4 inclusion criteria:\n\nYear - 2021, 2022, 2023\nClass - 202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278. These conform to single family homes\nTownship Code - 19 (Lemont), 30 (Palos), 28 (Orland)\nIs Multisale - No\n\n\n\nCode\nlibrary(arrow)\nlibrary(data.table)\nlibrary(dtplyr)\nlibrary(tidyverse)\n\nsfh2123_assessment &lt;-\n  open_csv_dataset(\"../data/20240217_Assessed_Values.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"township_name\", string()),\n      field(\"mailed_bldg\", int32()),\n      field(\"mailed_land\", int32()),\n      field(\"mailed_tot\", int32()),\n      field(\"certified_bldg\", int32()),\n      field(\"certified_land\", int32()),\n      field(\"certified_tot\", int32()),\n      field(\"board_bldg\", int32()),\n      field(\"board_land\", int32()),\n      field(\"board_tot\", int32()),\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_sales &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Sales.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"year\", int32()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"class\", string()),\n      field(\"sale_date\", string()),\n      field(\"is_mydec_date\", bool()),\n      field(\"sale_price\", int32()),\n      field(\"sale_document_num\", string()),\n      field(\"sale_deed_type\", string()),\n      field(\"mydec_deed_type\", string()),\n      field(\"sale_seller_name\", string()),\n      field(\"is_multisale\", bool()),\n      field(\"num_parcels_sale\", int32()),\n      field(\"sale_buyer_name\", string()),\n      field(\"sale_type\", string()),\n      field(\"sale_filter_same_sale_within_365\", bool()),\n      field(\"sale_filter_less_than_10k\", bool()),\n      field(\"sale_filter_deed_type\", bool())\n    )\n  ) %&gt;%\n  filter(year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\")) %&gt;%\n  filter(!is_multisale) \n\nsfh2123_characteristics &lt;- \n  open_csv_dataset(\"../data/20240217_Improvement_Characteristics.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"tax_year\", int32()),\n      field(\"card_num\", string()),\n      field(\"class\", string()),\n      field(\"township_code\", string()),\n      field(\"proration_key_pin\", string()),\n      field(\"pin_proration_rate\", double()),\n      field(\"card_proration_rate\", double()),\n      field(\"cdu\", string()),\n      field(\"pin_is_multicard\", bool()),\n      field(\"pin_num_cards\", int32()),\n      field(\"pin_is_multiland\", bool()),\n      field(\"pin_num_landlines\", int32()),\n      field(\"year_built\", int32()),\n      field(\"building_sqft\", int32()),\n      field(\"land_sqft\", int32()),\n      field(\"num_bedrooms\", int32()),\n      field(\"num_rooms\", int32()),\n      field(\"num_full_baths\", int32()),\n      field(\"num_half_baths\", int32()),\n      field(\"num_fireplaces\", int32()),\n      field(\"type_of_residence\", string()),\n      field(\"construction_quality\", string()),\n      field(\"num_apartments\", string()),\n      field(\"attic_finish\", string()),\n      field(\"garage_attached\", string()),\n      field(\"garage_area_included\", string()),\n      field(\"garage_size\", string()),\n      field(\"garage_ext_wall_material\", string()),\n      field(\"attic_type\", string()),\n      field(\"basement_type\", string()),\n      field(\"ext_wall_material\", string()),\n      field(\"central_heating\", string()),\n      field(\"repair_condition\", string()),\n      field(\"basement_finish\", string()),\n      field(\"roof_material\", string()),\n      field(\"single_v_multi_family\", string()),\n      field(\"site_desirability\", string()),\n      field(\"num_commercial_units\", string()),\n      field(\"renovation\", string()),\n      field(\"recent_renovation\", bool()),\n      field(\"porch\", string()),\n      field(\"central_air\", string()),\n      field(\"design_plan\", string())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_universe &lt;- \n  open_csv_dataset(\"../data/20240217_Parcel_Universe.csv\",\n    skip = 1,\n    na = c(\"\", \"[]\", \"NA\"),\n    schema(\n      field(\"pin\", string()),\n      field(\"pin10\", string()),\n      field(\"tax_year\", int32()),\n      field(\"class\", string()),\n      field(\"triad_name\", string()),\n      field(\"triad_code\", string()),\n      field(\"township_name\", string()),\n      field(\"township_code\", string()),\n      field(\"neighborhood_code\", string()),\n      field(\"tax_district_code\", string()),\n      field(\"zip_code\", string()),\n      field(\"longitude\", double()),\n      field(\"latitude\", double()),\n      field(\"centroid_x_crs_3435\", double()),\n      field(\"centroid_y_crs_3435\", double()),\n      field(\"census_block_group_geoid\", string()),\n      field(\"census_block_geoid\", string()),\n      field(\"census_congressional_district_geoid\", string()),\n      field(\"census_county_subdivision_geoid\", string()),\n      field(\"census_place_geoid\", string()),\n      field(\"census_puma_geoid\", string()),\n      field(\"census_school_district_elementary_geoid\", string()),\n      field(\"census_school_district_secondary_geoid\", string()),\n      field(\"census_school_district_unified_geoid\", string()),\n      field(\"census_state_representative_geoid\", string()),\n      field(\"census_state_senate_geoid\", string()),\n      field(\"census_tract_geoid\", string()),\n      field(\"census_zcta_geoid\", string()),\n      field(\"census_data_year\", int32()),\n      field(\"census_acs5_congressional_district_geoid\", string()),\n      field(\"census_acs5_county_subdivision_geoid\", string()),\n      field(\"census_acs5_place_geoid\", string()),\n      field(\"census_acs5_puma_geoid\", string()),\n      field(\"census_acs5_school_district_elementary_geoid\", string()),\n      field(\"census_acs5_school_district_secondary_geoid\", string()),\n      field(\"census_acs5_school_district_unified_geoid\", string()),\n      field(\"census_acs5_state_representative_geoid\", string()),\n      field(\"census_acs5_state_senate_geoid\", string()),\n      field(\"census_acs5_tract_geoid\", string()),\n      field(\"census_acs5_data_year\", int32()),\n      field(\"board_of_review_district_num\", string()),\n      field(\"board_of_review_district_data_year\", int32()),\n      field(\"commissioner_district_num\", string()),\n      field(\"commissioner_district_data_year\", int32()),\n      field(\"judicial_district_num\", string()),\n      field(\"judicial_district_data_year\", int32()),\n      field(\"ward_num\", string()),\n      field(\"ward_chicago_data_year\", int32()),\n      field(\"ward_evanston_data_year\", int32()),\n      field(\"chicago_community_area_num\", string()),\n      field(\"chicago_community_area_name\", string()),\n      field(\"chicago_community_area_data_year\", int32()),\n      field(\"chicago_industrial_corridor_num\", string()),\n      field(\"chicago_industrial_corridor_name\", string()),\n      field(\"chicago_industrial_corridor_data_year\", int32()),\n      field(\"chicago_police_district_num\", string()),\n      field(\"chicago_police_district_data_year\", int32()),\n      field(\"coordinated_care_area_num\", string()),\n      field(\"coordinated_care_area_data_year\", int32()),\n      field(\"enterprise_zone_num\", string()),\n      field(\"enterprise_zone_data_year\", int32()),\n      field(\"industrial_growth_zone_num\", string()),\n      field(\"industrial_growth_zone_data_year\", int32()),\n      field(\"qualified_opportunity_zone_num\", string()),\n      field(\"qualified_opportunity_zone_data_year\", int32()),\n      field(\"flood_fema_sfha\", bool()),\n      field(\"flood_fema_data_year\", int32()),\n      field(\"flood_fs_factor\", int32()),\n      field(\"flood_fs_risk_direction\", int32()),\n      field(\"flood_fs_data_year\", int32()),\n      field(\"ohare_noise_contour_no_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_half_mile_buffer_bool\", bool()),\n      field(\"ohare_noise_contour_data_year\", int32()),\n      field(\"airport_noise_dnl\", double()),\n      field(\"airport_noise_data_year\", string()),\n      field(\"school_elementary_district_geoid\", string()),\n      field(\"school_elementary_district_name\", string()),\n      field(\"school_secondary_district_geoid\", string()),\n      field(\"school_secondary_district_name\", string()),\n      field(\"school_unified_district_geoid\", string()),\n      field(\"school_unified_district_name\", string()),\n      field(\"school_year\", string()),\n      field(\"school_data_year\", int32()),\n      field(\"tax_municipality_num\", string()),\n      field(\"tax_municipality_name\", string()),\n      field(\"tax_school_elementary_district_num\", string()),\n      field(\"tax_school_elementary_district_name\", string()),\n      field(\"tax_school_secondary_district_num\", string()),\n      field(\"tax_school_secondary_district_name\", string()),\n      field(\"tax_school_unified_district_num\", string()),\n      field(\"tax_school_unified_district_name\", string()),\n      field(\"tax_community_college_district_num\", string()),\n      field(\"tax_community_college_district_name\", string()),\n      field(\"tax_fire_protection_district_num\", string()),\n      field(\"tax_fire_protection_district_name\", string()),\n      field(\"tax_library_district_num\", string()),\n      field(\"tax_library_district_name\", string()),\n      field(\"tax_park_district_num\", string()),\n      field(\"tax_park_district_name\", string()),\n      field(\"tax_sanitation_district_num\", string()),\n      field(\"tax_sanitation_district_name\", string()),\n      field(\"tax_special_service_area_num\", string()),\n      field(\"tax_special_service_area_name\", string()),\n      field(\"tax_tif_district_num\", string()),\n      field(\"tax_tif_district_name\", string()),\n      field(\"tax_districts_data_year\", int32()),\n      field(\"cmap_walkability_grid_id\", string()),\n      field(\"cmap_walkability_no_transit_score\", double()),\n      field(\"cmap_walkability_total_score\", double()),\n      field(\"cmap_walkability_data_year\", int32()),\n      field(\"subdivision_id\", string()),\n      field(\"subdivision_data_year\", int32())\n    )\n  ) %&gt;%\n  filter(tax_year %in% c(2021, 2022, 2023)) %&gt;%\n  filter(class %in% c(\"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"234\", \"278\")) %&gt;% \n  filter(township_code %in% c(\"19\", \"30\", \"28\"))\n\nsfh2123_assessment_dt &lt;- sfh2123_assessment %&gt;% as.data.table()\nsfh2123_sales_dt &lt;- sfh2123_sales %&gt;% as.data.table()\nsfh2123_characteristics_dt &lt;- sfh2123_characteristics %&gt;% as.data.table()\nsfh2123_universe_dt &lt;- sfh2123_universe %&gt;% as.data.table()\n\n\n\n\n\n\n\nCode\nsfh2123_sales_AT &lt;- sfh2123_sales_dt %&gt;%\n  lazy_dt() %&gt;%\n  left_join(sfh2123_assessment_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"year\" = \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"neighborhood_code\", \"township_code\", \"township_name\", \"class\", \"year\" = \"tax_year\")) %&gt;%\n  mutate(sale_price_ratio = 10 * certified_tot / sale_price) %&gt;%\n  collect()\n\nsfh2123_assessment_AT &lt;- sfh2123_assessment_dt %&gt;% \n  lazy_dt() %&gt;%\n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"township_code\", \"township_name\", \"class\", \"tax_year\")) %&gt;%\n  collect()\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\n\nsfh2123_sales_AT %&gt;%\n  mutate(id = row_number()) %&gt;%\n  tidyr::gather(-id, key = \"key\", value = \"val\") %&gt;%\n  mutate(isna = is.na(val)) %&gt;%\n  ggplot(aes(key, id, fill = isna)) +\n    geom_raster(alpha=0.8) +\n    scale_fill_manual(name = \"\",\n        values = c('steelblue', 'tomato3'),\n        labels = c(\"Present\", \"Missing\")) +\n    labs(x = \"Variable\",\n           y = \"Row Number\", title = \"Missing Values for Housing Sales\") +\n    coord_flip()\n\n\n\n\n\n\n\n\n\nIt seems like we have quite a few measures that are either entirely missing or have quite a few missing values. This is okay because we won’t be using all of our variables in order to reduce the complexity and increase the interpretability of our model.\n\n\n\n\n\nCode\nlibrary(corrr)\n\nsfh2123_sales_AT %&gt;%\n  select(c(sale_price, certified_tot, year_built, building_sqft, land_sqft, num_bedrooms, num_rooms, num_full_baths, num_half_baths, num_fireplaces, cmap_walkability_no_transit_score, cmap_walkability_total_score)) %&gt;%\n  select(where(is.numeric)) %&gt;%\n  select(where(function(x) sum(!is.na(x)) != 0)) %&gt;%\n  select(where(function(x) var(x, na.rm = TRUE) != 0)) %&gt;% \n  correlate(method = \"spearman\") %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\nThere seems to be a high level of correlation between many of the housing characteristics. Perhaps using a model that takes in account multicollinearity would be a good idea.\n\n\n\n\nYear BuiltBuilding SqFtLand SqFtBedsRoomsBathroomsWalkability\n\n\n\n\nCode\nlibrary(scales)\n\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = year_built, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Year Built \\nand Sale Price in Cook County, IL\", \n      x = \"Year Built\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nMore recently built houses seem to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = building_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Building Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Building Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nLarger building houses tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot(aes(x = land_sqft, y = sale_price)) +\n    geom_point(size = 0.1) +\n    geom_smooth(method = \"gam\", color = \"springgreen4\") +\n    scale_y_continuous(labels = label_currency()) + \n    labs(\n      title = \"Single Family Home Land Square Footage \\nand Sale Price in Cook County, IL\", \n      x = \"Land Square Footage\", \n      y = \"Sale Price\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nThe relationship here isn’t entirely clear, but it seems that more land sells for more, up until some point\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_bedrooms, y = sale_price, fill = factor(num_bedrooms))) +\n    scale_x_continuous(n.breaks = 9) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Bedrooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Bedrooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bedrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_rooms, y = sale_price, fill = factor(num_rooms))) +\n    geom_smooth(aes(x = num_rooms, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Number of Rooms \\nand Sale Price in Cook County, IL\", \n      x = \"Number of Rooms\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more rooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price, fill = factor(num_full_baths + num_half_baths * 0.5))) +\n    geom_smooth(aes(x = num_full_baths + num_half_baths * 0.5, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home Total Number of Baths \\nand Sale Price in Cook County, IL\", \n      x = \"Total Number of Baths\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with more bathrooms tend to sell for more\n\n\n\n\nCode\nsfh2123_sales_AT %&gt;%\n  ggplot() +\n    geom_boxplot(aes(x = cmap_walkability_total_score, y = sale_price, fill = factor(cmap_walkability_total_score))) +\n    geom_smooth(aes(x = cmap_walkability_total_score, y = sale_price), method = \"gam\", color = \"black\") +\n    scale_x_continuous(n.breaks = 20) +\n    scale_y_continuous(labels = label_currency()) +\n    labs(\n      title = \"Single Family Home CMAP Walkability and \\nSale Price in Cook County, IL\", \n      x = \"Total Walkability Score\", \n      y = \"Sale Price\"\n    ) + \n    theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nHouses with in less walkable communities tend to sell for more. Although it seems like individuals might want to live in more walkable communities. The kind of large single family homes that tend to sell for more actually contribute toward reducing walkability, which is most likely why we see a downward trend.\n\n\n\n\n\n\nLet us take a look at how our outcome variables are distributed spatially. Clustering might indicate that there is a spatial modeling technique is required.\n\n\nCode\nlibrary(sf)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n  filter(NAME %in% c(\"LEMONT\", \"PALOS\", \"ORLAND\")) %&gt;%\n  left_join(\n    sfh2123_sales_AT %&gt;%\n      group_by(township_code) %&gt;%\n      summarize(\n        median_sp = median(sale_price), \n        median_spr = median(sale_price_ratio))  %&gt;%\n      transmute(median_sp, median_spr, NAME = case_when(\n        township_code == \"19\" ~ \"LEMONT\",\n        township_code == \"30\" ~ \"PALOS\",\n        township_code == \"28\" ~ \"ORLAND\",\n      )\n    )\n  )\n\nsfh2123_sales_sf &lt;- sfh2123_sales_AT %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"))\n\n\n\n\nCode\nlibrary(leaflet)\n\nqpal1 &lt;- colorQuantile(\"Greens\", sfh2123_sales_sf$sale_price, n = 5)\n\nsfh2123_sales_sf %&gt;%\n  leaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n      data = townships,\n      fillColor = \"black\",\n      fillOpacity = 0.1,\n      color = \"black\",\n      weight = 2,\n      opacity = 0.5,\n      highlightOptions = highlightOptions(\n        fillOpacity = 0.2,\n        weight = 3),\n      label = sprintf(\n        \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Median Sale: %s&lt;br/&gt;\",\n        townships$NAME,\n        label_currency()(townships$median_sp)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addCircleMarkers(\n      radius = 3,\n      fillColor = ~ qpal1(sale_price),\n      fillOpacity = 0.7,\n      stroke = FALSE,\n      label = sprintf(\n        \"&lt;strong&gt;Sale Price:&lt;/strong&gt; %s\",\n        label_currency()(sfh2123_sales_sf$sale_price)) %&gt;% lapply(htmltools::HTML),\n      labelOptions = labelOptions(\n          style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n          textsize = \"12px\",\n          direction = \"auto\")\n    ) %&gt;%\n    addLegend(\n      pal = qpal1,\n      values = sfh2123_sales_sf$sale_price,\n      opacity = 0.7,\n      title = \"Sale Price of Single &lt;br&gt;Family Homes in Cook &lt;br&gt;County\",\n      position = \"topright\",\n      na.label = \"Insufficient Data\",\n      labFormat = function(type, cuts, p) {\n        n = length(cuts)\n        p = str_c(round(p * 100), '%')\n        cuts = str_c(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n        str_c('&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts, '&lt;/span&gt;')\n      })\n\n\n\n\n\n\nIt seems that there is clustering of similarly priced homes within our three townships. Lemont has the highest median sale price, but Palos and Orland have similar median sale prices. Perhaps using a spatial modeling technique like a spatial Bayesian or conditional autoregressive model is waranted.\n\n\nCode\nlibrary(spdep)\n\nknn &lt;- knearneigh(sfh2123_sales_sf, k = 20)\nnb &lt;- knn2nb(knn)\nweights &lt;- nb2listw(nb, style = \"B\")\n\nmoran.test(x = sfh2123_sales_sf$sale_price, listw = weights, zero.policy = TRUE) %&gt;% \n  broom::tidy() %&gt;% \n  select(estimate1, p.value, method) %&gt;%\n  rename(`Moran I statistic` = estimate1) %&gt;%\n  knitr::kable()\n\n\n\n\n\nMoran I statistic\np.value\nmethod\n\n\n\n\n0.4998853\n0\nMoran I test under randomisation\n\n\n\n\n\n\n\n\nFor our over/under assessment model, I will define over assessment as greater than the median sale_price_ratio. Theoretically, this should be 1, but parcels are so routinely under assessed as compared to their true sale value that a threshold of 1 would place almost all houses in the under assessed category. I also chose a two class outcome in order to avoid potential complexities related to multiple classification models. I also considered creating a regression model that predicted assessment ratios and simply discretizing the predictions later, but opted against it.\nIt also important to note that our assessment model will only include data from 2022 and our sale price model will include data from 2021 and 2022. Although prices may be slightly different in these years,\n\n\nCode\nassessment_data &lt;- sfh2123_sales_AT %&gt;%\n  filter(year == 2022) %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;%\n  ungroup() %&gt;%\n  mutate(overassessed = factor(sale_price_ratio &lt; median(sale_price_ratio)))\n\nsales_data &lt;- sfh2123_sales_AT %&gt;%\n  group_by(pin) %&gt;%\n  slice_tail() %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\")) %&gt;%\n  st_set_crs(4326)\n\n\n\n\n\n\n\nCode\nlibrary(tidymodels)\ntidymodels_prefer()\n\ns_workflow &lt;- workflow()\n\n\n\n\n\n\n\nCode\ns_rf_spec &lt;- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %&gt;%    \n  set_engine(\"ranger\") %&gt;%    \n  set_mode(\"regression\")  \n\ns_workflow &lt;- workflow() %&gt;%   \n  add_model(s_rf_spec)\n\n\n\n\n\nI chose to use variables that I know are typically considered when buying a house, but we could definitely construct a workflow evaluating models with various predictors.\n\n\nCode\ns_rec &lt;- sales_data %&gt;%    \n  st_drop_geometry() %&gt;%   \n  recipe(sale_price ~ year_built + building_sqft + land_sqft + num_bedrooms + num_rooms + num_full_baths + num_half_baths + num_fireplaces + type_of_residence + construction_quality + attic_finish + garage_size + ext_wall_material + basement_type + central_heating + roof_material + porch + central_air + school_elementary_district_name, data = .) %&gt;%    \n  step_string2factor(all_string()) %&gt;%    \n  step_impute_knn(all_predictors()) %&gt;%   \n  step_novel(all_nominal_predictors()) %&gt;%   \n  step_dummy(all_nominal_predictors())  \n\ns_workflow &lt;- s_workflow %&gt;%   \n  add_recipe(s_rec)\n\n\n\n\n\n\n\nCode\nset.seed(123) \ns_train_set &lt;- sales_data %&gt;% filter(year != 2023)\ns_test_set &lt;- sales_data %&gt;% filter(year == 2023)\n\nset.seed(234) \ns_train_resamples &lt;- bootstraps(s_train_set)  \n\n\nIn order to reduce the model tuning time, we will use a repeated measure ANOVA model to eliminate tuning parameter combinations that are unlikely to yield the best results.\n\n\nCode\nlibrary(finetune)\n\nset.seed(345) \ns_tune &lt;- s_workflow %&gt;%   \n  tune_race_anova(\n    resamples = s_train_resamples,     \n    grid = 20,     \n    metrics = metric_set(rmse, mape),     \n    control = control_race(verbose = TRUE))\n\n\nFinalize our model\n\n\nCode\ns_best &lt;- select_best(s_tune, \"rmse\") \ns_final_rf &lt;- finalize_model(s_rf_spec, s_best)  \ns_final_wf &lt;- workflow() %&gt;%   \n  add_recipe(s_rec) %&gt;%   \n  add_model(s_final_rf)  \n\n\nMake our predictions and get the RMSE and MAPE\n\n\nCode\ns_val_preds &lt;- s_final_wf %&gt;%    \n  fit(s_train_set) %&gt;%   \n  augment(s_test_set)  \n\ns_metrics &lt;- list(   \n  s_val_preds %&gt;%     \n    rmse(sale_price, .pred),   \n  s_val_preds %&gt;%     \n    mape(sale_price, .pred))  \n\ns_metrics %&gt;% bind_rows() %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n97375.92563\n\n\nmape\nstandard\n18.67622\n\n\n\n\n\nIt seems the average deviation of our predicted prices from the true sale price is about $97,500. That is pretty high all things considered. We definitely have quite a lot of refining to do.\n\n\nCode\ns_vip_rf_spec &lt;- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %&gt;% \n  set_engine(\"ranger\", importance = \"impurity\") %&gt;% \n  set_mode(\"regression\")\n\ns_vip_rf &lt;- finalize_model(s_vip_rf_spec, s_best)  \ns_vip_wf &lt;- workflow() %&gt;%   \n  add_recipe(s_rec) %&gt;%   \n  add_model(s_vip_rf) \n\ns_vip_rf_fit &lt;- s_vip_wf %&gt;%    \n  fit(s_train_set)\n\ns_vip_rf_fit %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip::vip(geom = \"point\")\n\n\n\n\n\n\n\n\n\nBuilding square footage is by far the most important variable within our model. This makes a lot of sense given our prior EDA and just intuitively. I think the results line up pretty fairly with what one would expect."
  },
  {
    "objectID": "posts/cook_part_3/index.html#part-b",
    "href": "posts/cook_part_3/index.html#part-b",
    "title": "Cook County Property Assessment - Part 3",
    "section": "Part B",
    "text": "Part B\nWe are going to conduct “out-of-sample” predictions for the entire year of 2023, but first, let’s try to create some new features that may allow us to improve on our assessments.\n\n\nCode\nsfh_assessment_fe &lt;- sfh2123_assessment_dt %&gt;%\n  lazy_dt() %&gt;%\n  left_join(sfh2123_characteristics_dt, by = c(\"pin\", \"township_code\", \"class\", \"tax_year\")) %&gt;% \n  left_join(sfh2123_universe_dt, by = c(\"pin\", \"tax_year\", \"class\", \"township_code\", \"township_name\")) %&gt;%\n  left_join(sfh2123_sales_dt, by = c(\"pin\", \"township_code\", \"class\", \"neighborhood_code\", \"tax_year\" = \"year\")) %&gt;% \n  collect()\n\n\nWe are going to get some age and education features from the ACS\n\n\nCode\nlibrary(tidycensus)\n\nacs2022vars &lt;- load_variables(2022, \"acs5\")\ntables &lt;- list(\"B01001\", \"B15003\")\n\nacs2022vars &lt;- acs2022vars %&gt;%\n  mutate(table = str_sub(name, 1, 7)) %&gt;%\n  filter(table %in% str_c(tables, \"_\")) %&gt;% \n  mutate(table = str_sub(table, 1, 6)) %&gt;% \n  mutate(name = str_c(\"estimate_\", name)) %&gt;%\n  mutate(label = str_sub(label, 11)) %&gt;%\n  separate_wider_delim(label, \"!!\", names = c(\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\"), too_few = \"align_start\")\n\nACS_data &lt;- map_df(tables,\n    \\(table) get_acs(geography = \"tract\", state =\"IL\", county = \"Cook\", table = table, year = 2022)\n  ) %&gt;%\n  pivot_wider(names_from = variable, values_from = c(estimate, moe))\n\n# gets the sum of ACS estimates for a single tract\nget_var_rowsums &lt;- function (ACS_data, var_df) {\n  ACS_data %&gt;%\n    select(.,\n      var_df %&gt;%\n        select(name) %&gt;%\n        unlist() %&gt;%\n        matches()\n    ) %&gt;% rowSums()\n}\n\nprocessed_ACS_data &lt;- ACS_data %&gt;%\n  mutate(\n    TotalPop = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B01001\",\n          `1st` == \"Total:\",\n          is.na(`2nd`)\n        )\n      ),\n    Age00_17 = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B01001\",\n          `3rd` %in% c(\"Under 5 years\", \"5 to 9 years\", \"10 to 14 years\", \"15 to 17 years\"),\n          is.na(`4th`)\n        )\n      ),\n    Age65p = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B01001\",\n          `3rd` %in% c(\"65 and 66 years\", \"67 to 69 years\", \"70 to 74 years\", \"75 to 79 years\", \"80 to 84 years\", \"85 years and over\"),\n          is.na(`4th`)\n        )\n      ),\n    Pct00_17 = Age00_17 / TotalPop,\n    Pct65p = Age65p / TotalPop,\n    EduHS = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` %in% c(\"Regular high school diploma\", \"GED or alternative credential\", \"Some college, less than 1 year\", \"Some college, 1 or more years, no degree\"),\n          is.na(`3rd`)\n        )\n      ),\n    TotalEdu = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `1st` == \"Total:\",\n          is.na(`2nd`)\n        )\n      ),\n    EduAS = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` == \"Associate's degree\",\n          is.na(`3rd`)\n        )\n      ),\n    EduBA = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` == \"Bachelor's degree\",\n          is.na(`3rd`)\n        )\n      ),\n    EduGA = get_var_rowsums(.,\n      acs2022vars %&gt;%\n        filter(\n          table == \"B15003\",\n          `2nd` %in% c(\"Master's degree\", \"Professional school degree\", \"Doctorate degree\"),\n          is.na(`3rd`)\n        )\n      ),\n    PctEdHS = EduHS / TotalEdu,\n    PctEduAS = EduAS / TotalEdu,\n    PctEduBA = EduBA / TotalEdu,\n    PctEduGA = EduGA / TotalEdu\n  ) %&gt;%\n  select(GEOID, starts_with(\"Pct\"))\n\n\nWe will combine these variables with some of our geographic variables from the geouniverse dataset to try to improve our model\n\n\nCode\nsfh_assessment_fe &lt;- sfh_assessment_fe %&gt;%\n  left_join(processed_ACS_data, by = c(\"census_tract_geoid\" = \"GEOID\"))\n\nsfh_assessment_fe_known &lt;- sfh_assessment_fe %&gt;%\n  filter(!is.na(sale_price))\n\n\n\n\nCode\ns_fe_workflow &lt;- workflow()\n\n\n\n\nCode\ns_fe_rf_spec &lt;- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %&gt;%    \n  set_engine(\"ranger\") %&gt;%    \n  set_mode(\"regression\")  \n\ns_fe_workflow &lt;- workflow() %&gt;%   \n  add_model(s_fe_rf_spec)\n\n\n\n\nCode\ns_fe_rec &lt;- recipe(sale_price ~ year_built + building_sqft + land_sqft + num_bedrooms + num_rooms + num_full_baths + num_half_baths + num_fireplaces + type_of_residence + construction_quality + attic_finish + garage_size + ext_wall_material + basement_type + central_heating + roof_material + porch + central_air + neighborhood_code + school_elementary_district_name + Pct00_17 + Pct65p + PctEdHS + PctEduAS + PctEduBA + PctEduGA, data = sfh_assessment_fe_known) %&gt;%    \n  step_string2factor(all_string()) %&gt;%    \n  step_impute_knn(all_predictors()) %&gt;%   \n  step_novel(all_nominal_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors())  \n\ns_fe_workflow &lt;- s_fe_workflow %&gt;%   \n  add_recipe(s_fe_rec)\n\n\n\n\nCode\nset.seed(456) \ns_fe_train_set &lt;- sfh_assessment_fe_known %&gt;% filter(tax_year != 2023)\ns_fe_test_set &lt;- sfh_assessment_fe_known %&gt;% filter(tax_year == 2023)\n\nset.seed(567) \ns_fe_train_resamples &lt;- bootstraps(s_fe_train_set)  \n\n\n\n\nCode\nlibrary(finetune)\n\nset.seed(678) \ns_fe_tune &lt;- s_fe_workflow %&gt;%   \n  tune_race_anova(\n    resamples = s_fe_train_resamples,     \n    grid = 20,     \n    metrics = metric_set(rmse, mape),     \n    control = control_race(verbose = TRUE))\n\n\n\n\nCode\ns_fe_best &lt;- select_best(s_fe_tune, \"rmse\") \ns_fe_final_rf &lt;- finalize_model(s_fe_rf_spec, s_fe_best)  \ns_fe_final_wf &lt;- workflow() %&gt;%   \n  add_recipe(s_fe_rec) %&gt;%   \n  add_model(s_fe_final_rf)  \n\n\n\n\nCode\ns_fe_val_preds &lt;- s_fe_final_wf %&gt;%    \n  fit(s_fe_train_set) %&gt;%   \n  augment(s_fe_test_set)  \n\ns_fe_metrics &lt;- list(   \n  s_fe_val_preds %&gt;%     \n    rmse(sale_price, .pred),   \n  s_fe_val_preds %&gt;%     \n    mape(sale_price, .pred))  \n\ns_fe_metrics %&gt;% bind_rows() %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n100419.96886\n\n\nmape\nstandard\n19.25759\n\n\n\n\n\nFor some reason, it seems that our model has gotten slightly worse. I wonder if the added features that we used are not truly being incorporated into the model in a meaningfully way. This could mean that our added features are simply adding noise.\n\n\nCode\ns_fe_vip_rf_spec &lt;- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %&gt;% \n  set_engine(\"ranger\", importance = \"impurity\") %&gt;% \n  set_mode(\"regression\")\n\ns_fe_vip_rf &lt;- finalize_model(s_fe_vip_rf_spec, s_fe_best)  \ns_fe_vip_wf &lt;- workflow() %&gt;%   \n  add_recipe(s_fe_rec) %&gt;%   \n  add_model(s_fe_vip_rf) \n\ns_fe_vip_rf_fit &lt;- s_fe_vip_wf %&gt;%    \n  fit(s_fe_train_set)\n\ns_fe_vip_rf_fit %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip::vip(geom = \"point\")\n\n\n\n\n\n\n\n\n\nInterestingly, the percent of individuals with graduate degrees is one of the more important features in the model."
  },
  {
    "objectID": "posts/cook_part_3/index.html#part-c",
    "href": "posts/cook_part_3/index.html#part-c",
    "title": "Cook County Property Assessment - Part 3",
    "section": "Part C",
    "text": "Part C\nBecause our feature engineered model worked worse than our original model, we are going to use our original model.\n\n\nCode\ns_aug &lt;- s_vip_rf_fit %&gt;%\n    augment(sfh_assessment_fe %&gt;% filter(tax_year == 2023))\n\n\nLet’s see how our assessments compares to the actual assessments.\n\n\nCode\ns_aug %&gt;%\n  mutate(mymodel_error = .pred - sale_price) %&gt;%\n  mutate(assessed_error = 10*certified_tot - sale_price) %&gt;%\n  summarize(\n    mymodel_RMSE = sqrt(mean(mymodel_error^2, na.rm = TRUE)), \n    assessed_RMSE = sqrt(mean(assessed_error^2, na.rm = TRUE)),\n    mymodel_MAPE = mean(abs(mymodel_error/sale_price), na.rm = TRUE),\n    assessed_MAPE = mean(abs(assessed_error/sale_price), na.rm = TRUE),) %&gt;%\n  mutate(across(where(is.numeric), round, digits = 3)) %&gt;%\n  pivot_longer(everything(), names_to = c(\"model\", \"metric\"), names_pattern = \"(.*)_(.*)\", values_to = \"value\") %&gt;%\n  knitr::kable()\n\n\n\n\n\nmodel\nmetric\nvalue\n\n\n\n\nmymodel\nRMSE\n99182.379\n\n\nassessed\nRMSE\n99502.179\n\n\nmymodel\nMAPE\n0.194\n\n\nassessed\nMAPE\n0.194\n\n\n\n\n\nIt’s pretty close, but this is not as great as we think it is. We saw in Part 1 that the assessments tend to be less than 85% of the sale price, so this is not really that great.\nNevertheless, let’s see how the distribution of of the Cook County assessed prices, our modeled assessments prices, and the actual sale prices.\n\n\nCode\ns_aug %&gt;%\n  mutate(assessed_price = 10*certified_tot) %&gt;%\n  mutate(modeled_price = .pred) %&gt;%\n  select(pin, ends_with(\"price\")) %&gt;%\n  pivot_longer(ends_with(\"price\"), names_to = \"metric\", values_to = \"value\") %&gt;%\n  ggplot(aes(value)) + \n    geom_density(position = \"stack\", na.rm = TRUE) +\n    facet_wrap(vars(metric), nrow = 3) +\n    scale_x_continuous(labels = label_currency()) + \n    labs(title = \"Sale Price Distribution of Assessed Prices, Modeled Prices, and Sale Prices\")\n\n\n\n\n\n\n\n\n\nThe distribution of assessed and modeled prices seem to be tending toward the mean. The estimates seem to be tending toward mean a little. This is most likely because the unbalanced nature of our data. There are a lot of homes within the $200,000 to $600,000 range than there are outside, so the assessed and modeled prices seem to be tending toward that range."
  },
  {
    "objectID": "posts/cook_part_1/index.html",
    "href": "posts/cook_part_1/index.html",
    "title": "Cook County Property Assessment - Part 1",
    "section": "",
    "text": "You have been tasked with undertaking a multi-part analysis of homes in Cook County, Illinois. You are provided with a database to facilitate this analysis. This database was constructed from the Cook County Open Data portal. More information is included in the database section below. Note that the database must be downloaded.\nFour tables are provided:\nassessments - 2021 to 2023 (not finalized)\nSee: https://datacatalog.cookcountyil.gov/Property-Taxation/Assessor-Assessed-Values/uzyt-m557/about_data\n\n\nView Table Columns\n\n\n\n\n\n\nColumn Name\nDescription\nType\n\n\n\n\npin\nParcel Identification Number (PIN)\nPlain Text\n\n\ntax_year\nTax year\nNumber\n\n\nclass\nProperty class\nPlain Text\n\n\ntownship_code\nTownship code\nPlain Text\n\n\ntownship_name\nTownship name\nPlain Text\n\n\nmailed_bldg\nAssessor mailed building value\nNumber\n\n\nmailed_land\nAssessor mailed land value\nNumber\n\n\nmailed_tot\nAssessor mailed total value\nNumber\n\n\ncertified_bldg\nAssessor certified building value\nNumber\n\n\ncertified_land\nAssessor certified land value\nNumber\n\n\ncertified_tot\nAssessor certified total value\nNumber\n\n\nboard_bldg\nBoard of Review certified building value\nNumber\n\n\nboard_land\nBoard of Review certified land value\nNumber\n\n\nboard_tot\nBoard of Review certified total value\nNumber\n\n\n\n\n\n\ncharacteristics - Tax year 2023 characteristics. See: https://datacatalog.cookcountyil.gov/Property-Taxation/Assessor-Single-and-Multi-Family-Improvement-Chara/x54s-btds/about_data\n\n\nView Table Columns\n\n\n\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\n\n\n\n\npin\nParcel Identification Number (PIN)\nPlain Text\n\n\ntax_year\nTax year\nNumber\n\n\ncard_num\nCard number. Each card is an improvement/building on the parcel\nNumber\n\n\nclass\nProperty class\nPlain Text\n\n\ntownship_code\nTownship code\nPlain Text\n\n\nproration_key_pin\nTieback key PIN. Prorated properties (whose value is split across multiple PINs) have a “main” or key PIN\nPlain Text\n\n\npin_proration_rate\nTieback proration rate. Prorated properties (whose value is split across multiple PINs) pay taxes on the proportion of value on their PIN. In other words, assessed value is multiplied by proration rate to determine taxable assessed value\nNumber\n\n\ncard_proration_rate\nCard proration rate. Prorated parcels (whose value is split across multiple cards) pay taxes on the proportion of value on their card. In other words, assessed value is multiplied by proration rate to determine taxable assessed value. Cards are divisions within parcels, such as one of multiple buildings on a single parcel.\nNumber\n\n\ncdu\nCondition, Desirability, and Utility code. Not well maintained.\nPlain Text\n\n\npin_is_multicard\nMulticard PIN. Indicates whether the parcel contains more than one building (ADU, coach house, etc.)\nCheckbox\n\n\npin_num_cards\nNumber of cards on this parcel. Each card is an improvement/building\nNumber\n\n\npin_is_multiland\nMultiland PIN. Indicates whether parcel has more than one landline\nCheckbox\n\n\npin_num_landlines\nNumber of landlines on a parcel. The sum of all landline square footage should be equal to the total square footage of the parcel. Each landline can correspond to a different land price/rate\nNumber\n\n\nyear_built\nYear built\nNumber\n\n\nbuilding_sqft\nBuilding square feet. Square footage of the building, as measured from the exterior\nNumber\n\n\nland_sqft\nLand square feet. Square footage of the land (not just the building) of the property. Note that a single PIN can have multiple landlines, meaning it can be associated with more than one land price/rate\nNumber\n\n\nnum_bedrooms\nNumber of bedrooms\nNumber\n\n\nnum_rooms\nRooms. Number of total rooms in the building (excluding baths). Not to be confused with bedrooms\nNumber\n\n\nnum_full_baths\nFull baths. Defined as having a bath or shower. If this value is missing, the default value is set to 1\nNumber\n\n\nnum_half_baths\nHalf baths. Defined as bathrooms without a shower or bathtub\nNumber\n\n\nnum_fireplaces\nFireplaces. Counted as the number of flues one can see from the outside of the building\nNumber\n\n\ntype_of_residence\nType of residence\nPlain Text\n\n\nconstruction_quality\nConstruction quality\nPlain Text\n\n\nnum_apartments\nApartments. Number of apartments for class 211 and 212 properties\nPlain Text\n\n\nattic_finish\nAttic finish\nPlain Text\n\n\ngarage_attached\nGarage 1 attached\nPlain Text\n\n\ngarage_area_included\nIs Garage 1 physically included within the building area? If yes, the garage area is subtracted from the building square feet calculation by the field agent\nPlain Text\n\n\ngarage_size\nGarage 1 size\nPlain Text\n\n\ngarage_ext_wall_material\nGarage 1 exterior wall material\nPlain Text\n\n\nattic_type\nAttic type\nPlain Text\n\n\nbasement_type\nBasement type\nPlain Text\n\n\next_wall_material\nExterior wall material\nPlain Text\n\n\ncentral_heating\nCentral heating\nPlain Text\n\n\nrepair_condition\nRepair condition\nPlain Text\n\n\nbasement_finish\nBasement finish\nPlain Text\n\n\nroof_material\nRoof material\nPlain Text\n\n\nsingle_v_multi_family\nSingle vs. multi-family use\nPlain Text\n\n\nsite_desirability\nSite desirability\nPlain Text\n\n\nnum_commercial_units\nNumber of commercial units on the parcel (the vast majority are for properties with class 212)\nPlain Text\n\n\nrenovation\nRenovation\nPlain Text\n\n\nrecent_renovation\nRenovation in last 3 years\nCheckbox\n\n\nporch\nPorch\nPlain Text\n\n\ncentral_air\nCentral air conditioning\nPlain Text\n\n\ndesign_plan\nDesign plan\nPlain Text\n\n\n\n\n\n\ngeospatial_universe - Information on latitude/longitude and neighborhood code from tax year 2022 (released on a delay). Only a subset of columns is selected. See: https://datacatalog.cookcountyil.gov/Property-Taxation/Assessor-Parcel-Universe/nj4t-kc8j/about_data\n\n\nView Table Columns\n\n\n\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\n\n\n\n\npin\nParcel Identification Number (PIN)\nPlain Text\n\n\npin10\nParcel Identification Number (10-digit)\nPlain Text\n\n\ntax_year\nTax year\nNumber\n\n\nclass\nProperty class\nPlain Text\n\n\ntriad_name\nTriad name. Reassessment of property in Cook County is done within a triennial cycle, meaning it occurs every three years. The Cook County Assessor’s Office alternates reassessments between triads: the north and west suburbs, the south and west suburbs and the City of Chicago.\nPlain Text\n\n\ntriad_code\nTriad code. Reassessment of property in Cook County is done within a triennial cycle, meaning it occurs every three years. The Cook County Assessor’s Office alternates reassessments between triads: the north and west suburbs, the south and west suburbs and the City of Chicago.\nPlain Text\n\n\ntownship_name\nTownship name\nPlain Text\n\n\ntownship_code\nTownship code\nPlain Text\n\n\nneighborhood_code\nAssessor neighborhood code, first two digits are township, last three are neighborhood\nPlain Text\n\n\ntax_district_code\nTax district code, as seen on individual property tax bills (Not currently up-to-date)\nPlain Text\n\n\nzip_code\nProperty zip code\nPlain Text\n\n\nlongitude\nParcel centroid longitude\nNumber\n\n\nlatitude\nParcel centroid latitude\nNumber\n\n\ncentroid_x_crs_3435\nParcel centroid X coordinate (CRS 3435)\nNumber\n\n\ncentroid_y_crs_3435\nParcel centroid Y coordinate (CRS 3435)\nNumber\n\n\ncensus_block_group_geoid\nCensus block group GEOID\nPlain Text\n\n\ncensus_block_geoid\nCensus block GEOID\nPlain Text\n\n\ncensus_congressional_district_geoid\nCensus congressional district GEOID\nPlain Text\n\n\ncensus_county_subdivision_geoid\nCensus county subdivision GEOID\nPlain Text\n\n\ncensus_place_geoid\nCensus place GEOID\nPlain Text\n\n\ncensus_puma_geoid\nCensus PUMA GEOID\nPlain Text\n\n\ncensus_school_district_elementary_geoid\nCensus school district (elementary) GEOID\nPlain Text\n\n\ncensus_school_district_secondary_geoid\nCensus school district (secondary) GEOID\nPlain Text\n\n\ncensus_school_district_unified_geoid\nCensus school district (unified) GEOID\nPlain Text\n\n\ncensus_state_representative_geoid\nCensus state representative GEOID\nPlain Text\n\n\ncensus_state_senate_geoid\nCensus state senate GEOID\nPlain Text\n\n\ncensus_tract_geoid\nCensus tract GEOID\nPlain Text\n\n\ncensus_zcta_geoid\nCensus ZCTA GEOID\nPlain Text\n\n\ncensus_data_year\nCensus data year\nNumber\n\n\ncensus_acs5_congressional_district_geoid\nCensus ACS5 congressional district GEOID\nPlain Text\n\n\ncensus_acs5_county_subdivision_geoid\nCensus ACS5 county subdivision GEOID\nPlain Text\n\n\ncensus_acs5_place_geoid\nCensus ACS5 place GEOID\nPlain Text\n\n\ncensus_acs5_puma_geoid\nCensus ACS5 PUMA GEOID\nPlain Text\n\n\ncensus_acs5_school_district_elementary_geoid\nCensus ACS5 school district (elementary) GEOID\nPlain Text\n\n\ncensus_acs5_school_district_secondary_geoid\nCensus ACS5 school district (secondary) GEOID\nPlain Text\n\n\ncensus_acs5_school_district_unified_geoid\nCensus ACS5 school district (unified) GEOID\nPlain Text\n\n\ncensus_acs5_state_representative_geoid\nCensus ACS5 state representative GEOID\nPlain Text\n\n\ncensus_acs5_state_senate_geoid\nCensus ACS5 state senate GEOID\nPlain Text\n\n\ncensus_acs5_tract_geoid\nCensus ACS5 tract GEOID\nPlain Text\n\n\ncensus_acs5_data_year\nCensus ACS5 data year\nNumber\n\n\nboard_of_review_district_num\nBoard of Review district number\nPlain Text\n\n\nboard_of_review_district_data_year\nBoard of Review district data year\nNumber\n\n\ncommissioner_district_num\nCommissioner district number\nPlain Text\n\n\ncommissioner_district_data_year\nCommissioner district data year\nNumber\n\n\njudicial_district_num\nJudicial district number\nPlain Text\n\n\njudicial_district_data_year\nJudicial district data year\nNumber\n\n\nward_num\nWard number\nPlain Text\n\n\nward_chicago_data_year\nChicago ward data year\nNumber\n\n\nward_evanston_data_year\nEvanston ward data year\nNumber\n\n\nchicago_community_area_num\nChicago community area number\nPlain Text\n\n\nchicago_community_area_name\nChicago community area name\nPlain Text\n\n\nchicago_community_area_data_year\nChicago community area data year\nNumber\n\n\nchicago_industrial_corridor_num\nChicago industrial corridor number\nPlain Text\n\n\nchicago_industrial_corridor_name\nChicago industrial corridor name\nPlain Text\n\n\nchicago_industrial_corridor_data_year\nChicago industrial corridor data year\nNumber\n\n\nchicago_police_district_num\nChicago police district number\nPlain Text\n\n\nchicago_police_district_data_year\nChicago police district data year\nNumber\n\n\ncoordinated_care_area_num\nCoordinated Care Area number\nPlain Text\n\n\ncoordinated_care_area_data_year\nCoordinated Care Area data year\nNumber\n\n\nenterprise_zone_num\nEnterprise Zone number\nPlain Text\n\n\nenterprise_zone_data_year\nEnterprise Zone data year\nNumber\n\n\nindustrial_growth_zone_num\nIndustrial Growth Zone number\nPlain Text\n\n\nindustrial_growth_zone_data_year\nIndustrial Growth Zone data year\nNumber\n\n\nqualified_opportunity_zone_num\nQualified Opportunity Zone number\nPlain Text\n\n\nqualified_opportunity_zone_data_year\nQualified Opportunity Zone data year\nNumber\n\n\nflood_fema_sfha\nFEMA Special Flood Hazard Area (SFHA) indicator\nCheckbox\n\n\nflood_fema_data_year\nFEMA Special Flood Hazard Area (SFHA) data year\nNumber\n\n\nflood_fs_factor\nFirst Street Flood Factor\nNumber\n\n\nflood_fs_risk_direction\nFirst Street flood risk direction\nNumber\n\n\nflood_fs_data_year\nFirst Street data year\nNumber\n\n\nohare_noise_contour_no_buffer_bool\nO’Hare noise contour indicator (no buffer). Indicates whether or not a parcel’s centroid is within O’Hare’s 65 DNL noise contour\nCheckbox\n\n\nohare_noise_contour_half_mile_buffer_bool\nO’Hare noise contour indicator (1/2 mile buffer). Indicates whether or not a parcel’s centroid is within O’Hare’s 65 DNL noise contour, buffered by 1/2 mile\nCheckbox\n\n\nohare_noise_contour_data_year\nO’Hare noise contour data year. The “omp” value corresponds to the projected noise contour upon completion of the O’Hare Modernization Project\nNumber\n\n\nairport_noise_dnl\nAirport continuous noise surface estimated DNL\nNumber\n\n\nairport_noise_data_year\nAirport continuous noise surface estimated data year\nPlain Text\n\n\nschool_elementary_district_geoid\nSchool district (elementary) GEOID, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_elementary_district_name\nSchool district (elementary) name, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_secondary_district_geoid\nSchool district (secondary) GEOID, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_secondary_district_name\nSchool district (secondary) name, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_unified_district_geoid\nSchool district (unified) GEOID, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_unified_district_name\nSchool district (unified) name, derived from Cook County and City of Chicago shapefiles. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\nschool_year\nSchool year\nPlain Text\n\n\nschool_data_year\nSchool data year\nNumber\n\n\ntax_municipality_num\nMunicipality number\nPlain Text\n\n\ntax_municipality_name\nMunicipality name\nPlain Text\n\n\ntax_school_elementary_district_num\nSchool district (elementary) number, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_elementary_district_name\nSchool district (elementary) name, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_secondary_district_num\nSchool district (secondary) number, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_secondary_district_name\nSchool district (secondary) name, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_unified_district_num\nSchool district (unified) number, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_school_unified_district_name\nSchool district (unified) name, derived from tax district. Chicago Public Schools are associated with attendance areas where suburban schools are associated with districts.\nPlain Text\n\n\ntax_community_college_district_num\nCommunity college district number\nPlain Text\n\n\ntax_community_college_district_name\nCommunity college district name\nPlain Text\n\n\ntax_fire_protection_district_num\nFire protection district number\nPlain Text\n\n\ntax_fire_protection_district_name\nFire protection district name\nPlain Text\n\n\ntax_library_district_num\nLibrary district number\nPlain Text\n\n\ntax_library_district_name\nLibrary district name\nPlain Text\n\n\ntax_park_district_num\nPark district number\nPlain Text\n\n\ntax_park_district_name\nPark district name\nPlain Text\n\n\ntax_sanitation_district_num\nSanitation district number\nPlain Text\n\n\ntax_sanitation_district_name\nSanitation district name\nPlain Text\n\n\ntax_special_service_area_num\nSpecial Service Area number\nPlain Text\n\n\ntax_special_service_area_name\nSpecial Service Area name\nPlain Text\n\n\ntax_tif_district_num\nTIF district number\nPlain Text\n\n\ntax_tif_district_name\nTIF district name\nPlain Text\n\n\ntax_districts_data_year\nData year for municipality, school, community college, fire, library, park, sanitary, special service area, and tax increment financing tax districts.\nNumber\n\n\ncmap_walkability_grid_id\nCMAP walkability grid ID. From CMAP’s ON TO 2050 spatial data files\nPlain Text\n\n\ncmap_walkability_no_transit_score\nCMAP walkability score (no transit). From CMAP’s ON TO 2050 spatial data files\nNumber\n\n\ncmap_walkability_total_score\nCMAP walkability total score. From CMAP’s ON TO 2050 spatial data files\nNumber\n\n\ncmap_walkability_data_year\nCMAP walkability data year\nNumber\n\n\nsubdivision_id\nSubdivision ID\nPlain Text\n\n\nsubdivision_data_year\nSubdivision data year\nNumber\n\n\n\n\n\n\nsales - Information on sales from 2021 to present (current mid-September 2023) See: https://datacatalog.cookcountyil.gov/Property-Taxation/Assessor-Parcel-Sales/wvhk-k5uv/about_data\n\n\nView Table Columns\n\n\n\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\n\n\n\n\npin\nParcel Identification Number (PIN)\nPlain Text\n\n\nyear\nYear\nNumber\n\n\ntownship_code\nTownship code\nPlain Text\n\n\nneighborhood_code\nAssessor neighborhood code, first two digits are township, last three are neighborhood\nPlain Text\n\n\nclass\nProperty class\nPlain Text\n\n\nsale_date\nSale date (recorded, not executed)\nDate & Time\n\n\nis_mydec_date\nIndicates whether the sale date has been overwritten with a more precise value from IDOR (Illinois Department of Revenue). In the past the Assessor’s ingest process truncated sale dates to the first of the month. Not all sales can be updated with dates from IDOR.\nCheckbox\n\n\nsale_price\nSale price\nNumber\n\n\nsale_document_num\nSale document number. Corresponds to Clerk’s document number\nPlain Text\n\n\nsale_deed_type\nSale deed type\nPlain Text\n\n\nmydec_deed_type\nDeed type from MyDec, more granular than CCAO deed type.\nPlain Text\n\n\nsale_seller_name\nSale seller name\nPlain Text\n\n\nis_multisale\nIndicates whether a parcel was sold individually or as part of a larger group of PINs\nCheckbox\n\n\nnum_parcels_sale\nThe number of parcels that were part of the sale\nNumber\n\n\nsale_buyer_name\nSale buyer name\nPlain Text\n\n\nsale_type\nSale type\nPlain Text\n\n\nsale_filter_same_sale_within_365\nRemove sale with the same value (for the same PIN) within 365 days\nCheckbox\n\n\nsale_filter_less_than_10k\nIndicator for whether sale is less than $10K FMW\nCheckbox\n\n\nsale_filter_deed_type\nIndicator for quit claim, executor, beneficiary and missing deed types\nCheckbox\n\n\n\n\n\n\n\n\nFirst let’s load our data and make some joins to sales data\n\n\nCode\nlibrary(tidyverse)\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"../data/cook.sqlite\")\n\nsfh_sales &lt;- tbl(con, 'sales') %&gt;%\n    collect() %&gt;%\n    filter(class %in% c(202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278)) %&gt;%\n    mutate(sale_date = as_datetime(sale_date)) %&gt;% \n    mutate(township_code = as.character(township_code)) %&gt;%\n    distinct(doc_no, .keep_all = TRUE)\n\ntownship_codes &lt;- read_csv(\"../data/township_codes.csv\") %&gt;% \n    mutate(across(where(is.numeric), as.character))\n\nsfh_characteristics &lt;- tbl(con, 'characteristics') %&gt;%\n    collect() %&gt;%\n    distinct(pin, .keep_all = T) %&gt;%\n    select(-c(class, township_code)) %&gt;%\n    right_join(sfh_sales, by = join_by(pin, year == year)) %&gt;%\n    right_join(township_codes)\n\nsfh_assessments &lt;- tbl(con, 'assessments') %&gt;%\n    collect() %&gt;%\n    mutate(township_code = as.character(township_code)) %&gt;%\n    distinct(pin, .keep_all = T) %&gt;%\n    select(-c(class, township_code)) %&gt;%\n    right_join(sfh_sales, by = join_by(pin, tax_year == year))\n\n\n\n\nThe distributions of average sale price for single family homes by township lines up with most people’s preconceptions of Cook County. We can see that average sale prices are highest in townships in northern Cook County in Chicago and the more wealthy northern suburbs. Within these very same townships, we can see that single family homes both tend to be larger and tend to cost more per square foot. Lastly, we can see that the oldest households tend be within the city of Chicago, while the mean age of houses within Cook County seems to lower, the farther you get from the city of Chicago.\n\nSale PriceBuilding SqFtPrice Per SqFtYears old\n\n\n\n\nCode\nlibrary(sf)\nlibrary(leaflet)\nlibrary(scales)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n    mutate(ORIGOID = as.character(ORIGOID)) %&gt;%\n    right_join(township_codes, by = join_by(ORIGOID == origoid))\n\nsfh_mean_by_township &lt;- sfh_characteristics %&gt;%\n    group_by(township_code) %&gt;%\n    reframe(sale_price_mean = mean(sale_price, na.rm = T),\n        bldg_sf_mean = mean(char_bldg_sf, na.rm = T),\n        sale_price_per_sf = mean(sale_price/char_bldg_sf, na.rm = T),\n        years_old_mean = mean(2023 - char_yrblt, na.rm = T)) %&gt;%\n    right_join(townships) %&gt;%\n    st_as_sf()\n    \nqpal &lt;- colorQuantile(\"Greens\", sfh_mean_by_township$sale_price_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(sale_price_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Average Sale: %s&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_currency()(sfh_mean_by_township$sale_price_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\"))   %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$sale_price_mean,\n            opacity = 0.7,\n            title = \"Mean Sale Price of &lt;/br&gt;Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Oranges\", sfh_mean_by_township$bldg_sf_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(bldg_sf_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Mean Building sqft: %s&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_comma(1)(sfh_mean_by_township$bldg_sf_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\"))   %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$bldg_sf_mean,\n            opacity = 0.7,\n            title = \"Mean Building Square Feet&lt;/br&gt; of Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_comma(1)(cuts[-n]), \" - \", label_comma(1)(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Blues\", sfh_mean_by_township$sale_price_per_sf, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(sale_price_per_sf),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;%s per sqft&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_currency()(sfh_mean_by_township$sale_price_per_sf)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")) %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$sale_price_per_sf,\n            opacity = 0.7,\n            title = \"Dollars per Square Foot of &lt;/br&gt;Single Family Homes in &lt;/br&gt;Cook County by Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Reds\", sfh_mean_by_township$years_old_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(years_old_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;%s years old&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_number(1)(sfh_mean_by_township$years_old_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")) %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$years_old_mean,\n            opacity = 0.7,\n            title = \"Mean Years Old of &lt;/br&gt;Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_number(1)(cuts[-n]), \" - \", label_number(1)(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\n\n\nIt seems that single family homes built in the last 30 - 40 years tend to be more expensive, but beyond that sale prices do not seem to be associated with sale prices. As expected, higher square footage single family homes tend to sell for more, but there is still a large amount variability in sale prices. Larger land square footage single family homes seem to sell for more up until about 15,000 square feet where additional land does not seem to be associated with much greater sale prices. More beds, rooms, and bathrooms seem to all be associated with greater sale prices. However, there seems to be some odd outliers with 0 bedrooms or 2 rooms that are selling for more than would be expected. This may be something we would want to investigate later. These could be simply a result of faulty assessor data.\n\nYear builtBuilding SqFtLand SqFtBedsRoomsBathrooms\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    ggplot(aes(x = char_yrblt, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Sale Price and Year Built in Cook County, IL\", \n            x = \"Year Built\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    ggplot(aes(x = char_bldg_sf, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Building Square Footage and Sale Price \\nin Cook County, IL\", \n            x = \"Building Square Footage\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    filter(char_land_sf &lt;= 10^5) %&gt;%\n    ggplot(aes(x = char_land_sf, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Building Square Footage and Sale Price \\nin Cook County, IL\", \n            x = \"Land Square Footage\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_beds, y = sale_price, fill = factor(char_beds))) +\n        scale_x_continuous(n.breaks = 9) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Number of Bedrooms and Sale Price \\nin Cook County, IL\", \n            x = \"Number of Bedrooms\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_rooms, y = sale_price, fill = factor(char_rooms))) +\n        scale_x_continuous(n.breaks = 20) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Number of Rooms and Sale Price \\nin Cook County, IL\", \n            x = \"Number of Rooms\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_fbath + char_hbath * 0.5, y = sale_price, fill = factor(char_fbath + char_hbath * 0.5))) +\n        scale_x_continuous(n.breaks = 20) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Total Number of Baths and Sale Price \\nin Cook County, IL\", \n            x = \"Total Number of Baths\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s get our data into a format that the cmfproperty package can use.\n\n\nCode\nlibrary(cmfproperty)\n\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"../data/cook.sqlite\")\n\nsfh_sales_cmf &lt;- sfh_sales %&gt;% \n    select(pin, year, sale_price, doc_no) %&gt;%\n    distinct(doc_no, .keep_all = TRUE) %&gt;%\n    select(-doc_no) %&gt;%\n    filter(as.numeric(sale_price) &gt; 2500)\n\nassessments_cmf &lt;- tbl(con, \"assessments\") %&gt;%\n    collect() %&gt;%\n    select(pin, tax_year, certified_tot)\n\nsale_assess_cmf &lt;- sfh_sales_cmf %&gt;% \n    left_join(assessments_cmf, by = join_by(pin, year == tax_year)) %&gt;% \n    rename(PIN = pin, SALE_YEAR = year, SALE_PRICE = sale_price, ASSESSED_VALUE = certified_tot) %&gt;%\n    mutate(ASSESSED_VALUE = 10 * ASSESSED_VALUE)\n\nratios &lt;- reformat_data(sale_assess_cmf,\n    sale_col = \"SALE_PRICE\",\n    assessment_col = \"ASSESSED_VALUE\",\n    sale_year_col = \"SALE_YEAR\")\n\nstats &lt;- calc_iaao_stats(ratios)\n\n\nOverall, we can see that at every sale price decile, single family homes are underassessed compared to their true sale price. However, the degree to which single family homes are underassessed is not equal. Regardless of efforts of the county, it is clear that in 2023 (for the months of Jan-Sep), houses within the lowest deciles tend to be assessed at higher ratios to their true sales price. The overall picture from 2021 to Sep 2023 is more enocouraging, but nevertheless the lowest decile tends to be assessed at higher rates than all other deciles and the 2nd to 5th lowest deciles seem to be asssed at lower rates than the higher deciles.\n\nBinned ScatterPercent AssessedCoefficient of DispersionPrice-Related DifferentialCoefficient of Price-Related Bias\n\n\n\n\nCode\nbinned &lt;- binned_scatter(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nknitr::asis_output(htmltools::htmlPreserve(binned[[1]]))\n\nbinned[[2]]\n\n\n\n\n\n\n\n\n\nIn 2023, the most expensive homes (the top decile) were assessed at 76.2% of their value and the least expensive homes (the bottom decile) were assessed at 93.1%. In other words, the least expensive homes were assessed at 1.22 times the rate applied to the most expensive homes. Across our sample from 2021 to 2023, the most expensive homes were assessed at 77.4% of their value and the least expensive homes were assessed at 84.6%, which is 1.09 times the rate applied to the most expensive homes.\n\n\n\n\n\n\nCode\npct_over &lt;- pct_over_under(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nknitr::asis_output(htmltools::htmlPreserve(pct_over[[1]]))\n\npct_over[[2]]\n\n\n\n\n\n\n\n\n\nIn Cook County, IL, 58% of the lowest value homes are overassessed and 52% of the highest value homes are overassessed.\n\n\n\n\n\n\nCode\niaao_rslt &lt;- iaao_graphs(stats,\n    ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, Illinois\")\n\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[1]]))\n\niaao_rslt[[2]]\n\n\n\n\n\n\n\n\n\nFor 2023, the COD in Cook County, Illinois was 19.6 which did not meet the IAAO standard for uniformity.\n\n\n\n\n\n\nCode\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[3]]))\n\niaao_rslt[[4]]\n\n\n\n\n\n\n\n\n\nIn 2023, the PRD in  Cook County, Illinois, was 1.074 which does not meet  the IAAO standard for vertical equity.\n\n\n\n\n\n\nCode\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[5]]))\n\niaao_rslt[[6]]\n\n\n\n\n\n\n\n\n\nIn 2023, the PRB in Cook County, Illinois was 0.004 which indicates that sales ratios increase by 0.4% when home values double. This meets the IAAO standard.\n\n\n\n\n\n\n\n\nLet’s evaluate a couple different linear models (linear models were chosen simply because of the lower computing power necessary to train them). First, we’ll split our data.\n\n\nCode\nlibrary(tidymodels) \ntidymodels_prefer()\n\nset.seed(1)\nsplit &lt;- initial_split(sfh_characteristics)\ntrain_set &lt;- training(split)\ntest_set &lt;- testing(split)\n\nset.seed(2)\ntrain_resamples &lt;- bootstraps(train_set)\n\n\nWe’ll preprocess our data.\n\n\nCode\nbasic_rec &lt;- recipe(sale_price ~ char_yrblt + char_bldg_sf + char_land_sf + char_beds + char_rooms + char_fbath + char_hbath + township_code, data = sfh_characteristics) %&gt;% \n    step_mutate(years_old = 2023 - char_yrblt, role = \"predictor\") %&gt;%\n    remove_role(char_yrblt, old_role = \"predictor\") %&gt;%\n    step_string2factor(township_code) %&gt;% \n    step_naomit(all_predictors()) %&gt;% \n    step_novel(all_nominal_predictors()) %&gt;%\n    step_dummy(all_nominal_predictors()) %&gt;%\n    step_zv(all_predictors())\n\nnormalized_rec &lt;- basic_rec %&gt;% \n   step_normalize(all_predictors())\n\n\nSave the specifications of our models.\n\n\nCode\nols_spec &lt;- linear_reg() %&gt;% \n    set_engine(\"lm\") %&gt;%\n    set_mode(\"regression\")\n\nridge_spec &lt;- linear_reg(penalty = tune(), mixture = 0) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\nlasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\nenet_spec &lt;- linear_reg(penalty = tune(), mixture = tune()) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\n\nCreate our workflows.\n\n\nCode\nall_workflows &lt;- workflow_set(\n    preproc = list(normalize = normalized_rec),\n    models = list( \n        ols = ols_spec,\n        ridge = ridge_spec,\n        lasso = lasso_spec,\n        enet = enet_spec))\n\n\nRun our models.\n\n\nCode\nctrl_grid &lt;- control_grid(\n    save_pred = TRUE,\n    save_workflow = TRUE)\n\nres_grid &lt;- all_workflows %&gt;% \n    workflow_map(\n        resamples = train_resamples, \n        grid = 20, \n        control = ctrl_grid,\n        metrics = metric_set(rmse, rsq, ccc),\n        verbose = TRUE)\n\n\nFit our best model (Elastic Net).\n\n\nCode\nres_ranks &lt;- res_grid %&gt;% \n    rank_results('rmse') %&gt;% \n    filter(.metric == 'rmse') %&gt;%\n    select(wflow_id, model, .config, rmse = mean, rank) %&gt;% \n    group_by(wflow_id) %&gt;% \n    slice_min(rank, with_ties = FALSE) %&gt;% \n    ungroup() %&gt;% \n    arrange(rank)\n\nwflow_id_best &lt;- res_ranks %&gt;% \n    slice_min(rank, with_ties = FALSE) %&gt;% \n    pull(wflow_id)\n\nwf_best &lt;- res_grid %&gt;% \n    extract_workflow_set_result(wflow_id_best) %&gt;% \n    select_best(metric = 'rmse')\n\nfit_best &lt;- res_grid %&gt;% \n    extract_workflow(wflow_id_best) %&gt;% \n    finalize_workflow(wf_best) %&gt;% \n    last_fit(split = split)\n\n\nLet’s look at how well our model performs\n\n\nCode\ntrain_fit &lt;- res_grid %&gt;% \n    extract_workflow(wflow_id_best) %&gt;%\n    finalize_workflow(wf_best) %&gt;% \n    fit(data = train_set)\n\ntest_augment &lt;- augment(train_fit, test_set)\n\n\n\n\nCode\nmape(test_augment, truth = sale_price, estimate = .pred) %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nmape\nstandard\n434.6188\n\n\n\n\n\nCode\nrmse(test_augment, truth = sale_price, estimate = .pred) %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n264690.7\n\n\n\n\n\nIt looks like our model underestimates higher sale price homes. This would make our model regressive, which is concerning.\n\n\nCode\nggplot(test_augment, aes(x = sale_price, y = sale_price - .pred)) +\n    geom_point() +\n    labs(title = \"Elastic Net Residuals and Sale Price in Cook County, IL\", \n        x = \"Sale Price\", \n        y = \"Residuals\")\n\n\n\n\n\n\n\n\n\nLet’s see what variables have the largest impact on sale_price.\nNotice that building square feet seems to have the largest impact on the sale price. This makes implicit sense because larger single family homes tend to sell for more. We can also see that certain townships (ex: New Trier, Lake View, North Chicago) can have large impacts on the sale price of single family homes.\nAlthough our exploratory data analysis indicated that the number of years old a single family home was and how much land it has was associated with changes in sale prices within certain ranges it seems that the model was still able to pick up on some association.\nInterestingly, the number of beds that a single family home has was only the fifth strongest non-township predictor within this model. My guess is that this is because there is some multicolinearity between it and building square feet and number of full baths (two of our strongest non-township predictors). Elastic net takes some characteristics from ridge regression which means that it may shrink coefficients for parameters that exibit multicollinearity. In the future, we should take some caution to address concerns that may stem out of the fact that some of our parameters may exhibit multicollinearity.\n\n\nCode\nfit_best %&gt;%\n    extract_fit_parsnip() %&gt;%\n    tidy() %&gt;% \n    arrange(desc(abs(estimate))) %&gt;%\n    select(-penalty) %&gt;%\n    knitr::kable()\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n411430.1509\n\n\nchar_bldg_sf\n173102.1930\n\n\ntownship_code_X23\n122590.9790\n\n\ntownship_code_X73\n100464.1254\n\n\ntownship_code_X74\n98948.7028\n\n\nchar_fbath\n57515.9458\n\n\ntownship_code_X71\n44273.8193\n\n\ntownship_code_X77\n40171.8266\n\n\ntownship_code_X25\n37585.7469\n\n\ntownship_code_X17\n37127.8833\n\n\nyears_old\n-36310.3012\n\n\ntownship_code_X32\n-29412.3966\n\n\ntownship_code_X37\n-26423.4514\n\n\nchar_land_sf\n25928.7813\n\n\ntownship_code_X12\n-24590.2254\n\n\nchar_beds\n-23844.3942\n\n\ntownship_code_X27\n23571.0122\n\n\ntownship_code_X21\n22396.3105\n\n\ntownship_code_X22\n18702.2171\n\n\ntownship_code_X24\n18433.0435\n\n\ntownship_code_X33\n17375.9446\n\n\ntownship_code_X13\n-15277.9551\n\n\nchar_hbath\n13864.3441\n\n\ntownship_code_X28\n-13663.1957\n\n\ntownship_code_X70\n-11151.1800\n\n\ntownship_code_X18\n-10018.7998\n\n\ntownship_code_X16\n9804.5747\n\n\ntownship_code_X75\n9622.6161\n\n\ntownship_code_X26\n9527.2867\n\n\ntownship_code_X38\n8921.9784\n\n\ntownship_code_X39\n-7649.2568\n\n\ntownship_code_X76\n7577.2306\n\n\ntownship_code_X30\n-7055.2081\n\n\ntownship_code_X34\n6767.3835\n\n\ntownship_code_X72\n-6149.2097\n\n\ntownship_code_X19\n-5829.4375\n\n\ntownship_code_X14\n-5619.0157\n\n\ntownship_code_X31\n5335.3295\n\n\ntownship_code_X20\n5057.9514\n\n\nchar_rooms\n-3085.1155\n\n\ntownship_code_X29\n-2818.9065\n\n\ntownship_code_X11\n2720.7418\n\n\ntownship_code_X35\n-464.7437\n\n\ntownship_code_X36\n-291.2669\n\n\ntownship_code_X15\n0.0000"
  },
  {
    "objectID": "posts/cook_part_1/index.html#conduct-an-exploratory-data-analysis",
    "href": "posts/cook_part_1/index.html#conduct-an-exploratory-data-analysis",
    "title": "Cook County Property Assessment - Part 1",
    "section": "",
    "text": "First let’s load our data and make some joins to sales data\n\n\nCode\nlibrary(tidyverse)\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"../data/cook.sqlite\")\n\nsfh_sales &lt;- tbl(con, 'sales') %&gt;%\n    collect() %&gt;%\n    filter(class %in% c(202, 203, 204, 205, 206, 207, 208, 209, 210, 234, 278)) %&gt;%\n    mutate(sale_date = as_datetime(sale_date)) %&gt;% \n    mutate(township_code = as.character(township_code)) %&gt;%\n    distinct(doc_no, .keep_all = TRUE)\n\ntownship_codes &lt;- read_csv(\"../data/township_codes.csv\") %&gt;% \n    mutate(across(where(is.numeric), as.character))\n\nsfh_characteristics &lt;- tbl(con, 'characteristics') %&gt;%\n    collect() %&gt;%\n    distinct(pin, .keep_all = T) %&gt;%\n    select(-c(class, township_code)) %&gt;%\n    right_join(sfh_sales, by = join_by(pin, year == year)) %&gt;%\n    right_join(township_codes)\n\nsfh_assessments &lt;- tbl(con, 'assessments') %&gt;%\n    collect() %&gt;%\n    mutate(township_code = as.character(township_code)) %&gt;%\n    distinct(pin, .keep_all = T) %&gt;%\n    select(-c(class, township_code)) %&gt;%\n    right_join(sfh_sales, by = join_by(pin, tax_year == year))\n\n\n\n\nThe distributions of average sale price for single family homes by township lines up with most people’s preconceptions of Cook County. We can see that average sale prices are highest in townships in northern Cook County in Chicago and the more wealthy northern suburbs. Within these very same townships, we can see that single family homes both tend to be larger and tend to cost more per square foot. Lastly, we can see that the oldest households tend be within the city of Chicago, while the mean age of houses within Cook County seems to lower, the farther you get from the city of Chicago.\n\nSale PriceBuilding SqFtPrice Per SqFtYears old\n\n\n\n\nCode\nlibrary(sf)\nlibrary(leaflet)\nlibrary(scales)\n\ntownships &lt;- read_sf(\"https://gis.cookcountyil.gov/traditional/rest/services/politicalBoundary/MapServer/3/query?outFields=*&where=1%3D1&f=geojson\") %&gt;%\n    mutate(ORIGOID = as.character(ORIGOID)) %&gt;%\n    right_join(township_codes, by = join_by(ORIGOID == origoid))\n\nsfh_mean_by_township &lt;- sfh_characteristics %&gt;%\n    group_by(township_code) %&gt;%\n    reframe(sale_price_mean = mean(sale_price, na.rm = T),\n        bldg_sf_mean = mean(char_bldg_sf, na.rm = T),\n        sale_price_per_sf = mean(sale_price/char_bldg_sf, na.rm = T),\n        years_old_mean = mean(2023 - char_yrblt, na.rm = T)) %&gt;%\n    right_join(townships) %&gt;%\n    st_as_sf()\n    \nqpal &lt;- colorQuantile(\"Greens\", sfh_mean_by_township$sale_price_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(sale_price_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Average Sale: %s&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_currency()(sfh_mean_by_township$sale_price_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\"))   %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$sale_price_mean,\n            opacity = 0.7,\n            title = \"Mean Sale Price of &lt;/br&gt;Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Oranges\", sfh_mean_by_township$bldg_sf_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(bldg_sf_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;Mean Building sqft: %s&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_comma(1)(sfh_mean_by_township$bldg_sf_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\"))   %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$bldg_sf_mean,\n            opacity = 0.7,\n            title = \"Mean Building Square Feet&lt;/br&gt; of Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_comma(1)(cuts[-n]), \" - \", label_comma(1)(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Blues\", sfh_mean_by_township$sale_price_per_sf, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(sale_price_per_sf),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;%s per sqft&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_currency()(sfh_mean_by_township$sale_price_per_sf)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")) %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$sale_price_per_sf,\n            opacity = 0.7,\n            title = \"Dollars per Square Foot of &lt;/br&gt;Single Family Homes in &lt;/br&gt;Cook County by Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_currency()(cuts[-n]), \" - \", label_currency()(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Reds\", sfh_mean_by_township$years_old_mean, n = 5)\n\nsfh_mean_by_township %&gt;%\n    leaflet() %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ qpal(years_old_mean),\n            fillOpacity = 0.7,\n            color = \"Black\",\n            weight = 0.5,\n            opacity = 0.5,\n            highlightOptions = highlightOptions(\n                weight = 2,\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = sprintf(\n                \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br&gt;%s years old&lt;br/&gt;\",\n                sfh_mean_by_township$NAME,\n                label_number(1)(sfh_mean_by_township$years_old_mean)) %&gt;% \n                    lapply(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")) %&gt;%\n        addLegend(\n            pal = qpal,\n            values = sfh_mean_by_township$years_old_mean,\n            opacity = 0.7,\n            title = \"Mean Years Old of &lt;/br&gt;Single Family Homes &lt;/br&gt;in Cook County by &lt;/br&gt;Township\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = function(type, cuts, p) {\n                n = length(cuts)\n                p = paste0(round(p * 100), '%')\n                cuts = paste0(label_number(1)(cuts[-n]), \" - \", label_number(1)(cuts[-1]))\n                paste0(\n                    '&lt;span title=\"', p[-n], \" - \", p[-1], '\"&gt;', cuts,\n                    '&lt;/span&gt;'\n                )\n            })\n\n\n\n\n\n\n\n\n\n\n\n\nIt seems that single family homes built in the last 30 - 40 years tend to be more expensive, but beyond that sale prices do not seem to be associated with sale prices. As expected, higher square footage single family homes tend to sell for more, but there is still a large amount variability in sale prices. Larger land square footage single family homes seem to sell for more up until about 15,000 square feet where additional land does not seem to be associated with much greater sale prices. More beds, rooms, and bathrooms seem to all be associated with greater sale prices. However, there seems to be some odd outliers with 0 bedrooms or 2 rooms that are selling for more than would be expected. This may be something we would want to investigate later. These could be simply a result of faulty assessor data.\n\nYear builtBuilding SqFtLand SqFtBedsRoomsBathrooms\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    ggplot(aes(x = char_yrblt, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Sale Price and Year Built in Cook County, IL\", \n            x = \"Year Built\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    ggplot(aes(x = char_bldg_sf, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Building Square Footage and Sale Price \\nin Cook County, IL\", \n            x = \"Building Square Footage\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    filter(sale_price &lt;= 10^7) %&gt;%\n    filter(char_land_sf &lt;= 10^5) %&gt;%\n    ggplot(aes(x = char_land_sf, y = sale_price)) +\n        geom_point(size = 0.1) +\n        geom_smooth(method = \"gam\", color = \"springgreen4\") +\n        scale_y_continuous(labels = label_currency()) + \n        labs(title = \"Single Family Home Building Square Footage and Sale Price \\nin Cook County, IL\", \n            x = \"Land Square Footage\", \n            y = \"Sale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_beds, y = sale_price, fill = factor(char_beds))) +\n        scale_x_continuous(n.breaks = 9) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Number of Bedrooms and Sale Price \\nin Cook County, IL\", \n            x = \"Number of Bedrooms\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_rooms, y = sale_price, fill = factor(char_rooms))) +\n        scale_x_continuous(n.breaks = 20) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Number of Rooms and Sale Price \\nin Cook County, IL\", \n            x = \"Number of Rooms\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsfh_characteristics %&gt;%\n    ggplot() +\n        geom_boxplot(aes(x = char_fbath + char_hbath * 0.5, y = sale_price, fill = factor(char_fbath + char_hbath * 0.5))) +\n        scale_x_continuous(n.breaks = 20) +\n        scale_y_continuous(labels = label_currency()) +\n        labs(title = \"Single Family Home Total Number of Baths and Sale Price \\nin Cook County, IL\", \n            x = \"Total Number of Baths\", \n            y = \"Sale Price\") + \n        theme(legend.position=\"none\")"
  },
  {
    "objectID": "posts/cook_part_1/index.html#use-cmfproperty-to-conduct-a-sales-ratio-study-across-the-relevant-time-period",
    "href": "posts/cook_part_1/index.html#use-cmfproperty-to-conduct-a-sales-ratio-study-across-the-relevant-time-period",
    "title": "Cook County Property Assessment - Part 1",
    "section": "",
    "text": "Let’s get our data into a format that the cmfproperty package can use.\n\n\nCode\nlibrary(cmfproperty)\n\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"../data/cook.sqlite\")\n\nsfh_sales_cmf &lt;- sfh_sales %&gt;% \n    select(pin, year, sale_price, doc_no) %&gt;%\n    distinct(doc_no, .keep_all = TRUE) %&gt;%\n    select(-doc_no) %&gt;%\n    filter(as.numeric(sale_price) &gt; 2500)\n\nassessments_cmf &lt;- tbl(con, \"assessments\") %&gt;%\n    collect() %&gt;%\n    select(pin, tax_year, certified_tot)\n\nsale_assess_cmf &lt;- sfh_sales_cmf %&gt;% \n    left_join(assessments_cmf, by = join_by(pin, year == tax_year)) %&gt;% \n    rename(PIN = pin, SALE_YEAR = year, SALE_PRICE = sale_price, ASSESSED_VALUE = certified_tot) %&gt;%\n    mutate(ASSESSED_VALUE = 10 * ASSESSED_VALUE)\n\nratios &lt;- reformat_data(sale_assess_cmf,\n    sale_col = \"SALE_PRICE\",\n    assessment_col = \"ASSESSED_VALUE\",\n    sale_year_col = \"SALE_YEAR\")\n\nstats &lt;- calc_iaao_stats(ratios)\n\n\nOverall, we can see that at every sale price decile, single family homes are underassessed compared to their true sale price. However, the degree to which single family homes are underassessed is not equal. Regardless of efforts of the county, it is clear that in 2023 (for the months of Jan-Sep), houses within the lowest deciles tend to be assessed at higher ratios to their true sales price. The overall picture from 2021 to Sep 2023 is more enocouraging, but nevertheless the lowest decile tends to be assessed at higher rates than all other deciles and the 2nd to 5th lowest deciles seem to be asssed at lower rates than the higher deciles.\n\nBinned ScatterPercent AssessedCoefficient of DispersionPrice-Related DifferentialCoefficient of Price-Related Bias\n\n\n\n\nCode\nbinned &lt;- binned_scatter(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nknitr::asis_output(htmltools::htmlPreserve(binned[[1]]))\n\nbinned[[2]]\n\n\n\n\n\n\n\n\n\nIn 2023, the most expensive homes (the top decile) were assessed at 76.2% of their value and the least expensive homes (the bottom decile) were assessed at 93.1%. In other words, the least expensive homes were assessed at 1.22 times the rate applied to the most expensive homes. Across our sample from 2021 to 2023, the most expensive homes were assessed at 77.4% of their value and the least expensive homes were assessed at 84.6%, which is 1.09 times the rate applied to the most expensive homes.\n\n\n\n\n\n\nCode\npct_over &lt;- pct_over_under(ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, IL\")\n\nknitr::asis_output(htmltools::htmlPreserve(pct_over[[1]]))\n\npct_over[[2]]\n\n\n\n\n\n\n\n\n\nIn Cook County, IL, 58% of the lowest value homes are overassessed and 52% of the highest value homes are overassessed.\n\n\n\n\n\n\nCode\niaao_rslt &lt;- iaao_graphs(stats,\n    ratios,\n    min_reporting_yr = 2021,\n    max_reporting_yr = 2023,\n    jurisdiction_name = \"Cook County, Illinois\")\n\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[1]]))\n\niaao_rslt[[2]]\n\n\n\n\n\n\n\n\n\nFor 2023, the COD in Cook County, Illinois was 19.6 which did not meet the IAAO standard for uniformity.\n\n\n\n\n\n\nCode\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[3]]))\n\niaao_rslt[[4]]\n\n\n\n\n\n\n\n\n\nIn 2023, the PRD in  Cook County, Illinois, was 1.074 which does not meet  the IAAO standard for vertical equity.\n\n\n\n\n\n\nCode\nknitr::asis_output(htmltools::htmlPreserve(iaao_rslt[[5]]))\n\niaao_rslt[[6]]\n\n\n\n\n\n\n\n\n\nIn 2023, the PRB in Cook County, Illinois was 0.004 which indicates that sales ratios increase by 0.4% when home values double. This meets the IAAO standard."
  },
  {
    "objectID": "posts/cook_part_1/index.html#explore-trends-and-relationships-with-property-sales-using-simple-regressions",
    "href": "posts/cook_part_1/index.html#explore-trends-and-relationships-with-property-sales-using-simple-regressions",
    "title": "Cook County Property Assessment - Part 1",
    "section": "",
    "text": "Let’s evaluate a couple different linear models (linear models were chosen simply because of the lower computing power necessary to train them). First, we’ll split our data.\n\n\nCode\nlibrary(tidymodels) \ntidymodels_prefer()\n\nset.seed(1)\nsplit &lt;- initial_split(sfh_characteristics)\ntrain_set &lt;- training(split)\ntest_set &lt;- testing(split)\n\nset.seed(2)\ntrain_resamples &lt;- bootstraps(train_set)\n\n\nWe’ll preprocess our data.\n\n\nCode\nbasic_rec &lt;- recipe(sale_price ~ char_yrblt + char_bldg_sf + char_land_sf + char_beds + char_rooms + char_fbath + char_hbath + township_code, data = sfh_characteristics) %&gt;% \n    step_mutate(years_old = 2023 - char_yrblt, role = \"predictor\") %&gt;%\n    remove_role(char_yrblt, old_role = \"predictor\") %&gt;%\n    step_string2factor(township_code) %&gt;% \n    step_naomit(all_predictors()) %&gt;% \n    step_novel(all_nominal_predictors()) %&gt;%\n    step_dummy(all_nominal_predictors()) %&gt;%\n    step_zv(all_predictors())\n\nnormalized_rec &lt;- basic_rec %&gt;% \n   step_normalize(all_predictors())\n\n\nSave the specifications of our models.\n\n\nCode\nols_spec &lt;- linear_reg() %&gt;% \n    set_engine(\"lm\") %&gt;%\n    set_mode(\"regression\")\n\nridge_spec &lt;- linear_reg(penalty = tune(), mixture = 0) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\nlasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\nenet_spec &lt;- linear_reg(penalty = tune(), mixture = tune()) %&gt;% \n    set_engine(\"glmnet\") %&gt;%\n    set_mode(\"regression\")\n\n\nCreate our workflows.\n\n\nCode\nall_workflows &lt;- workflow_set(\n    preproc = list(normalize = normalized_rec),\n    models = list( \n        ols = ols_spec,\n        ridge = ridge_spec,\n        lasso = lasso_spec,\n        enet = enet_spec))\n\n\nRun our models.\n\n\nCode\nctrl_grid &lt;- control_grid(\n    save_pred = TRUE,\n    save_workflow = TRUE)\n\nres_grid &lt;- all_workflows %&gt;% \n    workflow_map(\n        resamples = train_resamples, \n        grid = 20, \n        control = ctrl_grid,\n        metrics = metric_set(rmse, rsq, ccc),\n        verbose = TRUE)\n\n\nFit our best model (Elastic Net).\n\n\nCode\nres_ranks &lt;- res_grid %&gt;% \n    rank_results('rmse') %&gt;% \n    filter(.metric == 'rmse') %&gt;%\n    select(wflow_id, model, .config, rmse = mean, rank) %&gt;% \n    group_by(wflow_id) %&gt;% \n    slice_min(rank, with_ties = FALSE) %&gt;% \n    ungroup() %&gt;% \n    arrange(rank)\n\nwflow_id_best &lt;- res_ranks %&gt;% \n    slice_min(rank, with_ties = FALSE) %&gt;% \n    pull(wflow_id)\n\nwf_best &lt;- res_grid %&gt;% \n    extract_workflow_set_result(wflow_id_best) %&gt;% \n    select_best(metric = 'rmse')\n\nfit_best &lt;- res_grid %&gt;% \n    extract_workflow(wflow_id_best) %&gt;% \n    finalize_workflow(wf_best) %&gt;% \n    last_fit(split = split)\n\n\nLet’s look at how well our model performs\n\n\nCode\ntrain_fit &lt;- res_grid %&gt;% \n    extract_workflow(wflow_id_best) %&gt;%\n    finalize_workflow(wf_best) %&gt;% \n    fit(data = train_set)\n\ntest_augment &lt;- augment(train_fit, test_set)\n\n\n\n\nCode\nmape(test_augment, truth = sale_price, estimate = .pred) %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nmape\nstandard\n434.6188\n\n\n\n\n\nCode\nrmse(test_augment, truth = sale_price, estimate = .pred) %&gt;% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n264690.7\n\n\n\n\n\nIt looks like our model underestimates higher sale price homes. This would make our model regressive, which is concerning.\n\n\nCode\nggplot(test_augment, aes(x = sale_price, y = sale_price - .pred)) +\n    geom_point() +\n    labs(title = \"Elastic Net Residuals and Sale Price in Cook County, IL\", \n        x = \"Sale Price\", \n        y = \"Residuals\")\n\n\n\n\n\n\n\n\n\nLet’s see what variables have the largest impact on sale_price.\nNotice that building square feet seems to have the largest impact on the sale price. This makes implicit sense because larger single family homes tend to sell for more. We can also see that certain townships (ex: New Trier, Lake View, North Chicago) can have large impacts on the sale price of single family homes.\nAlthough our exploratory data analysis indicated that the number of years old a single family home was and how much land it has was associated with changes in sale prices within certain ranges it seems that the model was still able to pick up on some association.\nInterestingly, the number of beds that a single family home has was only the fifth strongest non-township predictor within this model. My guess is that this is because there is some multicolinearity between it and building square feet and number of full baths (two of our strongest non-township predictors). Elastic net takes some characteristics from ridge regression which means that it may shrink coefficients for parameters that exibit multicollinearity. In the future, we should take some caution to address concerns that may stem out of the fact that some of our parameters may exhibit multicollinearity.\n\n\nCode\nfit_best %&gt;%\n    extract_fit_parsnip() %&gt;%\n    tidy() %&gt;% \n    arrange(desc(abs(estimate))) %&gt;%\n    select(-penalty) %&gt;%\n    knitr::kable()\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n411430.1509\n\n\nchar_bldg_sf\n173102.1930\n\n\ntownship_code_X23\n122590.9790\n\n\ntownship_code_X73\n100464.1254\n\n\ntownship_code_X74\n98948.7028\n\n\nchar_fbath\n57515.9458\n\n\ntownship_code_X71\n44273.8193\n\n\ntownship_code_X77\n40171.8266\n\n\ntownship_code_X25\n37585.7469\n\n\ntownship_code_X17\n37127.8833\n\n\nyears_old\n-36310.3012\n\n\ntownship_code_X32\n-29412.3966\n\n\ntownship_code_X37\n-26423.4514\n\n\nchar_land_sf\n25928.7813\n\n\ntownship_code_X12\n-24590.2254\n\n\nchar_beds\n-23844.3942\n\n\ntownship_code_X27\n23571.0122\n\n\ntownship_code_X21\n22396.3105\n\n\ntownship_code_X22\n18702.2171\n\n\ntownship_code_X24\n18433.0435\n\n\ntownship_code_X33\n17375.9446\n\n\ntownship_code_X13\n-15277.9551\n\n\nchar_hbath\n13864.3441\n\n\ntownship_code_X28\n-13663.1957\n\n\ntownship_code_X70\n-11151.1800\n\n\ntownship_code_X18\n-10018.7998\n\n\ntownship_code_X16\n9804.5747\n\n\ntownship_code_X75\n9622.6161\n\n\ntownship_code_X26\n9527.2867\n\n\ntownship_code_X38\n8921.9784\n\n\ntownship_code_X39\n-7649.2568\n\n\ntownship_code_X76\n7577.2306\n\n\ntownship_code_X30\n-7055.2081\n\n\ntownship_code_X34\n6767.3835\n\n\ntownship_code_X72\n-6149.2097\n\n\ntownship_code_X19\n-5829.4375\n\n\ntownship_code_X14\n-5619.0157\n\n\ntownship_code_X31\n5335.3295\n\n\ntownship_code_X20\n5057.9514\n\n\nchar_rooms\n-3085.1155\n\n\ntownship_code_X29\n-2818.9065\n\n\ntownship_code_X11\n2720.7418\n\n\ntownship_code_X35\n-464.7437\n\n\ntownship_code_X36\n-291.2669\n\n\ntownship_code_X15\n0.0000"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html",
    "href": "posts/coding_warmup_4/index.html",
    "title": "Coding Warmup 4",
    "section": "",
    "text": "We are going to use a toy dataset called bivariate. There is a training, testing, and validation dataset provided.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ndata(bivariate)\n\nggplot(bivariate_train, aes(x = A, y = B, color = Class)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nUse logistic_reg and glm to make a classification model of Class ~ A * B. Then use tidy and glance to see some summary information on our model. Anything stand out to you?\n\n\nCode\nlog_model &lt;- logistic_reg() %&gt;%\n    set_engine('glm') %&gt;%\n    set_mode('classification') %&gt;%\n    fit(Class ~ A * B, data = bivariate_train)\n\nlog_model %&gt;% tidy()\n\n\n# A tibble: 4 × 5\n  term          estimate  std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  0.115     0.404          0.284 7.76e- 1\n2 A            0.00433   0.000434       9.97  2.01e-23\n3 B           -0.0553    0.00633       -8.74  2.32e-18\n4 A:B         -0.0000101 0.00000222    -4.56  5.04e- 6\n\n\nCode\nlog_model %&gt;% glance()\n\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         1329.    1008  -549. 1106. 1126.    1098.        1005  1009"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-a",
    "href": "posts/coding_warmup_4/index.html#part-a",
    "title": "Coding Warmup 4",
    "section": "",
    "text": "We are going to use a toy dataset called bivariate. There is a training, testing, and validation dataset provided.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ndata(bivariate)\n\nggplot(bivariate_train, aes(x = A, y = B, color = Class)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nUse logistic_reg and glm to make a classification model of Class ~ A * B. Then use tidy and glance to see some summary information on our model. Anything stand out to you?\n\n\nCode\nlog_model &lt;- logistic_reg() %&gt;%\n    set_engine('glm') %&gt;%\n    set_mode('classification') %&gt;%\n    fit(Class ~ A * B, data = bivariate_train)\n\nlog_model %&gt;% tidy()\n\n\n# A tibble: 4 × 5\n  term          estimate  std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  0.115     0.404          0.284 7.76e- 1\n2 A            0.00433   0.000434       9.97  2.01e-23\n3 B           -0.0553    0.00633       -8.74  2.32e-18\n4 A:B         -0.0000101 0.00000222    -4.56  5.04e- 6\n\n\nCode\nlog_model %&gt;% glance()\n\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         1329.    1008  -549. 1106. 1126.    1098.        1005  1009"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-b",
    "href": "posts/coding_warmup_4/index.html#part-b",
    "title": "Coding Warmup 4",
    "section": "Part B",
    "text": "Part B\nUse augment to get predictions. Look at the predictions.\n\n\nCode\nlog_model %&gt;% augment(bivariate_test)\n\n\n# A tibble: 710 × 6\n   .pred_class .pred_One .pred_Two     A     B Class\n   &lt;fct&gt;           &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n 1 One           0.730      0.270   742.  68.8 One  \n 2 Two           0.491      0.509   709.  50.4 Two  \n 3 One           0.805      0.195  1006.  89.9 One  \n 4 Two           0.431      0.569  1983. 112.  Two  \n 5 Two           0.169      0.831  1698.  81.0 Two  \n 6 One           0.900      0.0996  948.  98.9 One  \n 7 One           0.521      0.479   751.  54.8 One  \n 8 Two           0.347      0.653  1254.  72.2 Two  \n 9 Two           0.00568    0.994  4243. 136.  One  \n10 One           0.910      0.0898  713.  88.2 One  \n# ℹ 700 more rows"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-c",
    "href": "posts/coding_warmup_4/index.html#part-c",
    "title": "Coding Warmup 4",
    "section": "Part C",
    "text": "Part C\nVisually inspect the predictions using the code below\n\n\nCode\npreds &lt;- expand.grid(\n    A = seq(min(bivariate_train$A), max(bivariate_train$A), length.out = 100),\n    B = seq(min(bivariate_train$B), max(bivariate_train$B), length.out = 100)) %&gt;%\n    augment(log_model, .)\n\nggplot(preds, aes(x = A, y = B)) +\n    geom_contour(aes(z = .pred_One), breaks = .5, col = \"black\") + \n    geom_point(data = bivariate_val, aes(col = Class), alpha = 0.3)"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-d",
    "href": "posts/coding_warmup_4/index.html#part-d",
    "title": "Coding Warmup 4",
    "section": "Part D",
    "text": "Part D\nEvaluate your model using the following functions (which dataset(s) should you use to do this train, test, or validation). See if you can provide a basic interpretation of the measures.\n\nroc_auc\naccuracy\nroc_curve and autoplot\nf_meas\n\n\n\nCode\nval_preds &lt;- log_model %&gt;% \n    augment(bivariate_val)\n\nmetrics &lt;- list(\n    val_preds %&gt;%\n        roc_auc(Class, .pred_One),\n    val_preds %&gt;%\n        accuracy(Class, .pred_class),\n    val_preds %&gt;%\n        f_meas(Class, .pred_class))\n\nmetrics %&gt;% bind_rows()\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc  binary         0.790\n2 accuracy binary         0.76 \n3 f_meas   binary         0.827\n\n\n\n\nCode\nval_preds %&gt;% \n    roc_curve(Class, .pred_One) %&gt;%\n    autoplot()"
  },
  {
    "objectID": "posts/coding_warmup_4/index.html#part-e",
    "href": "posts/coding_warmup_4/index.html#part-e",
    "title": "Coding Warmup 4",
    "section": "Part E",
    "text": "Part E\nRecall Table 8.4 from the textbook. If necessary, class one can be positive and class two can be negative. Using the output from conf_mat, visually verify you know how to calculate the following:\n\nTrue Positive Rate (TPR), Sensitivity, or Recall\nTrue Negative Rate (TNR) or Specificity\nFalse Positive Rate, Type I error\nFalse Negative Rate (FNR), Type II error\nPositive Predictive Value (PPV) or Precision\n\n\n\nCode\nval_preds %&gt;% \n    conf_mat(truth = Class, estimate = .pred_class)\n\n\n          Truth\nPrediction One Two\n       One 172  42\n       Two  30  56"
  },
  {
    "objectID": "posts/coding_warmup_2/index.html",
    "href": "posts/coding_warmup_2/index.html",
    "title": "Coding Warmup 2",
    "section": "",
    "text": "Create an RMarkdown file to use for this assignment. Use html as the output and change at least one option in the yaml. Complete the rest of the assignment using markdown and chunks to create readable code and output."
  },
  {
    "objectID": "posts/coding_warmup_2/index.html#part-1",
    "href": "posts/coding_warmup_2/index.html#part-1",
    "title": "Coding Warmup 2",
    "section": "",
    "text": "Create an RMarkdown file to use for this assignment. Use html as the output and change at least one option in the yaml. Complete the rest of the assignment using markdown and chunks to create readable code and output."
  },
  {
    "objectID": "posts/coding_warmup_2/index.html#part-2",
    "href": "posts/coding_warmup_2/index.html#part-2",
    "title": "Coding Warmup 2",
    "section": "Part 2",
    "text": "Part 2\nUsing censusreporter.org, pick an American Community Survey variable and a geographic area and division (e.g. nationwide and states, statewide and county, county and tracts).\nUsing tigris, tidycensus, and leaflet (encouraged, or your favorite R package for maps), map the variable over your chosen geographic divisions. Select an appropriate pallete, and consider adding popup labels. Write a few sentences describing your map in Markdown\n\n\nCode\nlibrary(leaflet)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tidycensus)\n\nacs_il20 &lt;- get_acs(geography = \"tract\", \n    variables = c(\n        medincome = \"B19013_001\",\n        totalpop = \"B02001_001\",\n        white_nh = \"B03002_003\",\n        black_nh = \"B03002_004\",\n        aian_nh = \"B03002_005\",\n        asian_nh = \"B03002_005\",\n        hispanic = \"B03002_012\"),\n    state = \"IL\", \n    year = 2020) %&gt;%\n    pivot_wider(names_from = variable, values_from = c(estimate, moe)) %&gt;%\n    select(GEOID, starts_with(\"estimate\"))\n\ntracts_il20 &lt;- tigris::tracts(state = \"IL\", year = 2020) %&gt;% \n    st_transform(4326)\n\nacs_il20 &lt;- tracts_il20 %&gt;%\n    left_join(acs_il20)\n\nchi20 &lt;- tigris::county_subdivisions(state = \"IL\", county = \"Cook\", year = 2020) %&gt;%\n    filter(NAME == \"Chicago\") %&gt;% \n    st_transform(4326)\n\nacs_chi20 &lt;- acs_il20 %&gt;%\n    st_intersection(chi20)\n\n\n\n\nCode\npal &lt;- colorQuantile(\"Greens\", \n    domain = acs_chi20$estimate_medincome,\n    n = 5)\n\nleaflet() %&gt;%\n    addProviderTiles(providers$CartoDB.Positron) %&gt;% \n    addPolygons(\n        data = acs_chi20,\n        fillColor = ~ pal(estimate_medincome),\n        fillOpacity = 0.7,\n        color = \"Black\",\n        weight = 0.5,\n        opacity = 0.5,\n        highlightOptions = highlightOptions(\n            weight = 2,\n            color = \"Black\",\n            fillOpacity = 1,\n            bringToFront = TRUE),\n        label = sprintf(\n            \"&lt;strong&gt;Tract %s&lt;/strong&gt;&lt;br&gt;Median Income: %s&lt;br/&gt;\",\n            acs_chi20$GEOID,\n            scales::dollar(acs_chi20$estimate_medincome)) %&gt;% \n                lapply(htmltools::HTML),\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"12px\",\n            direction = \"auto\")) %&gt;%\n    addLegend(\n        pal = pal,\n        values = acs_chi20$estimate_medincome,\n        opacity = 0.7,\n        title = NULL,\n        position = \"bottomright\",\n        na.label = \"Insufficient Data\")"
  },
  {
    "objectID": "posts/coding_warmup_2/index.html#part-3",
    "href": "posts/coding_warmup_2/index.html#part-3",
    "title": "Coding Warmup 2",
    "section": "Part 3",
    "text": "Part 3\nConsider expanding the divvy example from class with the following:\n\napproximate trip distance from start/end location\n\nshow some summary stats by hour or day of week or community area or “rideable” type\n\nconstruct a regression with some combination of the above\n\n\n\nCode\ntemp &lt;- tempfile()\ndownload.file(\"https://divvy-tripdata.s3.amazonaws.com/202307-divvy-tripdata.zip\", temp)\ndivvy202307 &lt;- read_csv(unz(temp, \"202307-divvy-tripdata.csv\"))\nunlink(temp)\n\n\n\n\nCode\nlibrary(sfheaders)\nlibrary(units)\n\ndivvy202307_sf &lt;- divvy202307 %&gt;%\n    filter(!is.na(end_lat)) %&gt;%\n    filter(start_lng != end_lng & start_lat != end_lat) %&gt;%\n    pivot_longer(c(start_lat, start_lng, end_lat, end_lng), names_to = c(\"Position\", \".value\"), names_pattern = \"(.*)_(.*)\") %&gt;%\n    sf_linestring(linestring_id = \"ride_id\", x = \"lng\", y = \"lat\", keep = TRUE) %&gt;%\n    st_set_crs(4326) %&gt;%\n    st_transform(26971) %&gt;%\n    mutate(edistance = set_units(st_length(geometry), mi)) %&gt;%\n    mutate(start_time = force_tz(started_at, tzone = \"America/Chicago\")) %&gt;%\n    mutate(end_time = force_tz(ended_at, tzone = \"America/Chicago\")) %&gt;%\n    mutate(duration_time = end_time - start_time)\n\n\n\n\nCode\ndivvy202307_sf %&gt;%\n    st_drop_geometry() %&gt;%\n    ggplot() + \n        geom_density(aes(x = edistance, fill = rideable_type, y = after_stat(count)), alpha = 0.5) + \n        labs(x = 'Euclidian Trip Distance',\n            y = 'Rides',\n            title = 'Divvy Euclidian Distances - July 2023') +\n        scale_fill_discrete(name = \"Ride Type\",\n            labels = c(\"Classic\", \"Docked\", \"Electric\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndivvy202307_sf %&gt;%\n    st_drop_geometry() %&gt;%\n    ggplot() + \n        geom_density(aes(x = duration_time, fill = rideable_type, y = after_stat(count)), alpha = 0.5) + \n        xlim(0, 7200) +\n        labs(x = 'Trip Duration [sec]',\n            y = 'Rides',\n            title = 'Divvy Trip Duration - July 2023') +\n        scale_fill_discrete(name = \"Ride Type\",\n            labels = c(\"Classic\", \"Docked\", \"Electric\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndivvy202307_sf %&gt;%\n    st_drop_geometry() %&gt;%\n    mutate(day = wday(started_at, label = TRUE)) %&gt;%\n    ggplot() +\n        geom_bar(aes(day, fill = rideable_type)) +\n        labs(x = 'Day of the Week',\n            y = 'Rides',\n            title = 'Divvy Trips by Day of the Week - July 2023') +\n        scale_fill_discrete(name = \"Ride Type\",\n            labels = c(\"Classic\", \"Docked\", \"Electric\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndivvy202307_sf %&gt;%\n    st_drop_geometry() %&gt;%\n    mutate(day = wday(started_at, label = TRUE)) %&gt;%\n    mutate(hour = hour(started_at)) %&gt;%\n    ggplot() +\n        geom_bar(aes(hour, fill = rideable_type)) +\n        labs(x = 'Hour',\n            y = 'Rides',\n            title = 'Divvy Trips by Hour for Each Day of the Week - July 2023') +\n        scale_fill_discrete(name = \"Ride Type\",\n            labels = c(\"Classic\", \"Docked\", \"Electric\")) +\n        facet_grid(rows = vars(day))"
  },
  {
    "objectID": "posts/coding_warmup_2/index.html#part-4",
    "href": "posts/coding_warmup_2/index.html#part-4",
    "title": "Coding Warmup 2",
    "section": "Part 4",
    "text": "Part 4\nGrab another variable for the same geographic area and divisions with the intent of exploring correlation between this variable and the one selected in the part 2. Replicate some of the analysis from Tidy Modeling Sec 3.1.\n\n\nCode\nacs_il20 %&gt;%\n    filter(str_starts(GEOID, \"17031\")) %&gt;%\n    mutate(white_nh_pct = estimate_white_nh / estimate_totalpop) %&gt;%\n    ggplot(aes(x = white_nh_pct, y = estimate_medincome)) +\n        geom_point(alpha=.2) +\n        geom_smooth(method = lm) +\n        theme_bw() +\n        scale_y_continuous(labels = scales::dollar_format()) +\n        scale_x_continuous(labels = scales::percent_format()) +\n        labs(x='Percent White Non-Hispanic', y='Median Income', title='Median Income and Percent White Non-Hispanic by Census Tract \\nin Cook County')\n\n\n\n\n\n\n\n\n\n\n\nCode\nlm_white_medincome &lt;- acs_il20 %&gt;%\n    filter(str_starts(GEOID, \"17031\")) %&gt;%\n    mutate(white_nh_pct = estimate_white_nh / estimate_totalpop) %&gt;%\n    lm(estimate_medincome ~ white_nh_pct, data = .)\n\nsummary(lm_white_medincome)\n\n\n\nCall:\nlm(formula = estimate_medincome ~ white_nh_pct, data = .)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-80818 -16432  -1898  12285 133946 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     36250       1164   31.15   &lt;2e-16 ***\nwhite_nh_pct    90189       2337   38.59   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25860 on 1321 degrees of freedom\n  (9 observations deleted due to missingness)\nMultiple R-squared:  0.5299,    Adjusted R-squared:  0.5295 \nF-statistic:  1489 on 1 and 1321 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\nplot(lm_white_medincome)"
  },
  {
    "objectID": "posts/final_project/index.html",
    "href": "posts/final_project/index.html",
    "title": "Final Project",
    "section": "",
    "text": "The following project is a replication attempt of the machine learning model described in Huynh et al. [1] predicting lead exposure from drinking water within the city of Chicago. Lead-contaminated drinking water at the block level was defined as a binary variable indicating whether the majority of tests within a block have at least 1 ppb lead concentration. According to their model, approximately 75% of blocks are estimated to have lead-contaminated drinking water. The greatest predictors of lead-contaminated drinking water were geographic areas, population at the block, and number of buildings.\nHuynh et al. (and by extension, I) used the following data sources:\n\n\nData Sources\n\n\n\n\n\n\n\n\n\nSource\nMeasure\nExtent\n\n\n\n\nCity of Chicago Department of Water Management Lead Test Data\nConsecutive lead tests (ppb)\nAnonymized to the block\n\n\nCensus\nBlock FIPS\nBlock\n\n\nPopulation (#)\nBlock\n\n\nRace/ethnicity (#)\n\nAIAN\nAsian\nBlack\nHispanic\nWhite\n\nBlock\n\n\nAmerican Community Survey\nBlock FIPS\nBlock\n\n\nBlock group FIPS\nBlock group\n\n\nPopulation (#)\nBlock group, tract\n\n\nRace/ethnicity (#)\n\nAIAN\nAsian\nBlack\nHispanic\nWhite\n\nBlock group, tract\n\n\nHousing units (#)\nBlock group\n\n\nMedian house value ($)\nBlock group\n\n\nUpper house value ($)\nBlock group\n\n\nLower house value ($)\nBlock group\n\n\nMedian homeowner costs ($)\nBlock group\n\n\nEducation (#)\n\nHigh school\nGED\n&lt;1 year of college\n&gt; 1 year of college\nAssociate’s degree\nBachelor’s degree\nMaster’s degree\nProfessional School\nDoctoral Degree\n\nBlock group\n\n\nPoverty (#)\nBlock group\n\n\nEnglish-only speakers (#)\nBlock group\n\n\nComputer access (#)\nBlock group\n\n\nInternet access (#)\nBlock group\n\n\nComplete plumbing facilities (#)\nBlock group\n\n\nVacant Housing (#)\nBlock group\n\n\nOwner-occupied (#)\nBlock group\n\n\nChildren under 5 (#)\nBlock group\n\n\nChildren under 10 (#)\nBlock group\n\n\nChildren under 18 (#)\nBlock group\n\n\nChicago Building Footprints\nMedian building age (years)\nBlock\n\n\nBuilding (#)\nBlock\n\n\nMax age (years)\nBlock\n\n\nMean age (years)\nBlock\n\n\nBuilt after 1986 (#)\nBlock\n\n\nChicago Health Atlas\nCommunity area\nCommunity area\n\n\nLead poisoning rate (%)\nCommunity area\n\n\nHistorical lead poisoning rate (%)\nCommunity area\n\n\nEconomic diversity index\nTract\n\n\nHardship index\nTract\n\n\nSocial vulnerability index\nTract\n\n\nMajor crime (#)\nTract\n\n\nEviction rate (%)\nTract\n\n\nFine particulate matter concentration (\\(\\mu\\text{g/m}^3\\))\nTract\n\n\nAccess to food (%)\nTract\n\n\nUninsured rate (%)\nTract\n\n\nPer capita income ($)\nTract\n\n\nCognitive difficulty (%)\nTract\n\n\nDisability (%)\nTract\n\n\nCrowded housing (%)\nTract\n\n\nRent burdened (%)\nTract\n\n\nVacant housing (%)\nTract"
  },
  {
    "objectID": "posts/final_project/index.html#introduction",
    "href": "posts/final_project/index.html#introduction",
    "title": "Final Project",
    "section": "",
    "text": "The following project is a replication attempt of the machine learning model described in Huynh et al. [1] predicting lead exposure from drinking water within the city of Chicago. Lead-contaminated drinking water at the block level was defined as a binary variable indicating whether the majority of tests within a block have at least 1 ppb lead concentration. According to their model, approximately 75% of blocks are estimated to have lead-contaminated drinking water. The greatest predictors of lead-contaminated drinking water were geographic areas, population at the block, and number of buildings.\nHuynh et al. (and by extension, I) used the following data sources:\n\n\nData Sources\n\n\n\n\n\n\n\n\n\nSource\nMeasure\nExtent\n\n\n\n\nCity of Chicago Department of Water Management Lead Test Data\nConsecutive lead tests (ppb)\nAnonymized to the block\n\n\nCensus\nBlock FIPS\nBlock\n\n\nPopulation (#)\nBlock\n\n\nRace/ethnicity (#)\n\nAIAN\nAsian\nBlack\nHispanic\nWhite\n\nBlock\n\n\nAmerican Community Survey\nBlock FIPS\nBlock\n\n\nBlock group FIPS\nBlock group\n\n\nPopulation (#)\nBlock group, tract\n\n\nRace/ethnicity (#)\n\nAIAN\nAsian\nBlack\nHispanic\nWhite\n\nBlock group, tract\n\n\nHousing units (#)\nBlock group\n\n\nMedian house value ($)\nBlock group\n\n\nUpper house value ($)\nBlock group\n\n\nLower house value ($)\nBlock group\n\n\nMedian homeowner costs ($)\nBlock group\n\n\nEducation (#)\n\nHigh school\nGED\n&lt;1 year of college\n&gt; 1 year of college\nAssociate’s degree\nBachelor’s degree\nMaster’s degree\nProfessional School\nDoctoral Degree\n\nBlock group\n\n\nPoverty (#)\nBlock group\n\n\nEnglish-only speakers (#)\nBlock group\n\n\nComputer access (#)\nBlock group\n\n\nInternet access (#)\nBlock group\n\n\nComplete plumbing facilities (#)\nBlock group\n\n\nVacant Housing (#)\nBlock group\n\n\nOwner-occupied (#)\nBlock group\n\n\nChildren under 5 (#)\nBlock group\n\n\nChildren under 10 (#)\nBlock group\n\n\nChildren under 18 (#)\nBlock group\n\n\nChicago Building Footprints\nMedian building age (years)\nBlock\n\n\nBuilding (#)\nBlock\n\n\nMax age (years)\nBlock\n\n\nMean age (years)\nBlock\n\n\nBuilt after 1986 (#)\nBlock\n\n\nChicago Health Atlas\nCommunity area\nCommunity area\n\n\nLead poisoning rate (%)\nCommunity area\n\n\nHistorical lead poisoning rate (%)\nCommunity area\n\n\nEconomic diversity index\nTract\n\n\nHardship index\nTract\n\n\nSocial vulnerability index\nTract\n\n\nMajor crime (#)\nTract\n\n\nEviction rate (%)\nTract\n\n\nFine particulate matter concentration (\\(\\mu\\text{g/m}^3\\))\nTract\n\n\nAccess to food (%)\nTract\n\n\nUninsured rate (%)\nTract\n\n\nPer capita income ($)\nTract\n\n\nCognitive difficulty (%)\nTract\n\n\nDisability (%)\nTract\n\n\nCrowded housing (%)\nTract\n\n\nRent burdened (%)\nTract\n\n\nVacant housing (%)\nTract"
  },
  {
    "objectID": "posts/final_project/index.html#chicago-boundaries",
    "href": "posts/final_project/index.html#chicago-boundaries",
    "title": "Final Project",
    "section": "Chicago Boundaries",
    "text": "Chicago Boundaries\n\n\nCode\nchicagoBoundaries &lt;- st_read(\"https://data.cityofchicago.org/api/geospatial/qqq8-j68g?fourfour=qqq8-j68g&cacheBust=1712775952&date=20240411&accessType=DOWNLOAD&method=export&format=GeoJSON\") %&gt;%\n    st_transform(\"EPSG:4269\")\n\nchicagoCommunityAreas &lt;- st_read(\"https://data.cityofchicago.org/api/geospatial/cauq-8yn6?method=export&format=GeoJSON\") %&gt;%\n    st_transform(\"EPSG:4269\")\n\nchicagoBlocks &lt;- blocks(state = \"IL\", county = \"Cook\") %&gt;%\n    filter(st_intersects(., chicagoBoundaries, sparse = FALSE) %&gt;% unlist()) %&gt;%\n    filter(!str_detect(TRACTCE20, \"^9900\"))"
  },
  {
    "objectID": "posts/final_project/index.html#acs",
    "href": "posts/final_project/index.html#acs",
    "title": "Final Project",
    "section": "ACS",
    "text": "ACS\n\n\nCode\ncensus_metadata &lt;- \n    bind_rows(\n        load_variables(2022, \"acs5\"), \n        load_variables(2020, \"pl\"))\n\nblk_vars &lt;- c(\n    race_blk_total = \"P2_001N\",\n    race_blk_aianNH = \"P2_007N\",\n    race_blk_asianNH = \"P2_008N\",\n    race_blk_blackNH = \"P2_006N\",\n    race_blk_hispanic = \"P2_002N\",\n    race_blk_whiteNH = \"P2_005N\"\n)\n\nblkGrp_vars &lt;- c(\n    race_blkGrp_total = \"B03002_001\",\n    race_blkGrp_aianNH = \"B03002_005\",\n    race_blkGrp_asianNH = \"B03002_006\",\n    race_blkGrp_blackNH = \"B03002_004\",\n    race_blkGrp_hispanic = \"B03002_012\",\n    race_blkGrp_whiteNH = \"B03002_003\",\n    housingUnits = \"B25001_001\",\n    lowerValue = \"B25076_001\",\n    medValue = \"B25077_001\",\n    upperValue = \"B25078_001\",\n    homeownerCost = \"B25088_001\",\n    education_total = \"B15003_001\",\n    education_highSchool = \"B15003_017\",\n    education_ged = \"B15003_018\",\n    education_lt1yCollege = \"B15003_019\",\n    education_mt1yCollege = \"B15003_020\",\n    education_associate = \"B15003_021\",\n    education_bachelor = \"B15003_022\",\n    education_master = \"B15003_023\",\n    education_professional = \"B15003_024\",\n    education_doctorate = \"B15003_025\",\n    poverty_total = \"B17010_001\",\n    poverty_belowPovertyLvl = \"B17010_002\", \n    language_total = \"B99162_001\",\n    language_onlyEnglish = \"B99162_002\",\n    computer_total = \"B28003_001\",\n    computer_hasAComp = \"B28003_002\",\n    internet_total = \"B28011_001\",\n    internet_noInternet = \"B28011_008\",\n    plumbing_total = \"B25047_001\",\n    plumbing_complete = \"B25047_002\",\n    vacancy_total = \"B25002_001\",\n    vacancy_vacant = \"B25002_003\",\n    occupied_total = \"B25003_001\",\n    occupied_owner = \"B25003_002\",\n    age_total = \"B01001_001\",\n    age_maleU5 = \"B01001_003\",\n    age_male5to9 = \"B01001_004\",\n    age_male10to14 = \"B01001_005\",\n    age_male15to17 = \"B01001_006\",\n    age_femaleU5 = \"B01001_027\",\n    age_female5to9 = \"B01001_028\",\n    age_female10to14 = \"B01001_029\",\n    age_female15to17 = \"B01001_030\")\n\ntract_vars &lt;- c(\n    race_tract_total = \"B03002_001\",\n    race_tract_aianNH = \"B03002_005\",\n    race_tract_asianNH = \"B03002_006\",\n    race_tract_blackNH = \"B03002_004\",\n    race_tract_hispanic = \"B03002_012\",\n    race_tract_whiteNH = \"B03002_003\",\n    native_total = \"B05002_001\",\n    native_nativeBrn = \"B05002_002\",\n    native_foreignBrn = \"B05002_013\")\n\nselect_vars_metadata &lt;- census_metadata %&gt;%\n    filter(name %in% c(blk_vars, blkGrp_vars, tract_vars))\n\n\nGet data from ACS\n\n\nCode\nblk_data &lt;- get_decennial(geography = \"block\", variables = blk_vars, state = \"IL\", county = \"Cook\", output = \"wide\")\nblkGrp_data &lt;- get_acs(geography = \"block group\", variables = blkGrp_vars, state = \"IL\", county = \"Cook\", output = \"wide\") \ntract_data &lt;- get_acs(geography = \"tract\", variables = tract_vars, state = \"IL\", county = \"Cook\", output = \"wide\") \n\n\nFunction to calculate percent for each variable within the categories\n\n\nCode\npct_calculator &lt;- function(data, category) {\n    mutate(data, across(\n        .cols = matches(str_c(category, \"(.*)(?&lt;!(total))E$\"), perl = TRUE), \n        .fn = ~ .x / !!sym(str_c(category, \"_totalE\")),\n        .names = \"{.col}Pct\"))\n}\n\n\nGet data from the ACS and process it\n\n\nCode\nblk_data %&gt;%\n    select(-NAME) %&gt;%\n    rename(GEOID_blk = GEOID) %&gt;%\n    mutate(GEOID_blkGrp = str_sub(GEOID_blk, 1, -4)) %&gt;%\n    mutate(GEOID_tract = str_sub(GEOID_blk, 1, -5)) %&gt;%\n    relocate(GEOID_blkGrp, GEOID_tract, .after = GEOID_blk) %&gt;%\n    left_join(\n        blkGrp_data %&gt;%\n            select(-NAME), \n        by = join_by(GEOID_blkGrp == GEOID)) %&gt;%\n    left_join(\n        tract_data %&gt;%\n            select(-NAME), \n        by = join_by(GEOID_tract == GEOID)) %&gt;%\n    mutate(\n        age_U5E = age_maleU5E + age_femaleU5E,\n        age_5to9E = age_male5to9E + age_female5to9E,\n        age_10to17E = age_male10to14E + age_female10to14E + age_male15to17E + age_male15to17E) %&gt;%\n    select(-contains(\"male\"))"
  },
  {
    "objectID": "posts/final_project/index.html#chicago-lead-tests",
    "href": "posts/final_project/index.html#chicago-lead-tests",
    "title": "Final Project",
    "section": "Chicago Lead Tests",
    "text": "Chicago Lead Tests\n\n\nCode\npb_test_path &lt;- tempfile()\ndownload.file(\"https://www.chicagowaterquality.org/DataFiles/wqContent/Results.xlsx\", pb_test_path, mode=\"wb\")\n\nchicago_lead_tests &lt;- read_excel(path = pb_test_path, skip = 2, sheet = 1) %&gt;%\n    filter(!is.na(`Sample Date`))"
  },
  {
    "objectID": "posts/final_project/index.html#chicago-health-atlas",
    "href": "posts/final_project/index.html#chicago-health-atlas",
    "title": "Final Project",
    "section": "Chicago Health Atlas",
    "text": "Chicago Health Atlas\n\n\nCode\nrequest(\"https://chicagohealthatlas.org/api/action/download/\") %&gt;%\n    req_method(\"POST\") %&gt;%\n    req_body_raw(r\"[{\"layer\":\"tract-2020\",\"topics\":\"EDX-~2018-2022,HDX-~2018-2022,SVI-~2020,CZM-~2018-2022,EVR-~2018,PMC-~2023,LFA-~2019,UNS-~2018-2022,PCI-~2018-2022,DIV-~2018-2022,DIS-~2018-2022,HTJ-~2018-2022,RBU-~2018-2022,VAC-~2018-2022\",\"state\":\"\",\"within\":\"\",\"regions\":\"\",\"place_filters\":\"\",\"errors\":\"se\",\"population\":false,\"lat_long\":false,\"counties\":false,\"documentation\":false,\"format\":\"csv\",\"insight\":\"\",\"benchmark\":false}]\", \"application/x-www-form-urlencoded\") %&gt;%\n    req_perform() %&gt;%\n    resp_body_string() %&gt;%\n    read_csv()\n\nrequest(\"https://chicagohealthatlas.org/api/action/download/\") %&gt;%\n    req_method(\"POST\") %&gt;%\n    req_body_raw(r\"[{\"layer\":\"neighborhood\",\"topics\":\"LDPP-~2023,LDPPH-~2016\",\"state\":\"\",\"within\":\"\",\"regions\":\"\",\"place_filters\":\"\",\"errors\":\"se\",\"population\":false,\"lat_long\":false,\"counties\":false,\"documentation\":false,\"format\":\"csv\",\"insight\":\"\",\"benchmark\":false}]\", \"application/x-www-form-urlencoded\") %&gt;%\n    req_perform() %&gt;%\n    resp_body_string() %&gt;%\n    read_csv()"
  },
  {
    "objectID": "posts/final_project/index.html#chicago-building-footprints",
    "href": "posts/final_project/index.html#chicago-building-footprints",
    "title": "Final Project",
    "section": "Chicago Building Footprints",
    "text": "Chicago Building Footprints\n\n\nCode\nsf_use_s2(FALSE)\n\nchicagoBuildings &lt;- st_read(\"https://data.cityofchicago.org/api/geospatial/syp8-uezg?fourfour=syp8-uezg&cacheBust=1712775954&date=20240414&accessType=DOWNLOAD&method=export&format=GeoJSON\") %&gt;%\n    st_transform(\"EPSG:4269\")\n\nbuilding_blocks &lt;- chicagoBuildings %&gt;%\n    filter(!st_is_empty(.)) %&gt;%\n    filter(st_name1 != \"\") %&gt;%\n    st_join(chicagoBlocks)"
  },
  {
    "objectID": "posts/final_project/index.html#chicago-lead",
    "href": "posts/final_project/index.html#chicago-lead",
    "title": "Final Project",
    "section": "Chicago Lead",
    "text": "Chicago Lead\n\n\nCode\nresp &lt;- building_blocks %&gt;%\n    st_drop_geometry() %&gt;%\n    as_tibble() %&gt;%\n    filter(year_built != 0) %&gt;%\n    slice(1:100) %&gt;% \n    mutate(st_add = str_c(label_hous, pre_dir1, st_name1, st_type1, sep = \" \")) %&gt;%\n    pull(st_add) %&gt;% \n    map(~\n        request(\"https://sli.chicagowaterquality.org/servicematerialsearch/api/\") %&gt;%\n            req_method(\"POST\") %&gt;%\n            req_body_raw(str_c(r\"[{\"type\":\"text\",\"accNum\":\"-\",\"addr\":\"]\", .x, r\"[\"}]\"))\n    ) %&gt;%\n    req_perform_parallel(on_error = \"continue\")\n\nresp %&gt;%\n    resps_successes() %&gt;%\n    keep(map_lgl(., resp_has_body)) %&gt;%\n    resps_data(resp_body_json) %&gt;%\n    map(~ fromJSON(.x) %&gt;% `[[`(1)) %&gt;%\n    map_df(bind_cols)"
  },
  {
    "objectID": "posts/final_project/index.html#data",
    "href": "posts/final_project/index.html#data",
    "title": "Final Project",
    "section": "Data",
    "text": "Data\nLibraries\n\n\nCode\nlibrary(bonsai)\nlibrary(corrr)\nlibrary(finetune)\nlibrary(future)\nlibrary(httr2)\nlibrary(jsonlite)\nlibrary(leaflet)\nlibrary(magrittr)\nlibrary(mice)\nlibrary(readxl)\nlibrary(sf)\nlibrary(themis)\nlibrary(tidycensus)\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tigris)\n\n\n\nChicago Boundaries\n\nDownload\nDownload boundaries at various levels: the city, community areas, and census blocks.\n\n\nCode\nchicagoBoundaries &lt;- st_read(\"https://data.cityofchicago.org/api/geospatial/qqq8-j68g?fourfour=qqq8-j68g&cacheBust=1712775952&date=20240411&accessType=DOWNLOAD&method=export&format=GeoJSON\") %&gt;%\n    st_transform(\"EPSG:4269\")\n\nchicagoCommunityAreas &lt;- st_read(\"https://data.cityofchicago.org/api/geospatial/cauq-8yn6?method=export&format=GeoJSON\") %&gt;%\n    st_transform(\"EPSG:4269\")\n\ncookBlocks &lt;- blocks(state = \"IL\", county = \"Cook\") \n\n\n\n\nProcess\nPerform an intersection on census blocks to subset to those blocks that are within Chicago Boundaries. Mutate GEOIDs to create complete block, block group, and tract GEOIDS.\n\n\nCode\nchicagoBlocks &lt;- cookBlocks %&gt;%\n    filter(st_intersects(., chicagoBoundaries, sparse = FALSE) %&gt;% unlist()) %&gt;%\n    filter(!str_detect(TRACTCE20, \"^9900\")) %&gt;%\n    mutate(GEOID_blk = GEOID20) %&gt;%\n    mutate(GEOID_blkGrp = str_sub(GEOID_blk, 1, -4)) %&gt;%\n    mutate(GEOID_tract = str_sub(GEOID_blk, 1, -5)) %&gt;% \n    select(starts_with(\"GEOID_\"))\n\n\n\n\n\nAmerican Community Survey\n\nDownload\nGet metadata of all the relevant American Community Survey data.\n\n\nCode\ncensus_metadata &lt;- \n    bind_rows(\n        load_variables(2022, \"acs5\"), \n        load_variables(2020, \"pl\"))\n\nblk_vars &lt;- c(\n    race_blk_total = \"P2_001N\",\n    race_blk_aianNH = \"P2_007N\",\n    race_blk_asianNH = \"P2_008N\",\n    race_blk_blackNH = \"P2_006N\",\n    race_blk_hispanic = \"P2_002N\",\n    race_blk_whiteNH = \"P2_005N\"\n)\n\nblkGrp_vars &lt;- c(\n    race_blkGrp_total = \"B03002_001\",\n    race_blkGrp_aianNH = \"B03002_005\",\n    race_blkGrp_asianNH = \"B03002_006\",\n    race_blkGrp_blackNH = \"B03002_004\",\n    race_blkGrp_hispanic = \"B03002_012\",\n    race_blkGrp_whiteNH = \"B03002_003\",\n    housingUnits = \"B25001_001\",\n    lowerValue = \"B25076_001\",\n    medValue = \"B25077_001\",\n    upperValue = \"B25078_001\",\n    homeownerCost = \"B25088_001\",\n    education_total = \"B15003_001\",\n    education_highSchool = \"B15003_017\",\n    education_ged = \"B15003_018\",\n    education_lt1yCollege = \"B15003_019\",\n    education_mt1yCollege = \"B15003_020\",\n    education_associate = \"B15003_021\",\n    education_bachelor = \"B15003_022\",\n    education_master = \"B15003_023\",\n    education_professional = \"B15003_024\",\n    education_doctorate = \"B15003_025\",\n    poverty_total = \"B17010_001\",\n    poverty_belowPovertyLvl = \"B17010_002\", \n    language_total = \"B99162_001\",\n    language_onlyEnglish = \"B99162_002\",\n    computer_total = \"B28003_001\",\n    computer_hasAComp = \"B28003_002\",\n    internet_total = \"B28011_001\",\n    internet_noInternet = \"B28011_008\",\n    plumbing_total = \"B25047_001\",\n    plumbing_complete = \"B25047_002\",\n    vacancy_total = \"B25002_001\",\n    vacancy_vacant = \"B25002_003\",\n    occupied_total = \"B25003_001\",\n    occupied_owner = \"B25003_002\",\n    age_total = \"B01001_001\",\n    age_maleU5 = \"B01001_003\",\n    age_male5to9 = \"B01001_004\",\n    age_male10to14 = \"B01001_005\",\n    age_male15to17 = \"B01001_006\",\n    age_femaleU5 = \"B01001_027\",\n    age_female5to9 = \"B01001_028\",\n    age_female10to14 = \"B01001_029\",\n    age_female15to17 = \"B01001_030\")\n\ntract_vars &lt;- c(\n    race_tract_total = \"B03002_001\",\n    race_tract_aianNH = \"B03002_005\",\n    race_tract_asianNH = \"B03002_006\",\n    race_tract_blackNH = \"B03002_004\",\n    race_tract_hispanic = \"B03002_012\",\n    race_tract_whiteNH = \"B03002_003\",\n    native_total = \"B05002_001\",\n    native_nativeBrn = \"B05002_002\")\n\nselect_vars_metadata &lt;- census_metadata %&gt;%\n    filter(name %in% c(blk_vars, blkGrp_vars, tract_vars))\n\n\nDownload American Community Survey data for all the relevant variables\n\n\nCode\nblk_data &lt;- get_decennial(geography = \"block\", variables = blk_vars, state = \"IL\", county = \"Cook\", output = \"wide\")\nblkGrp_data &lt;- get_acs(geography = \"block group\", variables = blkGrp_vars, state = \"IL\", county = \"Cook\", output = \"wide\") \ntract_data &lt;- get_acs(geography = \"tract\", variables = tract_vars, state = \"IL\", county = \"Cook\", output = \"wide\") \n\n\n\n\nProcess\nJoin datasets and utilize multiple imputation by chained equations with random forest as the regression model.\n\n\nCode\nchicagoACS &lt;- blk_data %&gt;%\n    select(-NAME) %&gt;%\n    rename(GEOID_blk = GEOID) %&gt;%\n    mutate(GEOID_blkGrp = str_sub(GEOID_blk, 1, -4)) %&gt;%\n    mutate(GEOID_tract = str_sub(GEOID_blk, 1, -5)) %&gt;%\n    relocate(GEOID_blkGrp, GEOID_tract, .after = GEOID_blk) %&gt;%\n    left_join(\n        blkGrp_data %&gt;%\n            select(-ends_with(\"M\"), -NAME) %&gt;%\n            mice(meth = \"rf\", seed = 123) %&gt;%\n            complete() %&gt;%\n            as_tibble(),\n        join_by(GEOID_blkGrp == GEOID)) %&gt;%\n    left_join(\n        tract_data %&gt;%\n            select(-NAME), \n        join_by(GEOID_tract == GEOID)) %&gt;%\n    mutate(\n        age_U5E = age_maleU5E + age_femaleU5E,\n        age_5to9E = age_male5to9E + age_female5to9E,\n        age_10to17E = age_male10to14E + age_female10to14E + age_male15to17E + age_male15to17E) %&gt;%\n    select(-contains(\"male\"), -ends_with(\"M\")) %&gt;%\n    right_join(\n        chicagoBlocks %&gt;%\n            st_drop_geometry()\n    )\n\n\n\n\n\nChicago Building Footprints\n\nDownload\nDownload Chicago Building Footprints dataset to identify the age and number of buildings.\n\n\nCode\nchicagoBuildings &lt;- st_read(\"https://data.cityofchicago.org/api/geospatial/syp8-uezg?fourfour=syp8-uezg&cacheBust=1712775954&date=20240414&accessType=DOWNLOAD&method=export&format=GeoJSON\") %&gt;%\n    st_transform(\"EPSG:4269\")\n\n\n\n\nProcess\nRemove buildings with empty geometries or empty street names. Spatial join buildings to the block. Summarize building characteristics at the block level.\n\n\nCode\nsf_use_s2(FALSE)\n\nchicagoBuildingsImp &lt;- chicagoBuildings %&gt;%\n    filter(!st_is_empty(.)) %&gt;%\n    filter(st_name1 != \"\") %&gt;%\n    mutate(year_built =\n        case_when(\n            year_built == 0 ~ NA,\n            .default = as.integer(year_built)\n        )      \n    ) %&gt;%\n    select(year_built) %&gt;%\n    st_join(chicagoBlocks) %&gt;%\n    st_drop_geometry() %&gt;%\n    left_join(chicagoACS) %&gt;%\n    tibble() %&gt;%\n    mice(meth = \"rf\", seed = 234) %&gt;%\n    complete() %&gt;%\n    as_tibble()\n\nchicagoBldBlk &lt;- chicagoBuildingsImp %&gt;%\n    st_drop_geometry() %&gt;%\n    group_by(GEOID_blk) %&gt;%\n    summarise(\n        bldAge_median = 2024 - median(year_built),\n        bld_number = n(),\n        bldAge_max = 2024 - min(year_built),\n        bldAge_mean = 2024 - mean(year_built),\n        bldAge_nAft86 = sum(year_built &gt; 1986)\n    )\n\n\n\n\n\nChicago DWM Lead Tests\n\nDownload\nDownload Department of Water Management lead testing data\n\n\nCode\npb_test_path &lt;- tempfile()\ndownload.file(\"https://www.chicagowaterquality.org/DataFiles/wqContent/Results.xlsx\", pb_test_path, mode=\"wb\")\n\nchicagoPbTest &lt;- read_excel(path = pb_test_path, skip = 2, sheet = 1) \n\n\n\n\nProcess\n\n\nCode\nchicagoBuildingAddresses &lt;- chicagoBuildings %&gt;%\n    filter(!st_is_empty(.)) %&gt;%\n    filter(st_name1 != \"\") %&gt;%\n    st_join(chicagoBlocks) %&gt;%\n    st_drop_geometry() %&gt;%\n    as_tibble() %&gt;%\n    arrange(t_add1) %&gt;%\n    mutate(ID = row_number()) %&gt;%\n    mutate(\n        Address = str_pad(t_add1, 2, pad = \"0\"),\n        Address = str_c(str_sub(Address, end = -3), \"XX\"),\n        Address = str_c(Address, pre_dir1, st_name1, st_type1, sep = \" \"))\n\nchicagoPbBlk &lt;- chicagoPbTest %&gt;%\n    filter(!is.na(`Sample Date`)) %&gt;%\n    filter(`1st Draw` != \"See Follow-Up Sequential Sampling Table for Results\") %&gt;%\n    mutate(across(c(`1st Draw`, `2/3 Min`, `5 Min`), ~\n        case_when(\n            str_detect(.x, \"&lt;\") ~ NA,\n            .default = .x\n        )\n    )) %&gt;%\n    mutate(across(c(`1st Draw`, `2/3 Min`, `5 Min`), ~\n        case_when(\n            is.na(.x) ~ TRUE,\n            .default = FALSE\n        ),\n        .names = \"{.col}_lt1\"\n    )) %&gt;%\n    mutate(ID = \n        map_int(Address, ~\n            chicagoBuildingAddresses %&gt;%\n                filter(Address == .x) %&gt;%\n                slice( (n() + (n() %% 2))/2) %&gt;%\n                pluck(\"ID\") %&gt;%\n                {ifelse(length(.) == 0, NA, .)}\n        )\n    ) %&gt;% \n    left_join(chicagoBuildingAddresses) %&gt;%\n    group_by(GEOID_blk) %&gt;%\n    summarize(PB_gt1Pct = 1 - mean(`1st Draw_lt1`), PB_nTests = n()) %&gt;%\n    mutate(PB_majoritygt1 = PB_gt1Pct &gt;= 0.5)\n\n\n\n\n\nChicago Health Atlas\n\n\nCode\nchicagoHAtract &lt;- request(\"https://chicagohealthatlas.org/api/action/download/\") %&gt;%\n    req_method(\"POST\") %&gt;%\n    req_body_raw(r\"[{\"layer\":\"tract-2020\",\"topics\":\"EDX-~2018-2022,HDX-~2018-2022,SVI-~2020,CZM-~2018-2022,EVR-~2018,PMC-~2023,LFA-~2019,UNS-~2018-2022,PCI-~2018-2022,DIV-~2018-2022,DIS-~2018-2022,HTJ-~2018-2022,RBU-~2018-2022,VAC-~2018-2022\",\"state\":\"\",\"within\":\"\",\"regions\":\"\",\"place_filters\":\"\",\"errors\":\"se\",\"population\":false,\"lat_long\":false,\"counties\":false,\"documentation\":false,\"format\":\"csv\",\"insight\":\"\",\"benchmark\":false}]\", \"application/x-www-form-urlencoded\") %&gt;%\n    req_perform() %&gt;%\n    resp_body_string() %&gt;%\n    {read_csv(., col_names = names(read_csv(., n_max = 0)), cols(GEOID = \"c\"), skip = 2)} %&gt;%\n    select(-Layer, -Name) %&gt;%\n    rename(GEOID_tract = GEOID) %&gt;%\n    drop_na(!ends_with(\"se\"))\n\n\nchicagoHAPbCA &lt;- request(\"https://chicagohealthatlas.org/api/action/download/\") %&gt;%\n    req_method(\"POST\") %&gt;%\n    req_body_raw(r\"[{\"layer\":\"neighborhood\",\"topics\":\"LDPP-~2023,LDPPH-~2016\",\"state\":\"\",\"within\":\"\",\"regions\":\"\",\"place_filters\":\"\",\"errors\":\"se\",\"population\":false,\"lat_long\":false,\"counties\":false,\"documentation\":false,\"format\":\"csv\",\"insight\":\"\",\"benchmark\":false}]\", \"application/x-www-form-urlencoded\") %&gt;%\n    req_perform() %&gt;%\n    resp_body_string() %&gt;%\n    {read_csv(., col_names = names(read_csv(., n_max = 0)), cols(GEOID = \"c\"), skip = 2)}\n\nchicagoHAblk &lt;- chicagoBlocks %&gt;%\n    st_join(\n        left_join(chicagoHAPbCA, chicagoCommunityAreas, join_by(GEOID == area_numbe)) %&gt;%\n            st_as_sf(), \n        join = st_covered_by, \n        largest = TRUE) %&gt;%\n    rename(GEOID_CA = GEOID) %&gt;%\n    left_join(chicagoHAtract) %&gt;%\n    st_drop_geometry() %&gt;%\n    as_tibble() %&gt;%\n    select(-Layer, -Name, -community, -area, -shape_area, -perimeter, -area_num_1, -comarea_id, -comarea, -shape_len) %&gt;%\n    drop_na(!ends_with(\"se\"))\n\n\n\n\nChicago Service Line Inventory\n\nDownload\nNot currently implemented due to time constraints. This an additional data source that I am contemplating using.\n\n\nCode\nresp &lt;- building_blocks %&gt;%\n    st_drop_geometry() %&gt;%\n    as_tibble() %&gt;%\n    filter(year_built != 0) %&gt;%\n    slice(1:100) %&gt;% \n    mutate(st_add = str_c(label_hous, pre_dir1, st_name1, st_type1, sep = \" \")) %&gt;%\n    pull(st_add) %&gt;% \n    map(~\n        request(\"https://sli.chicagowaterquality.org/servicematerialsearch/api/\") %&gt;%\n            req_method(\"POST\") %&gt;%\n            req_body_raw(str_c(r\"[{\"type\":\"text\",\"accNum\":\"-\",\"addr\":\"]\", .x, r\"[\"}]\"))\n    ) %&gt;%\n    req_perform_parallel(on_error = \"continue\")\n\nresp %&gt;%\n    resps_successes() %&gt;%\n    keep(map_lgl(., resp_has_body)) %&gt;%\n    resps_data(resp_body_json) %&gt;%\n    map(~ fromJSON(.x) %&gt;% `[[`(1)) %&gt;%\n    map_df(bind_cols)\n\n\n\n\n\nJoining and Conducting Final Processing\nIn the end, the following criteria was used to include blocks within the study:\n\nPopulation greater than 0\nNumber of buildings greater than 0\nWithin tract included in the Chicago Health Atlas\n\nThis leaves us with:\n\n33,004 total blocks\n12,031 blocks with at least one prior DWM test\n\n0.799 blocks have a majority of first draw tests with detected lead levels greater than 1 ppb\n\n\n\n\nCode\npct_calculator &lt;- function(data, category) {\n    mutate(data, across(\n        .cols = matches(str_c(\"^\", category, \"(.*)(?&lt;!(total))E$\"), perl = TRUE), \n        .fn = ~ .x / !!sym(str_c(category, \"_totalE\")),\n        .names = \"{.col}Pct\")) %&gt;%\n    select(-matches(str_c(\"^\", category, \"(.*)(?&lt;!(total))E$\"), perl = TRUE))\n}\n\ndata &lt;- chicagoACS %&gt;%\n    left_join(chicagoPbBlk) %&gt;%\n    inner_join(chicagoBldBlk) %&gt;%\n    inner_join(chicagoHAblk) %&gt;%\n    select(-ends_with(\"se\")) %&gt;%\n    relocate(GEOID_CA, PB_gt1Pct, PB_nTests, PB_majoritygt1, .after = GEOID_tract) %&gt;%\n    rename_with(.cols = starts_with(\"race_blk_\"), .fn = ~ str_c(.x, \"E\")) %&gt;%\n    filter(race_blk_totalE &gt; 0) %&gt;%\n    pct_calculator(\"race_blk\") %&gt;%\n    pct_calculator(\"race_blkGrp\") %&gt;%\n    pct_calculator(\"race_tract\") %&gt;%\n    pct_calculator(\"education\") %&gt;%\n    pct_calculator(\"poverty\") %&gt;%\n    pct_calculator(\"computer\") %&gt;%\n    pct_calculator(\"internet\") %&gt;%\n    pct_calculator(\"plumbing\") %&gt;%\n    pct_calculator(\"vacancy\") %&gt;%\n    pct_calculator(\"occupied\") %&gt;%\n    pct_calculator(\"age\") %&gt;%\n    pct_calculator(\"language\") %&gt;%\n    pct_calculator(\"native\") %&gt;%\n    drop_na(-starts_with(\"PB\")) %&gt;%\n    select(-matches(\"^(?!race)(.*)_totalE$\", perl = TRUE)) %&gt;%\n    rename_with(.cols = starts_with(\"race\"), ~ \n        str_replace(.x, \"race\", \"population\") %&gt;%\n            str_replace(\"_totalE\", \"E\")\n    )\n\ndata %&gt;%\n    summarize(across(everything(), ~ sum(is.na(.x)))) %&gt;%\n    View()"
  },
  {
    "objectID": "posts/final_project/index.html#exploratory-data-analysis",
    "href": "posts/final_project/index.html#exploratory-data-analysis",
    "title": "Final Project",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTracts that test more tend to have a higher percent of water tests with greater than 1 PPB lead even when adjusting for population size.\n\nLead Positive Percentage by Number of TestsLead Positive Percentage by Number of Tests Per Person\n\n\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_tract) %&gt;%\n    summarize(\n        n = sum(PB_nTests, na.rm = TRUE),\n        gt1pct = sum(PB_nTests * PB_gt1Pct, na.rm = TRUE)/ n\n    ) %&gt;% \n    group_by(n, gt1pct) %&gt;%\n    summarize(nTract = n()) %&gt;% \n    ggplot(aes(x = n, y = gt1pct, color = nTract, size = nTract)) +\n        geom_point() +\n        labs(\n            title = \"Number of Tests vs Percent of Tests with Greater than 1 \\nPPB Lead Detected by Tract\",\n            x = \"Tests (#)\",\n            y = \"Tests with Greater than 1 PPB Lead Detected (%)\") +\n        scale_color_gradient(low = \"steelblue1\", high = \"black\") +\n        scale_y_continuous(labels = scales::percent) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            legend.position=\"none\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_tract) %&gt;%\n    summarize(\n        nPer100People = 100 *sum(PB_nTests, na.rm = TRUE) / population_tractE[1],\n        gt1pct = sum(PB_nTests * PB_gt1Pct, na.rm = TRUE)/  sum(PB_nTests, na.rm = TRUE)\n    ) %&gt;% \n    ggplot(aes(x = nPer100People, y = gt1pct)) +\n        geom_point(color = \"steelblue1\") +\n        labs(\n            title = \"Number of Tests per 100 Residents vs Percent of Tests with Greater than 1 \\nPPB Lead Detected by Tract\",\n            x = \"Tests Per 100 Residents (#)\",\n            y = \"Tests with Greater than 1 PPB Lead Detected (%)\") +\n        scale_y_continuous(labels = scales::percent) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            legend.position=\"none\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\nWe can see that residents on the north side have disproportionately low positive lead rates when compared to that of the rest of Chicago\n\nPositive Test Percentage by Block GroupPositive Test Percentage by TractPositive Test Percentage by Community Area\n\n\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_blkGrp) %&gt;%\n    summarize(\n        n = sum(PB_nTests, na.rm = TRUE),\n        gt1pct = sum(PB_nTests * PB_gt1Pct, na.rm = TRUE) / n\n    ) %&gt;% \n    left_join(block_groups(state = \"IL\", county = \"Cook\", progress_bar = FALSE), join_by(GEOID_blkGrp == GEOID)) %&gt;%\n    st_as_sf() %$%\n        {leaflet(.) %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ colorNumeric(\"Blues\", gt1pct)(gt1pct),\n            fillOpacity = 0.7,\n            weight = 0,\n            highlightOptions = highlightOptions(\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = str_glue_data(., \"&lt;strong&gt;{GEOID_blkGrp}&lt;/strong&gt;&lt;br&gt;Percent of Tests: {round(gt1pct,2)}&lt;br/&gt;\") %&gt;% \n                    map(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")\n        ) %&gt;%\n        addLegend(\n            pal = colorNumeric(\"Blues\", gt1pct),\n            values = gt1pct,\n            opacity = 0.7,\n            title = \"Tests with Greater than 1 PPB Lead &lt;br&gt; Detected (%) By Block Group\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = labelFormat(\n                prefix = \" \", suffix = \" %\",\n                transform = function(x) 100 * x)\n        )} %&gt;%\n        htmlwidgets::prependContent(htmltools::tags$style(type = \"text/css\", \"div.info.legend.leaflet-control br {clear: both;}\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_tract) %&gt;%\n    summarize(\n        n = sum(PB_nTests, na.rm = TRUE),\n        gt1pct = sum(PB_nTests * PB_gt1Pct, na.rm = TRUE) / n\n    ) %&gt;% \n    left_join(tracts(state = \"IL\", county = \"Cook\", progress_bar = FALSE), join_by(GEOID_tract == GEOID)) %&gt;%\n    st_as_sf() %$%\n        {leaflet(.) %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ colorNumeric(\"Blues\", gt1pct)(gt1pct),\n            fillOpacity = 0.7,\n            weight = 0,\n            highlightOptions = highlightOptions(\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = str_glue_data(., \"&lt;strong&gt;{GEOID_tract}&lt;/strong&gt;&lt;br&gt;Percent of Tests: {round(gt1pct,2)}&lt;br/&gt;\") %&gt;% \n                    map(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")\n        ) %&gt;%\n        addLegend(\n            pal = colorNumeric(\"Blues\", gt1pct),\n            values = gt1pct,\n            opacity = 0.7,\n            title = \"Tests with Greater than 1 PPB Lead &lt;br&gt; Detected (%) By Tract\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = labelFormat(\n                prefix = \" \", suffix = \" %\",\n                transform = function(x) 100 * x)\n        )} %&gt;%\n        htmlwidgets::prependContent(htmltools::tags$style(type = \"text/css\", \"div.info.legend.leaflet-control br {clear: both;}\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_CA) %&gt;%\n    summarize(\n        n = sum(PB_nTests, na.rm = TRUE),\n        gt1pct = sum(PB_nTests * PB_gt1Pct, na.rm = TRUE) / n\n    ) %&gt;% \n    left_join(chicagoCommunityAreas, join_by(GEOID_CA == area_numbe)) %&gt;%\n    st_as_sf() %$%\n        {leaflet(.) %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ colorNumeric(\"Blues\", gt1pct)(gt1pct),\n            fillOpacity = 0.7,\n            weight = 0,\n            highlightOptions = highlightOptions(\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = str_glue_data(., \"&lt;strong&gt;{community}&lt;/strong&gt;&lt;br&gt;Percent of Tests: {round(gt1pct,2)}&lt;br/&gt;\") %&gt;% \n                    map(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")\n        ) %&gt;%\n        addLegend(\n            pal = colorNumeric(\"Blues\", gt1pct),\n            values = gt1pct,\n            opacity = 0.7,\n            title = \"Tests with Greater than 1 PPB Lead &lt;br&gt; Detected (%) By Community Area\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\",\n            labFormat = labelFormat(\n                prefix = \" \", suffix = \" %\",\n                transform = function(x) 100 * x)\n        )} %&gt;%\n        htmlwidgets::prependContent(htmltools::tags$style(type = \"text/css\", \"div.info.legend.leaflet-control br {clear: both;}\"))\n\n\n\n\n\n\n\n\n\n\n\nTests Per Person by Block GroupTests Per Person by Tract\n\n\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_blkGrp) %&gt;%\n    summarize(\n        nPer100People = 100 *sum(PB_nTests, na.rm = TRUE) / population_blkGrpE[1]\n    ) %&gt;% \n    left_join(block_groups(state = \"IL\", county = \"Cook\", progress_bar = FALSE), join_by(GEOID_blkGrp == GEOID)) %&gt;%\n    st_as_sf() %$%\n        {leaflet(.) %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ colorNumeric(\"Blues\", nPer100People)(nPer100People),\n            fillOpacity = 0.7,\n            weight = 0,\n            highlightOptions = highlightOptions(\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = str_glue_data(., \"&lt;strong&gt;{GEOID_blkGrp}&lt;/strong&gt;&lt;br&gt;Tests per 100 People: {round(nPer100People,2)}&lt;br/&gt;\") %&gt;% \n                    map(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")\n        ) %&gt;%\n        addLegend(\n            pal = colorNumeric(\"Blues\", nPer100People),\n            values = nPer100People,\n            opacity = 0.7,\n            title = \"Tests per 100 People &lt;br&gt;By Block Group\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\"\n        )} %&gt;%\n        htmlwidgets::prependContent(htmltools::tags$style(type = \"text/css\", \"div.info.legend.leaflet-control br {clear: both;}\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_tract) %&gt;%\n    summarize(\n        nPer100People = 100 *sum(PB_nTests, na.rm = TRUE) / population_tractE[1]\n    ) %&gt;% \n    left_join(tracts(state = \"IL\", county = \"Cook\", progress_bar = FALSE), join_by(GEOID_tract == GEOID)) %&gt;%\n    st_as_sf() %$%\n        {leaflet(.) %&gt;%\n        addProviderTiles(providers$CartoDB.Positron) %&gt;% \n        addPolygons(\n            fillColor = ~ colorNumeric(\"Blues\", nPer100People)(nPer100People),\n            fillOpacity = 0.7,\n            weight = 0,\n            highlightOptions = highlightOptions(\n                color = \"Black\",\n                fillOpacity = 1,\n                bringToFront = T),\n            label = str_glue_data(., \"&lt;strong&gt;{GEOID_tract}&lt;/strong&gt;&lt;br&gt;Tests per 100 People: {round(nPer100People,2)}&lt;br/&gt;\") %&gt;% \n                    map(htmltools::HTML),\n            labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"12px\",\n                direction = \"auto\")\n        ) %&gt;%\n        addLegend(\n            pal = colorNumeric(\"Blues\", nPer100People),\n            values = nPer100People,\n            opacity = 0.7,\n            title = \"Tests per 100 People &lt;br&gt;By Tract\",\n            position = \"topright\",\n            na.label = \"Insufficient Data\"\n        )} %&gt;%\n        htmlwidgets::prependContent(htmltools::tags$style(type = \"text/css\", \"div.info.legend.leaflet-control br {clear: both;}\"))\n\n\n\n\n\n\n\n\n\n\n\nPositive Test Percentage by Mean Building AgePositive Test Percentage by Percent Built Before 1986\n\n\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_tract) %&gt;%\n    summarize(\n        bldAge_mean = sum(bldAge_mean * bld_number, na.rm = TRUE)/sum(bld_number, na.rm = TRUE),\n        PB_gt1Pct = sum(PB_gt1Pct * PB_nTests, na.rm = TRUE)/sum(PB_nTests, na.rm = TRUE)\n    ) %&gt;% \n    ggplot(aes(x = bldAge_mean, y = PB_gt1Pct)) +\n        geom_point(color = \"steelblue1\") +\n        labs(\n            title = \"Mean Building Age vs Percent of Tests with Greater than 1 \\nPPB Lead Detected by Tract\",\n            x = \"Mean Building Age (years)\",\n            y = \"Tests with Greater than 1 PPB Lead Detected (%)\") +\n        scale_y_continuous(labels = scales::percent) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            legend.position=\"none\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_tract) %&gt;%\n    summarize(\n        bldAge_nBfr86 = 1-((sum(bldAge_nAft86, na.rm = TRUE))/sum(bld_number, na.rm = TRUE)),\n        PB_gt1Pct = sum(PB_gt1Pct * PB_nTests, na.rm = TRUE)/sum(PB_nTests, na.rm = TRUE)\n    ) %&gt;% \n    ggplot(aes(x = bldAge_nBfr86, y = PB_gt1Pct)) +\n        geom_point(color = \"steelblue1\") +\n        labs(\n            title = \"Percent of Buildings built after 1986 vs Percent of Tests with \\nGreater than 1 PPB Lead Detected by Tract\",\n            x = \"Buildings built after 1986 (%)\",\n            y = \"Tests with Greater than 1 PPB Lead Detected (%)\") +\n        scale_x_continuous(labels = scales::percent) +\n        scale_y_continuous(labels = scales::percent) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            legend.position=\"none\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndata %&gt;%\n    select(where(is.numeric)) %&gt;%\n    select(where(function(x) sum(!is.na(x)) != 0)) %&gt;%\n    select(where(function(x) var(x, na.rm = TRUE) != 0)) %&gt;% \n    correlate(method = \"spearman\") %&gt;%\n    autoplot()"
  },
  {
    "objectID": "posts/final_project/index.html#lead-positive-percentage-by-number-of-tests",
    "href": "posts/final_project/index.html#lead-positive-percentage-by-number-of-tests",
    "title": "Final Project",
    "section": "Lead Positive Percentage by Number of Tests",
    "text": "Lead Positive Percentage by Number of Tests\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_tract) %&gt;%\n    summarize(\n        n = sum(PB_nTests, na.rm = TRUE),\n        gt1pct = sum(PB_nTests * PB_gt1Pct, na.rm = TRUE)/ n\n    ) %&gt;% \n    group_by(n, gt1pct) %&gt;%\n    summarize(nTract = n()) %&gt;% \n    ggplot(aes(x = n, y = gt1pct, color = nTract, size = nTract)) +\n        geom_point() +\n        labs(\n            title = \"Number of Tests vs Percent of Tests with Greater than 1 \\nPPB Lead Detected by Tract\",\n            x = \"Tests (#)\",\n            y = \"Tests with Greater than 1 PPB Lead Detected\") +\n        scale_color_gradient(low = \"steelblue1\", high = \"black\") +\n        scale_y_continuous(labels = scales::percent) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            legend.position=\"none\"\n        )"
  },
  {
    "objectID": "posts/final_project/index.html#lead-positive-percentage-by-number-of-tests-per-person",
    "href": "posts/final_project/index.html#lead-positive-percentage-by-number-of-tests-per-person",
    "title": "Final Project",
    "section": "Lead Positive Percentage by Number of Tests Per Person",
    "text": "Lead Positive Percentage by Number of Tests Per Person\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_tract) %&gt;%\n    summarize(\n        nPer100People = 100 *sum(PB_nTests, na.rm = TRUE) / population_tractE[1],\n        gt1pct = sum(PB_nTests * PB_gt1Pct, na.rm = TRUE)/  sum(PB_nTests, na.rm = TRUE)\n    ) %&gt;% \n    ggplot(aes(x = nPer100People, y = gt1pct)) +\n        geom_point(color = \"steelblue1\") +\n        labs(\n            title = \"Number of Tests per 100 Residents vs Percent of Tests with Greater than 1 \\nPPB Lead Detected by Tract\",\n            x = \"Tests Per 100 Residents (#)\",\n            y = \"Tests with Greater than 1 PPB Lead Detected\") +\n        scale_y_continuous(labels = scales::percent) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            legend.position=\"none\"\n        )"
  },
  {
    "objectID": "posts/final_project/index.html#positive-test-percentage-by-percent-built-before-1986",
    "href": "posts/final_project/index.html#positive-test-percentage-by-percent-built-before-1986",
    "title": "Final Project",
    "section": "Positive Test Percentage by Percent Built Before 1986",
    "text": "Positive Test Percentage by Percent Built Before 1986\n\n\nCode\ndata %&gt;%\n    group_by(GEOID_tract) %&gt;%\n    summarize(\n        bldAge_nBfr86 = 1-((sum(bldAge_nAft86, na.rm = TRUE))/sum(bld_number, na.rm = TRUE)),\n        PB_gt1Pct = sum(PB_gt1Pct * PB_nTests, na.rm = TRUE)/sum(PB_nTests, na.rm = TRUE)\n    ) %&gt;% \n    ggplot(aes(x = bldAge_nBfr86, y = PB_gt1Pct)) +\n        geom_point(color = \"steelblue1\") +\n        labs(\n            title = \"Percent of Buildings built after 1986 vs Percent of Tests with \\nGreater than 1 PPB Lead Detected by Tract\",\n            x = \"Buildings built after 1986 (%)\",\n            y = \"Tests with Greater than 1 PPB Lead Detected (%)\") +\n        scale_y_continuous(labels = scales::percent) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            legend.position=\"none\"\n        )"
  },
  {
    "objectID": "posts/final_project/index.html#modeling",
    "href": "posts/final_project/index.html#modeling",
    "title": "Final Project",
    "section": "Modeling",
    "text": "Modeling\n\n\nCode\ntidymodels_prefer()\n\n\n\nCreating Test/Training Data\n\n\nCode\nset.seed(345) \nmodel_fitting_data &lt;- data %&gt;%\n    mutate(PB_nTests = \n        case_when(\n            is.na(PB_nTests) ~ 5,\n            .default = PB_nTests\n        )\n    ) %&gt;%\n    filter(!is.na(PB_majoritygt1)) %&gt;%\n    mutate(PB_majoritygt1 = as.factor(PB_majoritygt1)) %&gt;%\n    filter(GEOID_CA == \"22\") %&gt;%\n    select(-PB_gt1Pct, -GEOID_blk, -GEOID_CA)\n\nsplit &lt;- initial_split(model_fitting_data, strata = PB_majoritygt1)\ntrain &lt;- training(split)\ntest  &lt;- testing(split)\n\nset.seed(456) \nresamples &lt;- vfold_cv(train, v = 5, strata = PB_majoritygt1)\n\n\n\n\nCreating Our Recipes\n\n\nCode\ndefault_recipe &lt;- model_fitting_data %&gt;%    \n    recipe(PB_majoritygt1 ~ .) %&gt;%   \n    step_novel(all_nominal_predictors()) %&gt;%   \n    step_dummy(all_nominal_predictors()) %&gt;%\n    step_zv(all_predictors()) %&gt;%\n    step_smote(all_outcomes())\n\nnormalized_recipe &lt;- default_recipe %&gt;%\n    step_normalize(all_predictors())\n\n\n\n\nCreating Our Models\n\n\nCode\nlogistic_class_spec &lt;- \n    logistic_reg(penalty = tune(), mixture = tune()) %&gt;% \n    set_engine(\"glmnet\") %&gt;% \n    set_mode(\"classification\")\n\nlightGBM_class_spec &lt;- \n    boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), min_n = tune(), sample_size = tune(), trees = tune()) %&gt;%\n    set_engine(\"lightgbm\") %&gt;%\n    set_mode(\"classification\")\n\nrf_class_spec &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCreating Workflow\n\n\nCode\nnormalized &lt;- workflow_set(\n    preproc = list(normalized = normalized_recipe),\n    models = list(logistic = logistic_class_spec))\n\nno_pre_proc &lt;- workflow_set(\n    preproc = list(simple = default_recipe), \n    models = list(RF = rf_class_spec, boosting = lightGBM_class_spec))\n\n\n\n\nCode\nall_workflows &lt;- bind_rows(no_pre_proc, normalized)\n\n\n\n\nTune Model\n\n\nCode\nconflicted::conflicts_prefer(purrr::flatten)\nconflicted::conflicts_prefer(purrr::set_names)\n\ngrid_results &lt;- all_workflows %&gt;%\n  workflow_map(\n    \"tune_race_anova\",\n    seed = 567,\n    resamples = resamples,\n    grid = 30,\n    control = control_race(\n      save_pred = FALSE,\n      save_workflow = FALSE,\n      parallel_over = \"everything\"))\n\n\n\n\nCode\nautoplot(grid_results)\n\n\n\n\n\n\n\n\n\n\n\nSelect Best Model\n\n\nCode\nconflicted::conflicts_prefer(dplyr::filter)\n\nbest_wf &lt;- grid_results %&gt;% \n    rank_results() %&gt;%\n    filter(.metric == \"roc_auc\", rank == 1) %&gt;%\n    pull(wflow_id)\n\nbest_results &lt;- grid_results %&gt;%\n    extract_workflow_set_result(best_wf) %&gt;% \n    select_best(metric = \"roc_auc\") \n\nbest_results_fit &lt;- \n    grid_results %&gt;% \n    extract_workflow(best_wf) %&gt;%\n    finalize_workflow(best_results) %&gt;% \n    last_fit(split = split)\n\n\n\n\nCode\nbayes_results &lt;- grid_results %&gt;% \n    extract_workflow(best_wf) %&gt;%\n    tune_bayes(\n        resamples = resamples,\n        initial = 20,\n        iter = 25,\n        control = control_bayes(verbose = TRUE)\n    )\n\n\n\n\nCode\nbayes_results %&gt;%\n  show_best(metric = \"roc_auc\") %&gt;% \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrees\nmin_n\ntree_depth\nlearn_rate\nloss_reduction\nsample_size\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n.iter\n\n\n\n\n633\n2\n13\n0.0017964\n0.0000367\n0.3963353\nroc_auc\nbinary\n0.7191007\n5\n0.0337507\nIter9\n9\n\n\n1290\n33\n12\n0.0004314\n0.0478811\n0.3810152\nroc_auc\nbinary\n0.7188557\n5\n0.0486365\nPreprocessor1_Model17\n0\n\n\n1186\n21\n12\n0.0012358\n0.0000000\n0.3930846\nroc_auc\nbinary\n0.7157183\n5\n0.0400548\nIter16\n16\n\n\n932\n3\n8\n0.0000000\n3.4591221\n0.2315099\nroc_auc\nbinary\n0.7154971\n5\n0.0359560\nPreprocessor1_Model01\n0\n\n\n1737\n21\n7\n0.0000000\n13.4263931\n0.2740644\nroc_auc\nbinary\n0.7143354\n5\n0.0459334\nIter10\n10\n\n\n\n\n\n\n\nCode\nfinal_fit &lt;- grid_results %&gt;% \n    extract_workflow(best_wf) %&gt;%\n    finalize_workflow(select_best(bayes_results, metric = \"roc_auc\")) %&gt;% \n    last_fit(split = split)\n\n\n\n\nCode\nfinal_fit %&gt;%\n    collect_predictions() %&gt;%\n    roc_curve(PB_majoritygt1, .pred_FALSE) %&gt;%\n    autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_fit %&gt;% \n    collect_metrics() %&gt;%\n    knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.6382979\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.6828125\nPreprocessor1_Model1\n\n\n\n\n\n\n\nCode\nfinal_fit %&gt;%\n    collect_predictions() %&gt;%\n    conf_mat(PB_majoritygt1, .pred_class) %&gt;%\n    autoplot(type = \"heatmap\")"
  }
]